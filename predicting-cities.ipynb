{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXQfUTayFg2l",
    "outputId": "140f2379-a732-4dda-ab2a-0a0b077959fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 29 20:29:48 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 24%   35C    P8    20W / 250W |     80MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4757      G   /usr/lib/xorg/Xorg                 75MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import momepy\n",
    "import fiona\n",
    "import networkx as nx\n",
    "\n",
    "# Seed for result reproducability\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset_root = './datasets'\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0lkjKOX9KP9",
    "outputId": "cc223d13-efbd-429e-ea30-1653d77a4eee"
   },
   "outputs": [],
   "source": [
    "full_dataset_label = 'No Bounds'\n",
    "\n",
    "# training_places = ['Coventry'] # for testing\n",
    "training_places = ['Leeds', 'Cambridge', 'Coventry', 'Bristol', 'Leicester', 'Glasgow']\n",
    "# training_places = [full_dataset_label]\n",
    "test_places = ['Leeds', 'Manchester', 'Sheffield', 'Liverpool', 'Edinburgh', 'Wales']\n",
    "true_inductive = ['nashville indiana', 'belfast', 'manhattan', 'singapore', 'tokyo']\n",
    "\n",
    "# Fields to ignore\n",
    "meridian_fields = ['meridian_id', 'meridian_gid', 'meridian_code',\n",
    "                   'meridian_osodr', 'meridian_number', 'meridian_road_name',\n",
    "                   'meridian_indicator', 'meridian_class', 'meridian_class_scale']\n",
    "census_geom_fields = ['wz11cd', 'lsoa11nm', 'msoa11nm',\n",
    "                      'oa11cd', 'lsoa11cd', 'msoa11cd'] # Allowed: lad11cd, lad11nm\n",
    "misc_fields = ['id']\n",
    "ignore_fields = meridian_fields + census_geom_fields + misc_fields\n",
    "\n",
    "\n",
    "unnorm_feature_fields = ['metres', 'choice2km', 'nodecount2km', 'integration2km',\n",
    "                      'choice10km', 'nodecount10km','integration10km',\n",
    "                      'choice100km','nodecount100km','integration100km']\n",
    "rank_fields = ['choice2kmrank', 'choice10kmrank','integration10kmrank', 'integration2kmrank']\n",
    "log_fields = ['choice2kmlog','choice10kmlog','choice100kmlog']\n",
    "all_feature_fields = unnorm_feature_fields + rank_fields + log_fields\n",
    "\n",
    "# Post-processing features\n",
    "feats = ['metres', 'choice2km', 'nodecount2km', 'integration2km', 'choice10km',\n",
    "         'nodecount10km', 'integration10km', 'choice100km', 'nodecount100km',\n",
    "         'integration100km', 'choice2kmrank', 'choice10kmrank', 'integration10kmrank',\n",
    "         'integration2kmrank', 'choice2kmlog', 'choice10kmlog', 'choice100kmlog', 'x', 'y']\n",
    "\n",
    "# dictionary caches - RELOADING THIS CELL DELETES GRAPH CACHES\n",
    "loaded_gdfs = {}\n",
    "loaded_graphs={}\n",
    "\n",
    "# Projection\n",
    "from pyproj import CRS, Transformer\n",
    "crs_proj = CRS.from_epsg(27700)\n",
    "crs_4326 = CRS(\"WGS84\")\n",
    "transformer = Transformer.from_crs(crs_4326, crs_proj)\n",
    "\n",
    "def proj_and_reorder_bounds(bbox):\n",
    "  S, W, N, E = bbox\n",
    "  [S, N], [W, E] = transformer.transform([S, N], [W, E])\n",
    "  return (S, W, N, E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Isle of Wight', 'Wycombe', None, 'Enfield', 'Slough',\n",
       "       'South Bucks', 'Hillingdon', 'Ealing', 'Chiltern', 'Copeland',\n",
       "       'Windsor and Maidenhead', 'Plymouth', 'South Hams', 'Oxford',\n",
       "       'Waltham Forest', 'Mendip', 'Dudley', 'Cotswold', 'Erewash',\n",
       "       'Redbridge', 'Epping Forest', 'Test Valley',\n",
       "       'Basingstoke and Deane', 'South Gloucestershire', 'Woking',\n",
       "       'Broxbourne', 'Wolverhampton', 'Wiltshire', 'Swindon',\n",
       "       'Bath and North East Somerset', 'Trafford', 'Salford',\n",
       "       'South Staffordshire', 'West Oxfordshire', 'Malvern Hills',\n",
       "       'Vale of White Horse', 'South Kesteven', 'North Kesteven',\n",
       "       'Guildford', 'Southwark', 'Chichester', 'Waverley', 'Elmbridge',\n",
       "       'Forest of Dean', 'Tewkesbury', 'Charnwood', 'Sheffield',\n",
       "       'Ashfield', 'North West Leicestershire', 'North East Derbyshire',\n",
       "       'Stroud', 'Shropshire', 'Telford and Wrekin', 'Horsham',\n",
       "       'City of London', 'Newcastle-under-Lyme', 'Stafford',\n",
       "       'Stoke-on-Trent', 'Arun', 'Lichfield', 'Sandwell', 'Birmingham',\n",
       "       'Amber Valley', 'Mole Valley', 'Bolsover', 'Rushcliffe',\n",
       "       'Wychavon', 'Gedling', 'Gloucester', 'Liverpool',\n",
       "       'Newark and Sherwood', 'Sefton', 'St. Helens', 'Worcester',\n",
       "       'Flintshire', 'Bassetlaw', 'Knowsley', 'Wyre Forest', 'Bromsgrove',\n",
       "       'Denbighshire', 'Herefordshire, County of', 'Rotherham',\n",
       "       'Chesterfield', 'Barnet', 'Monmouthshire', 'Cheltenham',\n",
       "       'Spelthorne', 'Sutton', 'Cheshire East',\n",
       "       'Cheshire West and Chester', 'Runnymede', 'Reigate and Banstead',\n",
       "       'Kingston upon Thames', 'Epsom and Ewell', 'Tandridge', 'Merton',\n",
       "       'Croydon', 'Stockport', 'Stratford-on-Avon', 'Northumberland',\n",
       "       'Walsall', 'Solihull', 'Mid Sussex', 'Waveney', 'Lincoln',\n",
       "       'Tonbridge and Malling', 'Redditch', 'Doncaster',\n",
       "       'Brighton and Hove', 'Tameside', 'High Peak', 'North Lincolnshire',\n",
       "       'Lewes', 'North Warwickshire', 'Gravesham',\n",
       "       'East Riding of Yorkshire', 'South Somerset', 'West Dorset',\n",
       "       'Sevenoaks', 'Medway', 'Nottingham', 'Tamworth', 'Warwick',\n",
       "       'Dartford', 'Surrey Heath', 'South Norfolk', 'Oldham',\n",
       "       'West Lindsey', 'Lambeth', 'North Norfolk', 'Breckland',\n",
       "       'Broxtowe', 'Staffordshire Moorlands', 'Worthing',\n",
       "       \"King's Lynn and West Norfolk\", 'Kirklees', 'Calderdale',\n",
       "       'Great Yarmouth', 'Crawley', 'East Devon', 'Mid Devon',\n",
       "       'St Edmundsbury', 'Mid Suffolk', 'East Cambridgeshire',\n",
       "       'Forest Heath', 'North Devon', 'Fenland', 'North Dorset',\n",
       "       'Bracknell Forest', 'Haringey', 'Coventry', 'Hounslow',\n",
       "       'Wakefield', 'Eastbourne', 'Selby', 'Wealden', 'West Somerset',\n",
       "       'Exeter', 'Kingston upon Hull, City of', 'Broadland', 'Norwich',\n",
       "       'Eden', 'Rugby', 'Barrow-in-Furness', 'Cannock Chase',\n",
       "       'South Lakeland', 'Carlisle', 'Isle of Anglesey', 'West Berkshire',\n",
       "       'Allerdale', 'Derby', 'South Derbyshire', 'Leicester',\n",
       "       'Hinckley and Bosworth', 'Gwynedd', 'County Durham', 'Bexley',\n",
       "       'West Devon', 'Torridge', 'Winchester', 'South Oxfordshire',\n",
       "       'Blaby', 'North Somerset', 'Bristol, City of', 'Wigan',\n",
       "       'Warrington', 'West Lancashire', 'Fylde', 'Manchester',\n",
       "       'North Tyneside', 'Newcastle upon Tyne', 'Rochdale', 'Barnsley',\n",
       "       'Gateshead', 'Sunderland', 'Redcar and Cleveland', 'Hartlepool',\n",
       "       'Bury', 'Ryedale', 'Harborough', 'Rutland', 'Scarborough',\n",
       "       'Harrogate', 'Melton', 'Hambleton', 'Richmondshire',\n",
       "       'South Tyneside', 'Pendle', 'Bolton', 'Bradford', 'Chorley',\n",
       "       'York', 'Leeds', 'New Forest', 'Preston', 'Powys', 'South Ribble',\n",
       "       'Wyre', 'Rossendale', 'Darlington', 'Stockton-on-Tees', 'Burnley',\n",
       "       'Craven', 'Christchurch', 'East Dorset', 'Weymouth and Portland',\n",
       "       'Middlesbrough', 'Conwy', 'Southampton', 'Blackpool', 'Fareham',\n",
       "       'Eastleigh', 'Lancaster', 'Purbeck', 'Gosport', 'Poole',\n",
       "       'Bournemouth', 'Wrexham', 'Pembrokeshire', 'Sedgemoor', 'Cornwall',\n",
       "       'Taunton Deane', 'Halton', 'Mansfield', 'Wirral',\n",
       "       'Carmarthenshire', 'Blackburn with Darwen', 'East Staffordshire',\n",
       "       'Ceredigion', 'Richmond upon Thames', 'Isles of Scilly',\n",
       "       'Derbyshire Dales', 'Adur', 'Rhondda Cynon Taf', 'Caerphilly',\n",
       "       'Ribble Valley', 'The Vale of Glamorgan', 'Bridgend',\n",
       "       'Neath Port Talbot', 'Merthyr Tydfil', 'Swansea', 'Cardiff',\n",
       "       'Blaenau Gwent', 'Newport', 'Hyndburn', 'Torfaen',\n",
       "       'East Hertfordshire', 'Stevenage', 'Uttlesford', 'St Albans',\n",
       "       'East Lindsey', 'Colchester', 'East Northamptonshire',\n",
       "       'Central Bedfordshire', 'Babergh', 'Braintree', 'Huntingdonshire',\n",
       "       'Suffolk Coastal', 'Ipswich', 'Peterborough', 'South Holland',\n",
       "       'Welwyn Hatfield', 'Boston', 'Watford', 'Maldon',\n",
       "       'South Cambridgeshire', 'Hertsmere', 'Three Rivers', 'Bedford',\n",
       "       'Brentwood', 'North Hertfordshire', 'Cambridge', 'Basildon',\n",
       "       'Harlow', 'Chelmsford', 'Tendring', 'Dacorum', 'Luton', 'Harrow',\n",
       "       'Havering', 'Islington', 'Brent', 'Greenwich', 'Castle Point',\n",
       "       'Aylesbury Vale', 'Milton Keynes', 'Kettering', 'Thurrock',\n",
       "       'Westminster', 'Camden', 'Hammersmith and Fulham',\n",
       "       'Kensington and Chelsea', 'Teignbridge', 'Southend-on-Sea', 'Hart',\n",
       "       'East Hampshire', 'Lewisham', 'Rochford', 'Wandsworth',\n",
       "       'North East Lincolnshire', 'Wokingham', 'Barking and Dagenham',\n",
       "       'Newham', 'Portsmouth', 'Tower Hamlets', 'Daventry', 'Corby',\n",
       "       'Rushmoor', 'South Northamptonshire', 'Wellingborough', 'Hackney',\n",
       "       'Torbay', 'Northampton', 'Havant', 'Reading', 'Swale', 'Shepway',\n",
       "       'Hastings', 'Bromley', 'Tunbridge Wells', 'Maidstone', 'Cherwell',\n",
       "       'Oadby and Wigston', 'Rother', 'Canterbury', 'Ashford', 'Thanet',\n",
       "       'Dover', 'Nuneaton and Bedworth'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load full dataset\n",
    "full_gdf = gpd.read_file('./OpenMapping-gb-v1_gpkg/gpkg/ssx_openmapping_gb_v1.gpkg',\n",
    "                    ignore_fields=ignore_fields)\n",
    "included_places = full_gdf['lad11nm'].unique()\n",
    "included_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "id": "8tKbyZGIE_8i",
    "outputId": "8307f1d2-0344-46cc-d09a-19c7e703d215"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_places' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m osmnx_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_gdf\u001b[39m(place\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_places\u001b[49m[\u001b[38;5;241m0\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m#(W, S, E, N)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124;03m\"\"\"Geodataframe (gdf) loader with caching\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m place \u001b[38;5;129;01min\u001b[39;00m included_places:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Retrieve matching rows corresponding to the Local Authority\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_places' is not defined"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "# Data processing parameters\n",
    "radii = { # metres\n",
    "    '2km': 2000,\n",
    "    '10km': 10000,\n",
    "    '100km': 100000\n",
    "}\n",
    "radius = '2km' # for larger radii either turn off boundary masking or widen bbox\n",
    "modifier = 'rank'\n",
    "geoms = 2\n",
    "classes = 0\n",
    "osmnx_buffer = 10000\n",
    "\n",
    "def load_gdf(place=training_places[0], verbose=False): #(W, S, E, N)\n",
    "    \"\"\"Geodataframe (gdf) loader with caching\"\"\"\n",
    "    if place in included_places:\n",
    "        # Retrieve matching rows corresponding to the Local Authority\n",
    "        gdf = full_gdf.query(f'lad11nm == \"{place}\"').copy()\n",
    "    elif place == full_dataset_label:\n",
    "        # Read full dataset without boundaries\n",
    "        gdf = full_gdf.copy()\n",
    "    else:\n",
    "        # Load gdf from osmnx (for testing only, graph will lack target attr)\n",
    "        # Actually uses the Nominatim API:\n",
    "        # https://nominatim.org/release-docs/latest/api/Overview/\n",
    "        g = ox.graph.graph_from_place(place, buffer_dist=osmnx_buffer)\n",
    "        g = ox.projection.project_graph(g)\n",
    "        gdf = ox.utils_graph.graph_to_gdfs(g, nodes=False)\n",
    "        gdf = gdf.rename(columns={'length': 'metres'})\n",
    "        return gdf\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{gdf.size} geometries retrieved from {place}')\n",
    "\n",
    "    loaded_gdfs[place] = gdf\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def add_boundary_mask(gdf, place, rad, verbose=False):\n",
    "    \"\"\"Add flag column to indicate geometries within 'rad' of the bounding box\n",
    "       No masking if loading full dataset\"\"\"\n",
    "    if place == full_dataset_label:\n",
    "        s = True\n",
    "        masked_count = 0\n",
    "    else:\n",
    "        if place in bboxes:\n",
    "            # Use defined boundaries\n",
    "            S, W, N, E = proj_and_reorder_bounds(bboxes[place])\n",
    "        else:\n",
    "            # Use total bounds (For osmnx-loaded graphs)\n",
    "            W, S, E, N = gdf.geometry.total_bounds\n",
    "        boundary_line = LineString([(S, W), (N, W), (N, E), (S, E), (S, W)])\n",
    "        boundary = boundary_line.buffer(radii[rad])\n",
    "        s = gdf.geometry.disjoint(boundary)\n",
    "        masked_count = gdf.size - s.sum()\n",
    "    if verbose:\n",
    "        print(f'Masking {masked_count} out of {gdf.size} geometries within boundary buffer')\n",
    "    gdf['boundary_mask'] = s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJAhcotL7n8J"
   },
   "source": [
    "# Construct SSx Graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTKO9ZGc0J40",
    "outputId": "fbe0c8c6-780a-4548-d791-2a3b3b5fd04d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from itertools import chain\n",
    "from virtual_node import VirtualNode\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.transforms import OneHotDegree, NormalizeFeatures\n",
    "from torch_geometric.data import Batch, InMemoryDataset, download_url, extract_zip\n",
    "\n",
    "# For one hot encoding of node degrees\n",
    "max_deg = 16\n",
    "\n",
    "def process_graph(g, feature_fields=[]):\n",
    "    node_fields = set(chain.from_iterable(d.keys() for *_, d in g.nodes(data=True)))\n",
    "    to_delete_fields = [field for field in node_fields if field not in feature_fields]\n",
    "    for _, d in g.nodes(data=True):\n",
    "        # remove non float-attributes\n",
    "        for attr in to_delete_fields:\n",
    "            del d[attr]\n",
    "    return g\n",
    "\n",
    "def load_graph(place, feature_fields=[], reload=True, verbose=False):\n",
    "  if verbose:\n",
    "    print(f'Loading graph of {place}...')\n",
    "  key = (place)\n",
    "  if key in loaded_graphs and reload:\n",
    "    g = loaded_graphs[key]\n",
    "    if verbose:\n",
    "        print('Loaded existing graph.')\n",
    "  else:\n",
    "    gdf = load_gdf(place, verbose=verbose)\n",
    "    G = momepy.gdf_to_nx(gdf, approach='dual')\n",
    "    G = process_graph(G, feature_fields)\n",
    "    if verbose:\n",
    "      print(f'Generated graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "    node_attrs = set(chain.from_iterable(d.keys() for *_, d in G.nodes(data=True)))\n",
    "    edge_attrs = set(chain.from_iterable(d.keys() for *_, d in G.edges(data=True)))\n",
    "    if verbose:\n",
    "        # List node and edge attributes\n",
    "        print(f'Node attributes: {node_attrs}')\n",
    "        print(f'Edge Attributes: {edge_attrs}')\n",
    "    \n",
    "    # If no node attributes, node degree will be added later\n",
    "    # Edge attribute (angle) is always included due to momepy\n",
    "    if len(node_attrs) > 0:\n",
    "        g = from_networkx(G, group_node_attrs=list(node_attrs), group_edge_attrs=list(edge_attrs))\n",
    "    else:\n",
    "        g = from_networkx(G, group_edge_attrs=list(edge_attrs))\n",
    "    loaded_graphs[key] = g\n",
    "  return g\n",
    "\n",
    "def print_graph_properties(g):\n",
    "    # Gather some statistics about the graph.\n",
    "    print(f'Number of nodes: {g.num_nodes}')\n",
    "    print(f'Number of edges: {g.num_edges}')\n",
    "    print(f'Average node degree: {g.num_edges / g.num_nodes:.2f}')\n",
    "    print(f'Number of training nodes: {g.train_mask.sum()}')\n",
    "    print(f'Training node label rate: {int(g.train_mask.sum()) / g.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {g.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {g.has_self_loops()}')\n",
    "    print(f'Is undirected: {g.is_undirected()}')\n",
    "\n",
    "def load_graphs(df, la_col_name, virtual_node=False,\n",
    "                feature_fields=[], target_attrs=[]):\n",
    "    print('Test')\n",
    "    data_list = []\n",
    "    la_names = df[la_col_name].unique()\n",
    "    for place in included_places:\n",
    "        if place in la_names:\n",
    "            g = load_graph(place, feature_fields, verbose=True)\n",
    "            \n",
    "            # Normalize node features\n",
    "            g = NormalizeFeatures()(g)\n",
    "            \n",
    "            # Add virtual node\n",
    "            if virtual_node:\n",
    "                g = VirtualNode()(g)\n",
    "            \n",
    "            # One hot encode degree if no node features\n",
    "            if g.num_node_features == 0:\n",
    "                g = OneHotDegree(max_deg)(g)\n",
    "            \n",
    "            # Get row corresponding to place\n",
    "            row = df.query(f'`{la_col_name}` == \"{place}\"')\n",
    "\n",
    "            # Obtain target attribute(s)\n",
    "            ys = []\n",
    "            for target in target_attrs:\n",
    "                ys.append(row.iloc[0][target])\n",
    "            \n",
    "            # Set graph target attribute\n",
    "            g.y = torch.tensor([ys])\n",
    "            data_list.append(g)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Authority District code (2013)</th>\n",
       "      <th>Local Authority District name (2013)</th>\n",
       "      <th>IMD - Average rank</th>\n",
       "      <th>IMD - Average score</th>\n",
       "      <th>Income - Average rank</th>\n",
       "      <th>Income - Average score</th>\n",
       "      <th>Employment - Average rank</th>\n",
       "      <th>Employment - Average score</th>\n",
       "      <th>Education, Skills and Training - Average rank</th>\n",
       "      <th>Education, Skills and Training - Average score</th>\n",
       "      <th>...</th>\n",
       "      <th>Crime - Average rank</th>\n",
       "      <th>Crime - Average score</th>\n",
       "      <th>Barriers to Housing and Services - Average rank</th>\n",
       "      <th>Barriers to Housing and Services - Average score</th>\n",
       "      <th>Living Environment - Average rank</th>\n",
       "      <th>Living Environment - Average score</th>\n",
       "      <th>Income Deprivation Affecting Children Index (IDACI) - Average rank</th>\n",
       "      <th>Income Deprivation Affecting Children Index (IDACI) - Average score</th>\n",
       "      <th>Income Deprivation Affecting Older People (IDAOPI) - Average rank</th>\n",
       "      <th>Income Deprivation Affecting Older People (IDAOPI) - Average score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>21886.60</td>\n",
       "      <td>33.178</td>\n",
       "      <td>22711.37</td>\n",
       "      <td>0.239</td>\n",
       "      <td>24876.54</td>\n",
       "      <td>0.211</td>\n",
       "      <td>20101.48</td>\n",
       "      <td>30.510</td>\n",
       "      <td>...</td>\n",
       "      <td>17360.29</td>\n",
       "      <td>0.078</td>\n",
       "      <td>8132.08</td>\n",
       "      <td>13.128</td>\n",
       "      <td>6723.11</td>\n",
       "      <td>8.260</td>\n",
       "      <td>22579.19</td>\n",
       "      <td>0.307</td>\n",
       "      <td>20692.34</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>23562.71</td>\n",
       "      <td>40.216</td>\n",
       "      <td>23472.98</td>\n",
       "      <td>0.268</td>\n",
       "      <td>24731.49</td>\n",
       "      <td>0.216</td>\n",
       "      <td>22728.01</td>\n",
       "      <td>40.640</td>\n",
       "      <td>...</td>\n",
       "      <td>23468.17</td>\n",
       "      <td>0.633</td>\n",
       "      <td>13789.08</td>\n",
       "      <td>18.316</td>\n",
       "      <td>10521.28</td>\n",
       "      <td>12.907</td>\n",
       "      <td>24366.41</td>\n",
       "      <td>0.357</td>\n",
       "      <td>19587.43</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>19716.01</td>\n",
       "      <td>28.567</td>\n",
       "      <td>20485.88</td>\n",
       "      <td>0.204</td>\n",
       "      <td>23187.19</td>\n",
       "      <td>0.186</td>\n",
       "      <td>19185.28</td>\n",
       "      <td>27.875</td>\n",
       "      <td>...</td>\n",
       "      <td>16326.90</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>8251.14</td>\n",
       "      <td>12.863</td>\n",
       "      <td>6150.27</td>\n",
       "      <td>7.923</td>\n",
       "      <td>21220.74</td>\n",
       "      <td>0.273</td>\n",
       "      <td>16755.19</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>17046.82</td>\n",
       "      <td>24.625</td>\n",
       "      <td>17740.60</td>\n",
       "      <td>0.177</td>\n",
       "      <td>19639.45</td>\n",
       "      <td>0.156</td>\n",
       "      <td>16660.09</td>\n",
       "      <td>24.637</td>\n",
       "      <td>...</td>\n",
       "      <td>13642.44</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>12889.76</td>\n",
       "      <td>17.844</td>\n",
       "      <td>5674.10</td>\n",
       "      <td>7.068</td>\n",
       "      <td>18134.25</td>\n",
       "      <td>0.226</td>\n",
       "      <td>15487.05</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>17423.32</td>\n",
       "      <td>23.639</td>\n",
       "      <td>18141.06</td>\n",
       "      <td>0.168</td>\n",
       "      <td>20106.98</td>\n",
       "      <td>0.150</td>\n",
       "      <td>16385.06</td>\n",
       "      <td>22.569</td>\n",
       "      <td>...</td>\n",
       "      <td>19412.70</td>\n",
       "      <td>0.224</td>\n",
       "      <td>7457.80</td>\n",
       "      <td>12.346</td>\n",
       "      <td>9002.91</td>\n",
       "      <td>10.710</td>\n",
       "      <td>18234.49</td>\n",
       "      <td>0.215</td>\n",
       "      <td>15816.84</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>E09000029</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>12063.57</td>\n",
       "      <td>14.579</td>\n",
       "      <td>13697.34</td>\n",
       "      <td>0.111</td>\n",
       "      <td>12238.97</td>\n",
       "      <td>0.086</td>\n",
       "      <td>11629.13</td>\n",
       "      <td>12.576</td>\n",
       "      <td>...</td>\n",
       "      <td>18649.65</td>\n",
       "      <td>0.163</td>\n",
       "      <td>15338.03</td>\n",
       "      <td>19.784</td>\n",
       "      <td>16296.96</td>\n",
       "      <td>19.062</td>\n",
       "      <td>15248.39</td>\n",
       "      <td>0.159</td>\n",
       "      <td>12180.12</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>E09000030</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>25486.40</td>\n",
       "      <td>35.657</td>\n",
       "      <td>25624.12</td>\n",
       "      <td>0.253</td>\n",
       "      <td>19994.04</td>\n",
       "      <td>0.138</td>\n",
       "      <td>16654.45</td>\n",
       "      <td>18.831</td>\n",
       "      <td>...</td>\n",
       "      <td>25365.55</td>\n",
       "      <td>0.762</td>\n",
       "      <td>29089.59</td>\n",
       "      <td>37.748</td>\n",
       "      <td>27007.76</td>\n",
       "      <td>39.823</td>\n",
       "      <td>28983.38</td>\n",
       "      <td>0.393</td>\n",
       "      <td>30626.21</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>E09000031</td>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>23744.54</td>\n",
       "      <td>30.190</td>\n",
       "      <td>22759.13</td>\n",
       "      <td>0.193</td>\n",
       "      <td>19861.43</td>\n",
       "      <td>0.128</td>\n",
       "      <td>17236.42</td>\n",
       "      <td>18.693</td>\n",
       "      <td>...</td>\n",
       "      <td>27260.33</td>\n",
       "      <td>0.860</td>\n",
       "      <td>29428.98</td>\n",
       "      <td>38.435</td>\n",
       "      <td>25539.47</td>\n",
       "      <td>35.439</td>\n",
       "      <td>23811.53</td>\n",
       "      <td>0.270</td>\n",
       "      <td>22673.23</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>E09000032</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>15774.73</td>\n",
       "      <td>18.295</td>\n",
       "      <td>15537.30</td>\n",
       "      <td>0.127</td>\n",
       "      <td>11170.92</td>\n",
       "      <td>0.079</td>\n",
       "      <td>7358.71</td>\n",
       "      <td>7.250</td>\n",
       "      <td>...</td>\n",
       "      <td>22396.34</td>\n",
       "      <td>0.439</td>\n",
       "      <td>19644.23</td>\n",
       "      <td>24.595</td>\n",
       "      <td>26639.14</td>\n",
       "      <td>38.202</td>\n",
       "      <td>17873.64</td>\n",
       "      <td>0.207</td>\n",
       "      <td>21646.04</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>E09000033</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>21304.43</td>\n",
       "      <td>27.686</td>\n",
       "      <td>18162.63</td>\n",
       "      <td>0.170</td>\n",
       "      <td>14749.10</td>\n",
       "      <td>0.109</td>\n",
       "      <td>8805.94</td>\n",
       "      <td>8.793</td>\n",
       "      <td>...</td>\n",
       "      <td>22177.90</td>\n",
       "      <td>0.443</td>\n",
       "      <td>27914.83</td>\n",
       "      <td>35.103</td>\n",
       "      <td>30685.46</td>\n",
       "      <td>54.767</td>\n",
       "      <td>22220.52</td>\n",
       "      <td>0.287</td>\n",
       "      <td>20532.73</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Local Authority District code (2013) Local Authority District name (2013)  \\\n",
       "0                              E06000001                           Hartlepool   \n",
       "1                              E06000002                        Middlesbrough   \n",
       "2                              E06000003                 Redcar and Cleveland   \n",
       "3                              E06000004                     Stockton-on-Tees   \n",
       "4                              E06000005                           Darlington   \n",
       "..                                   ...                                  ...   \n",
       "321                            E09000029                               Sutton   \n",
       "322                            E09000030                        Tower Hamlets   \n",
       "323                            E09000031                       Waltham Forest   \n",
       "324                            E09000032                           Wandsworth   \n",
       "325                            E09000033                          Westminster   \n",
       "\n",
       "     IMD - Average rank  IMD - Average score  Income - Average rank  \\\n",
       "0              21886.60               33.178               22711.37   \n",
       "1              23562.71               40.216               23472.98   \n",
       "2              19716.01               28.567               20485.88   \n",
       "3              17046.82               24.625               17740.60   \n",
       "4              17423.32               23.639               18141.06   \n",
       "..                  ...                  ...                    ...   \n",
       "321            12063.57               14.579               13697.34   \n",
       "322            25486.40               35.657               25624.12   \n",
       "323            23744.54               30.190               22759.13   \n",
       "324            15774.73               18.295               15537.30   \n",
       "325            21304.43               27.686               18162.63   \n",
       "\n",
       "     Income - Average score  Employment - Average rank  \\\n",
       "0                     0.239                   24876.54   \n",
       "1                     0.268                   24731.49   \n",
       "2                     0.204                   23187.19   \n",
       "3                     0.177                   19639.45   \n",
       "4                     0.168                   20106.98   \n",
       "..                      ...                        ...   \n",
       "321                   0.111                   12238.97   \n",
       "322                   0.253                   19994.04   \n",
       "323                   0.193                   19861.43   \n",
       "324                   0.127                   11170.92   \n",
       "325                   0.170                   14749.10   \n",
       "\n",
       "     Employment - Average score  \\\n",
       "0                         0.211   \n",
       "1                         0.216   \n",
       "2                         0.186   \n",
       "3                         0.156   \n",
       "4                         0.150   \n",
       "..                          ...   \n",
       "321                       0.086   \n",
       "322                       0.138   \n",
       "323                       0.128   \n",
       "324                       0.079   \n",
       "325                       0.109   \n",
       "\n",
       "     Education, Skills and Training - Average rank  \\\n",
       "0                                         20101.48   \n",
       "1                                         22728.01   \n",
       "2                                         19185.28   \n",
       "3                                         16660.09   \n",
       "4                                         16385.06   \n",
       "..                                             ...   \n",
       "321                                       11629.13   \n",
       "322                                       16654.45   \n",
       "323                                       17236.42   \n",
       "324                                        7358.71   \n",
       "325                                        8805.94   \n",
       "\n",
       "     Education, Skills and Training - Average score  ...  \\\n",
       "0                                            30.510  ...   \n",
       "1                                            40.640  ...   \n",
       "2                                            27.875  ...   \n",
       "3                                            24.637  ...   \n",
       "4                                            22.569  ...   \n",
       "..                                              ...  ...   \n",
       "321                                          12.576  ...   \n",
       "322                                          18.831  ...   \n",
       "323                                          18.693  ...   \n",
       "324                                           7.250  ...   \n",
       "325                                           8.793  ...   \n",
       "\n",
       "     Crime - Average rank  Crime - Average score  \\\n",
       "0                17360.29                  0.078   \n",
       "1                23468.17                  0.633   \n",
       "2                16326.90                 -0.013   \n",
       "3                13642.44                 -0.263   \n",
       "4                19412.70                  0.224   \n",
       "..                    ...                    ...   \n",
       "321              18649.65                  0.163   \n",
       "322              25365.55                  0.762   \n",
       "323              27260.33                  0.860   \n",
       "324              22396.34                  0.439   \n",
       "325              22177.90                  0.443   \n",
       "\n",
       "     Barriers to Housing and Services - Average rank  \\\n",
       "0                                            8132.08   \n",
       "1                                           13789.08   \n",
       "2                                            8251.14   \n",
       "3                                           12889.76   \n",
       "4                                            7457.80   \n",
       "..                                               ...   \n",
       "321                                         15338.03   \n",
       "322                                         29089.59   \n",
       "323                                         29428.98   \n",
       "324                                         19644.23   \n",
       "325                                         27914.83   \n",
       "\n",
       "     Barriers to Housing and Services - Average score  \\\n",
       "0                                              13.128   \n",
       "1                                              18.316   \n",
       "2                                              12.863   \n",
       "3                                              17.844   \n",
       "4                                              12.346   \n",
       "..                                                ...   \n",
       "321                                            19.784   \n",
       "322                                            37.748   \n",
       "323                                            38.435   \n",
       "324                                            24.595   \n",
       "325                                            35.103   \n",
       "\n",
       "     Living Environment - Average rank  Living Environment - Average score  \\\n",
       "0                              6723.11                               8.260   \n",
       "1                             10521.28                              12.907   \n",
       "2                              6150.27                               7.923   \n",
       "3                              5674.10                               7.068   \n",
       "4                              9002.91                              10.710   \n",
       "..                                 ...                                 ...   \n",
       "321                           16296.96                              19.062   \n",
       "322                           27007.76                              39.823   \n",
       "323                           25539.47                              35.439   \n",
       "324                           26639.14                              38.202   \n",
       "325                           30685.46                              54.767   \n",
       "\n",
       "     Income Deprivation Affecting Children Index (IDACI) - Average rank  \\\n",
       "0                                             22579.19                    \n",
       "1                                             24366.41                    \n",
       "2                                             21220.74                    \n",
       "3                                             18134.25                    \n",
       "4                                             18234.49                    \n",
       "..                                                 ...                    \n",
       "321                                           15248.39                    \n",
       "322                                           28983.38                    \n",
       "323                                           23811.53                    \n",
       "324                                           17873.64                    \n",
       "325                                           22220.52                    \n",
       "\n",
       "     Income Deprivation Affecting Children Index (IDACI) - Average score  \\\n",
       "0                                                0.307                     \n",
       "1                                                0.357                     \n",
       "2                                                0.273                     \n",
       "3                                                0.226                     \n",
       "4                                                0.215                     \n",
       "..                                                 ...                     \n",
       "321                                              0.159                     \n",
       "322                                              0.393                     \n",
       "323                                              0.270                     \n",
       "324                                              0.207                     \n",
       "325                                              0.287                     \n",
       "\n",
       "     Income Deprivation Affecting Older People (IDAOPI) - Average rank  \\\n",
       "0                                             20692.34                   \n",
       "1                                             19587.43                   \n",
       "2                                             16755.19                   \n",
       "3                                             15487.05                   \n",
       "4                                             15816.84                   \n",
       "..                                                 ...                   \n",
       "321                                           12180.12                   \n",
       "322                                           30626.21                   \n",
       "323                                           22673.23                   \n",
       "324                                           21646.04                   \n",
       "325                                           20532.73                   \n",
       "\n",
       "     Income Deprivation Affecting Older People (IDAOPI) - Average score  \n",
       "0                                                0.244                   \n",
       "1                                                0.253                   \n",
       "2                                                0.189                   \n",
       "3                                                0.179                   \n",
       "4                                                0.176                   \n",
       "..                                                 ...                   \n",
       "321                                              0.129                   \n",
       "322                                              0.497                   \n",
       "323                                              0.251                   \n",
       "324                                              0.234                   \n",
       "325                                              0.249                   \n",
       "\n",
       "[326 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_row(row):\n",
    "    code1, code2 = row.iloc[0]['Code'].split('/')\n",
    "    name1, name2 = row.iloc[0]['Name'].split('/')\n",
    "    row1 = row.copy()\n",
    "    row1['Code'] = code1\n",
    "    row1['Name'] = name1\n",
    "    row2 = row.copy()\n",
    "    row2['Code'] = code2\n",
    "    row2['Name'] = name2\n",
    "    return pd.concat([row1, row2])\n",
    "    \n",
    "def load_city_cluster_df():\n",
    "    df = pd.read_excel('datasets/clustermembershipv2.xls', sheet_name='Clusters by Local Authority', header=9)\n",
    "    df = df[['Code', 'Name', 'Supergroup Code', 'Group Code', 'Subgroup Code']]\n",
    "    \n",
    "    # Remove last two lines (empty rows)\n",
    "    df = df[:-2]\n",
    "    \n",
    "    # Unmerge London/Westminster and Cornwall/Isles of Scilly\n",
    "    lon_wes_row = df.query('Name == \"City of London/Westminster\"')\n",
    "    corn_isles_row = df.query('Name == \"Cornwall/Isles of Scilly\"')\n",
    "    df = pd.concat([df, split_row(lon_wes_row), split_row(corn_isles_row)])\n",
    "        \n",
    "    # Turn categorical data into numeric\n",
    "    df['Supergroup Code'] = df['Supergroup Code'].astype('category')\n",
    "    df['Group Code'] = df['Group Code'].astype('category')\n",
    "    df['Subgroup Code'] = df['Subgroup Code'].astype('category')\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    # subtract one to make it 0 indexed\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_gva_df(): \n",
    "    gva_df = pd.read_excel('datasets/regionalgvaibylainuk.xls', sheet_name='Total GVA', header=2)\n",
    "    return gva_df\n",
    "\n",
    "def load_deprivation_df():\n",
    "    sheets_and_cols = {\n",
    "        'IMD': 'IMD',\n",
    "        'Income': 'Income',\n",
    "        'Employment': 'Employment',\n",
    "        'Education': 'Education, Skills and Training',\n",
    "        'Health': 'Health Deprivation and Disability',\n",
    "        'Crime': 'Crime',\n",
    "        'Barriers': 'Barriers to Housing and Services',\n",
    "        'Living': 'Living Environment',\n",
    "        'IDACI': 'Income Deprivation Affecting Children Index (IDACI)',\n",
    "        'IDAOPI': 'Income Deprivation Affecting Older People (IDAOPI)',\n",
    "    }\n",
    "    id_cols = ['Local Authority District code (2013)', 'Local Authority District name (2013)']\n",
    "    dep_metrics = ['Average rank', 'Average score']\n",
    "    \n",
    "    out_df = None\n",
    "    for sheet in sheets_and_cols:\n",
    "        dep_df = pd.read_excel('datasets/File_10_ID2015_Local_Authority_District_Summaries.xlsx',\n",
    "                               sheet_name=sheet, header=0)\n",
    "        cols_to_read = id_cols + [f'{sheets_and_cols[sheet]} - {metric}' for metric in dep_metrics]  \n",
    "        dep_df = dep_df[cols_to_read]\n",
    "        if out_df is not None:\n",
    "            out_df = out_df.merge(dep_df, on=id_cols)\n",
    "        else:\n",
    "            out_df = dep_df\n",
    "    return out_df\n",
    "    \n",
    "\n",
    "\n",
    "# gva_data_list = load_graphs(load_gva_df(), 'LA_name', target_attrs=[2015])\n",
    "# torch.save(gva_data_list, 'datasets/ssx_gva_dataset.pt')\n",
    "\n",
    "# city_cluster_data_list = load_graphs(load_city_cluster_df(), 'Name', feature_fields=all_feature_fields,\n",
    "#                             target_attrs=['Supergroup Code', 'Group Code', 'Subgroup Code'])\n",
    "\n",
    "# torch.save(city_cluster_data_list, 'datasets/ssx_cities_dataset_norm.pt')\n",
    "\n",
    "df = load_deprivation_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9wO1_DeQXEh"
   },
   "source": [
    "## Data Processing & Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ehwALurUGclK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved dataset and process into dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 277\n",
      "Number of test graphs: 70\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 1852666], x=[320225, 17], edge_attr=[1852666, 1], edge_type=[1852666], y=[64, 3], batch=[320225], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 1997694], x=[344754, 17], edge_attr=[1997694, 1], edge_type=[1997694], y=[64, 3], batch=[344754], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 2076266], x=[345558, 17], edge_attr=[2076266, 1], edge_type=[2076266], y=[64, 3], batch=[345558], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 1849294], x=[316517, 17], edge_attr=[1849294, 1], edge_type=[1849294], y=[64, 3], batch=[316517], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 21\n",
      "DataBatch(edge_index=[2, 443314], x=[77694, 17], edge_attr=[443314, 1], edge_type=[443314], y=[21, 3], batch=[77694], ptr=[22])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "def print_dataset_stats(dataset):\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    data = dataset[0]  # Get the first graph object.\n",
    "    print()\n",
    "    print(data)\n",
    "    print('=============================================================')\n",
    "\n",
    "    # Gather some statistics about the first graph.\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of node features: {data.num_node_features}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Number of edge features: {data.num_edge_features}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "def process_dataset(dataset, split=0.8, batch_size=64, verbose=False):\n",
    "    # Train-test split\n",
    "    idx = torch.randperm(len(dataset))\n",
    "    split_idx = math.floor(split * len(dataset))\n",
    "    train_idx = idx[:split_idx]\n",
    "    test_idx = idx[split_idx:]\n",
    "    train_dataset = [dataset[i] for i in train_idx]\n",
    "    test_dataset = [dataset[i] for i in test_idx]\n",
    "    if verbose:\n",
    "        print(f'Number of training graphs: {len(train_dataset)}')\n",
    "        print(f'Number of test graphs: {len(test_dataset)}')\n",
    "    \n",
    "    # Load graphs into dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    if verbose:\n",
    "        for step, data in enumerate(train_loader):\n",
    "            print(f'Step {step + 1}:')\n",
    "            print('=======')\n",
    "            print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "            print(data)\n",
    "            print()\n",
    "\n",
    "    return dataset, train_loader, test_loader\n",
    "\n",
    "def get_data_stats(dataset, target_index):\n",
    "    num_node_features = dataset[0].num_node_features\n",
    "    try:\n",
    "        targets = [data.y[0][target_index].item() for data in dataset]\n",
    "    except IndexError:\n",
    "        return num_node_features, 1\n",
    "    return num_node_features, max(targets) + 1 # 0-indexed\n",
    "\n",
    "\n",
    "dataset = torch.load('datasets/ssx_cities_dataset_normalized.pt')\n",
    "dataset, train_loader, test_loader = process_dataset(dataset, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS with Mean SSx Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "num_node_features = dataset[0].num_node_features\n",
    "X = np.zeros((len(dataset), num_node_features))\n",
    "y = np.zeros(len(dataset))\n",
    "\n",
    "# Get mean vectors for each graph\n",
    "for i, graph in enumerate(dataset):\n",
    "    X[i] = graph.x.mean(dim=0) # shape [17]\n",
    "    y[i] = graph.y[0]\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(reg.score(X, y)) # transductive\n",
    "pd.DataFrame({ 'features': feature_fields, 'coefficients': reg.coef_ })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS with Link Pred Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Nuneaton and Bedworth'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('datasets/link_pred_metrics_1_iter.pt').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plymouth', 'Slough', 'Windsor and Maidenhead', 'Isle of Wight', 'Chiltern', 'South Bucks', 'Wycombe', 'Copeland', 'South Hams', 'Oxford', 'Mendip', 'Ealing', 'Enfield', 'Hillingdon', 'Waltham Forest']\n",
      "R score for IMD - Average rank: 0.20607476068801267\n",
      "R score for IMD - Average score: 0.23636080015338445\n",
      "R score for Income - Average rank: 0.21490914834506458\n",
      "R score for Income - Average score: 0.2674242831754361\n",
      "R score for Employment - Average rank: 0.04613619879567721\n",
      "R score for Employment - Average score: 0.039374725044619585\n",
      "R score for Education, Skills and Training - Average rank: 0.05273854700808622\n",
      "R score for Education, Skills and Training - Average score: 0.04289300683985364\n",
      "R score for Health Deprivation and Disability - Average rank: 0.13478310645107694\n",
      "R score for Health Deprivation and Disability - Average score: 0.13698660458567802\n",
      "R score for Crime - Average rank: 0.6239643041357243\n",
      "R score for Crime - Average score: 0.6318451698500016\n",
      "R score for Barriers to Housing and Services - Average rank: 0.2291340286251471\n",
      "R score for Barriers to Housing and Services - Average score: 0.1575293507465344\n",
      "R score for Living Environment - Average rank: 0.22189575628000668\n",
      "R score for Living Environment - Average score: 0.16171568051129437\n",
      "R score for Income Deprivation Affecting Children Index (IDACI) - Average rank: 0.38268142582977127\n",
      "R score for Income Deprivation Affecting Children Index (IDACI) - Average score: 0.4299337528041822\n",
      "R score for Income Deprivation Affecting Older People (IDAOPI) - Average rank: 0.35030269664288693\n",
      "R score for Income Deprivation Affecting Older People (IDAOPI) - Average score: 0.38036174366752473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'IMD - Average rank': 0.20607476068801267,\n",
       " 'IMD - Average score': 0.23636080015338445,\n",
       " 'Income - Average rank': 0.21490914834506458,\n",
       " 'Income - Average score': 0.2674242831754361,\n",
       " 'Employment - Average rank': 0.04613619879567721,\n",
       " 'Employment - Average score': 0.039374725044619585,\n",
       " 'Education, Skills and Training - Average rank': 0.05273854700808622,\n",
       " 'Education, Skills and Training - Average score': 0.04289300683985364,\n",
       " 'Health Deprivation and Disability - Average rank': 0.13478310645107694,\n",
       " 'Health Deprivation and Disability - Average score': 0.13698660458567802,\n",
       " 'Crime - Average rank': 0.6239643041357243,\n",
       " 'Crime - Average score': 0.6318451698500016,\n",
       " 'Barriers to Housing and Services - Average rank': 0.2291340286251471,\n",
       " 'Barriers to Housing and Services - Average score': 0.1575293507465344,\n",
       " 'Living Environment - Average rank': 0.22189575628000668,\n",
       " 'Living Environment - Average score': 0.16171568051129437,\n",
       " 'Income Deprivation Affecting Children Index (IDACI) - Average rank': 0.38268142582977127,\n",
       " 'Income Deprivation Affecting Children Index (IDACI) - Average score': 0.4299337528041822,\n",
       " 'Income Deprivation Affecting Older People (IDAOPI) - Average rank': 0.35030269664288693,\n",
       " 'Income Deprivation Affecting Older People (IDAOPI) - Average score': 0.38036174366752473}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def link_pred_regression(link_pred_metric):\n",
    "    dep_df = load_deprivation_df()\n",
    "    link_pred_dataset = torch.load('datasets/link_pred_metrics_1_iter.pt')\n",
    "    \n",
    "    id_cols = ['Local Authority District name (2013)', 'Local Authority District code (2013)']\n",
    "    scores = {}\n",
    "    valid_places = [place for place in dep_df[id_cols[0]] \\\n",
    "                    if place in link_pred_dataset]\n",
    "    print(valid_places)\n",
    "    \n",
    "    if link_pred_metric in list(link_pred_dataset.values())[0]:\n",
    "        # Retrieve the run-level results\n",
    "        X = [link_pred_dataset[place][link_pred_metric] for place in valid_places]\n",
    "    else:\n",
    "        # Retrieve and obtain the average inductive result over test places\n",
    "        X = []\n",
    "        for train_place in valid_places:\n",
    "            metric_acc = []\n",
    "            for test_place in link_pred_dataset[train_place]['tests']:\n",
    "                metric = link_pred_dataset[train_place]['tests'][test_place][link_pred_metric]\n",
    "                metric_acc.append(metric)\n",
    "            X.append([sum(metric_acc) / len(metric_acc)])\n",
    "    \n",
    "    # Obtain deprivation statistics corresponding to retrieved metrics\n",
    "    dep_df = dep_df.query(f'`{id_cols[0]}` == @valid_places')\n",
    "    metrics = [col for col in dep_df.columns\n",
    "               if col not in id_cols]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        Y = dep_df[metric].values\n",
    "        reg = LinearRegression().fit(X, Y)\n",
    "        score = reg.score(X, Y)\n",
    "        scores[metric] = score\n",
    "        print(f'R score for {metric}: {score}')\n",
    "    return scores\n",
    "\n",
    "scores = link_pred_regression('train_auc')                            \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 348 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 348 samples in 0.008s...\n",
      "[t-SNE] Computed conditional probabilities for sample 348 / 348\n",
      "[t-SNE] Mean sigma: 2407881.875207\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 43.949558\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.132745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.6021e+02, 1.5132e+03, 1.6610e+02,  ..., 4.1916e+00, 4.5222e+05,\n",
       "         8.7298e+04],\n",
       "        [1.7607e+02, 1.1871e+03, 1.5061e+02,  ..., 5.6303e+00, 4.8446e+05,\n",
       "         1.9388e+05],\n",
       "        [1.1940e+02, 5.6643e+03, 4.7075e+02,  ..., 5.5866e+00, 5.3290e+05,\n",
       "         1.9539e+05],\n",
       "        ...,\n",
       "        [1.2878e+02, 4.2688e+03, 3.7005e+02,  ..., 4.7765e+00, 6.3555e+05,\n",
       "         1.6788e+05],\n",
       "        [1.8291e+02, 1.3880e+03, 1.5450e+02,  ..., 5.1571e+00, 6.3056e+05,\n",
       "         1.4935e+05],\n",
       "        [1.3168e+02, 2.0656e+03, 2.3951e+02,  ..., 5.1180e+00, 4.3551e+05,\n",
       "         2.8955e+05]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original features\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(dataset, include_feats):\n",
    "    feat_idx = torch.tensor([feats.index(feat) for feat in include_feats])\n",
    "    features = [torch.index_select(data.x, 1, feat_idx) for data in dataset]\n",
    "    \n",
    "    avg_feats = [torch.mean(feats, dim=0) for feats in features]\n",
    "    avg_feats = torch.stack(avg_feats)\n",
    "    tsne = TSNE(learning_rate='auto', verbose=1).fit_transform(avg_feats)\n",
    "\n",
    "    plt.scatter(tsne[:, 0], tsne[:, 1])\n",
    "    return avg_feats\n",
    "\n",
    "include_feats = rank_fields # CHANGE THIS\n",
    "dataset = torch.load('datasets/ssx_dataset.pt')\n",
    "tsne(dataset, feats)\n",
    "\n",
    "# Embedded features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard MLP For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Module, Sequential, ModuleList, Conv1d, MaxPool1d\n",
    "from torch.nn import Identity, ReLU, Sigmoid, Tanh, LogSoftmax\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GCN2Conv, GraphConv, DynamicEdgeConv, TopKPooling, MLP\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "from torch_geometric.nn import global_sort_pool as gsp\n",
    "\n",
    "activations = {\n",
    "    'none': (lambda x: x),\n",
    "    'relu': F.relu,\n",
    "    'sigmoid': F.sigmoid,\n",
    "    'tanh': F.tanh,\n",
    "    'logsoft': (lambda x: F.log_softmax(x, dim=-1))\n",
    "}\n",
    "\n",
    "gnn_layers = {\n",
    "    'gcn': GCNConv,\n",
    "    'gcnii': GCN2Conv,\n",
    "    'graph': GraphConv\n",
    "}\n",
    "\n",
    "# agg_layers = {\n",
    "#     'max': global_max_pool,\n",
    "#     'avg': global_mean_pool\n",
    "# }\n",
    "\n",
    "\n",
    "class LinearRegression(Module):\n",
    "    def __init__(self, in_feats, num_classes):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.layer = Linear(in_feats, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, batch = data.x, data.batch\n",
    "        x = gap(x, batch)\n",
    "        \n",
    "        out = self.layer(x)\n",
    "        return out\n",
    "\n",
    "class GraphLinear(Linear):\n",
    "    def forward(self, data, _):\n",
    "        return super().forward(data)\n",
    "    \n",
    "class GraphMLP(Module):\n",
    "    def __init__(self, in_feats, h_feats, num_layers, num_classes, act=None):\n",
    "        super(GraphMLP, self).__init__()\n",
    "        assert num_layers >= 1\n",
    "        channel_list = [h_feats] * (num_layers - 1)\n",
    "        channel_list = [in_feats] + channel_list + [num_classes]\n",
    "        \n",
    "        layers = []\n",
    "        for dims in zip(channel_list[:-1], channel_list[1:]):\n",
    "            layers.append(Linear(*dims))\n",
    "            layers.append(ReLU())\n",
    "        self.act = activations[act]\n",
    "        self.layer = Sequential(*layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, batch = data.x, data.batch\n",
    "        x = gap(x, batch)\n",
    "        \n",
    "        out = self.act(self.layer(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class GNN(Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, num_layers, \n",
    "                 act='none', dropout=0.5, type='gcn'):\n",
    "        super(GNN, self).__init__()\n",
    "        assert num_layers >= 1\n",
    "        layer = gnn_layers[type]\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.lin = Linear(h_feats, num_classes)\n",
    "        self.dropout = dropout\n",
    "        self.act = activations[act]\n",
    "        self.layers = ModuleList()\n",
    "        channel_list = [h_feats] * num_layers\n",
    "        channel_list = [in_feats] + channel_list\n",
    "        for dims in zip(channel_list[:-1], channel_list[1:]):\n",
    "            self.layers.append(layer(*dims))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # data should have the following 3 attributes\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)            \n",
    "            \n",
    "        x = gap(x, batch)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.act(self.lin(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class TopKGNN(Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, type='graph', act='none'):\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layers[type]\n",
    "        \n",
    "        self.conv1 = gnn_layer(in_feats, h_feats)\n",
    "        self.pool1 = TopKPooling(h_feats, ratio=0.8)\n",
    "        self.conv2 = gnn_layer(h_feats, h_feats)\n",
    "        self.pool2 = TopKPooling(h_feats, ratio=0.8)\n",
    "        self.conv3 = gnn_layer(h_feats, h_feats)\n",
    "        self.pool3 = TopKPooling(h_feats, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(h_feats * 2, h_feats)\n",
    "        self.lin2 = torch.nn.Linear(h_feats, h_feats // 2)\n",
    "        self.lin3 = torch.nn.Linear(h_feats // 2, num_classes)\n",
    "        \n",
    "        self.act = activations[act]\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        # x = self.lin3(x)\n",
    "        x = self.act(self.lin3(x))\n",
    "        return x\n",
    "\n",
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_channels, num_classes, num_layers,\n",
    "                 train_dataset, GNN=GCNConv, k=0.6, act='none'):\n",
    "        super().__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = max(10, k)\n",
    "        self.k = int(k)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(in_feats, hidden_channels))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GNN(hidden_channels, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_channels * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((self.k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.mlp = MLP([dense_dim, 128, num_classes], dropout=0.5, batch_norm=False)\n",
    "        self.act = activations[act]\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [conv(xs[-1], edge_index).tanh()]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "        x = gsp(x, batch, self.k)\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = self.conv1(x).relu()\n",
    "        x = self.maxpool1d(x)\n",
    "        x = self.conv2(x).relu()\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        return self.act(self.mlp(x))\n",
    "\n",
    "\n",
    "class GNNBetMLP(Module):\n",
    "    def __init__(self, nhid,dropout):\n",
    "        super(GNNBetMLP, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.linear1 = torch.nn.Linear(nhid,2*nhid)\n",
    "        self.linear2 = torch.nn.Linear(2*nhid,2*nhid)\n",
    "        self.linear3 = torch.nn.Linear(2*nhid,1)\n",
    "\n",
    "\n",
    "    def forward(self,input_vec,dropout):\n",
    "\n",
    "        score_temp = F.relu(self.linear1(input_vec))\n",
    "        score_temp = F.dropout(score_temp,self.dropout)\n",
    "        score_temp = F.relu(self.linear2(score_temp))\n",
    "        score_temp = F.dropout(score_temp,self.dropout)\n",
    "        score_temp = self.linear3(score_temp)\n",
    "\n",
    "        return score_temp\n",
    "    \n",
    "\n",
    "# Only for single output\n",
    "class GNNBetFullMLP(GNN):\n",
    "    def __init__(self, in_feats, h_feats, num_layers, dropout, agg='gcn'):\n",
    "        super(GNNBetFullMLP, self).__init__(in_feats, h_feats, h_feats, \n",
    "                                            num_layers, dropout=dropout, type=agg)\n",
    "        self.score_layer = GNNBetMLP(h_feats * num_layers, self.dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # data should have the following 3 attributes\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        embeddings = []\n",
    "        \n",
    "        #Layers for aggregation operation\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = F.normalize(x, p=2, dim=1)\n",
    "            x_agg = gap(x, batch)\n",
    "            embeddings.append(x_agg)\n",
    "            \n",
    "        \n",
    "        full_embedding = torch.cat(embeddings, dim=1)\n",
    "        score = self.score_layer(full_embedding, self.dropout)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8XIVW32RQXB"
   },
   "source": [
    "## Graph Regression/Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGCNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(17, 32)\n",
      "    (1): GCNConv(32, 32)\n",
      "    (2): GCNConv(32, 32)\n",
      "    (3): GCNConv(32, 1)\n",
      "  )\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))\n",
      "  (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))\n",
      "  (mlp): MLP(77760, 128, 8)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: nan, Val: nan\n",
      "Epoch: 002, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 003, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 004, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 005, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 006, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 007, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 008, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 009, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 010, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 011, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 012, Train: 0.2094, Val: 0.2000\n",
      "Epoch: 013, Train: 0.2094, Val: 0.2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m train()\n\u001b[1;32m     51\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[0;32m---> 52\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     54\u001b[0m         start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_losses) \u001b[38;5;241m-\u001b[39m print_every\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     34\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:  \u001b[38;5;66;03m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     38\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mDGCNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m xs \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m--> 176\u001b[0m     xs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtanh()]\n\u001b[1;32m    177\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(xs[\u001b[38;5;241m1\u001b[39m:], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Global pooling.\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:185\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:309\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    307\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 309\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__collect__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__user_args__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:201\u001b[0m, in \u001b[0;36mMessagePassing.__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    200\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_size__(size, dim, data)\n\u001b[0;32m--> 201\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__lift__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_j\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n",
      "File \u001b[0;32m/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:171\u001b[0m, in \u001b[0;36mMessagePassing.__lift__\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n\u001b[1;32m    170\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "learning_rate = 0.0002\n",
    "h_feats = 32\n",
    "target_index = 0\n",
    "dropout = 0.6\n",
    "num_node_features, num_classes = get_data_stats(train_loader.dataset, target_index)\n",
    "num_layers = 3\n",
    "\n",
    "model = DGCNN(num_node_features, h_feats, num_classes, num_layers, train_loader.dataset)\n",
    "# model = GNNBetFullMLP(num_node_features, h_feats, num_layers, dropout)\n",
    "# model = GNN(num_node_features, h_feats, num_classes, num_layers, act='logsoft')\n",
    "# model = TopKGNN(num_node_features, h_feats, num_classes)\n",
    "# model = GraphMLP(num_node_features, h_feats, num_layers, num_classes)\n",
    "# model = LinearRegression(num_node_features, num_classes)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss() if num_classes == 1 else torch.nn.NLLLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        target = data.y.unsqueeze(1).float() if num_classes == 1 else data.y[:,target_index].long()\n",
    "        loss = criterion(out, target)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "        if num_classes == 1:\n",
    "            out = out.squeeze(1).cpu().detach()\n",
    "            correct += r2_score(data.y.cpu().detach(), out)  # Check correlation against ground-truth.\n",
    "        else:\n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y[:,target_index]).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive average correlation.\n",
    "\n",
    "num_epochs = 100\n",
    "print_every = 1\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "            start = len(train_losses) - print_every\n",
    "            mean_train = np.mean(train_losses[start:])\n",
    "            mean_test = np.mean(test_losses[start:])\n",
    "            print(f'Epoch: {epoch + 1:03d}, Train: {mean_train:.4f}, Val: {mean_test:.4f}')\n",
    "    train_losses.append(train_acc)\n",
    "    test_losses.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "g, loader = load_data(training_places, num_val=0.2, num_parts=1024,\n",
    "                      num_classes=0, batch_size=128,\n",
    "                      reload=True, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
