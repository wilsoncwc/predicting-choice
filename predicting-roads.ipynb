{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7958681-6281-4f3f-92b8-ee6f2a1c8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os.path as osp\n",
    "from itertools import chain\n",
    "\n",
    "import momepy\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import BCEWithLogitsLoss, Conv1d, MaxPool1d, ModuleList\n",
    "\n",
    "from torch_geometric.data import Data, Batch, InMemoryDataset, download_url, extract_zip\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, GCNConv, global_sort_pool\n",
    "from torch_geometric.transforms import RandomLinkSplit, OneHotDegree\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset_root = './datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeae2176-9966-47f8-9116-5f9cd7860713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Isle of Wight' 'Wycombe' None 'Enfield' 'Slough' 'South Bucks'\n",
      " 'Hillingdon' 'Ealing' 'Chiltern' 'Copeland' 'Windsor and Maidenhead'\n",
      " 'Plymouth' 'South Hams' 'Oxford' 'Waltham Forest' 'Mendip' 'Dudley'\n",
      " 'Cotswold' 'Erewash' 'Redbridge' 'Epping Forest' 'Test Valley'\n",
      " 'Basingstoke and Deane' 'South Gloucestershire' 'Woking' 'Broxbourne'\n",
      " 'Wolverhampton' 'Wiltshire' 'Swindon' 'Bath and North East Somerset'\n",
      " 'Trafford' 'Salford' 'South Staffordshire' 'West Oxfordshire'\n",
      " 'Malvern Hills' 'Vale of White Horse' 'South Kesteven' 'North Kesteven'\n",
      " 'Guildford' 'Southwark' 'Chichester' 'Waverley' 'Elmbridge'\n",
      " 'Forest of Dean' 'Tewkesbury' 'Charnwood' 'Sheffield' 'Ashfield'\n",
      " 'North West Leicestershire' 'North East Derbyshire' 'Stroud' 'Shropshire'\n",
      " 'Telford and Wrekin' 'Horsham' 'City of London' 'Newcastle-under-Lyme'\n",
      " 'Stafford' 'Stoke-on-Trent' 'Arun' 'Lichfield' 'Sandwell' 'Birmingham'\n",
      " 'Amber Valley' 'Mole Valley' 'Bolsover' 'Rushcliffe' 'Wychavon' 'Gedling'\n",
      " 'Gloucester' 'Liverpool' 'Newark and Sherwood' 'Sefton' 'St. Helens'\n",
      " 'Worcester' 'Flintshire' 'Bassetlaw' 'Knowsley' 'Wyre Forest'\n",
      " 'Bromsgrove' 'Denbighshire' 'Herefordshire, County of' 'Rotherham'\n",
      " 'Chesterfield' 'Barnet' 'Monmouthshire' 'Cheltenham' 'Spelthorne'\n",
      " 'Sutton' 'Cheshire East' 'Cheshire West and Chester' 'Runnymede'\n",
      " 'Reigate and Banstead' 'Kingston upon Thames' 'Epsom and Ewell'\n",
      " 'Tandridge' 'Merton' 'Croydon' 'Stockport' 'Stratford-on-Avon'\n",
      " 'Northumberland' 'Walsall' 'Solihull' 'Mid Sussex' 'Waveney' 'Lincoln'\n",
      " 'Tonbridge and Malling' 'Redditch' 'Doncaster' 'Brighton and Hove'\n",
      " 'Tameside' 'High Peak' 'North Lincolnshire' 'Lewes' 'North Warwickshire'\n",
      " 'Gravesham' 'East Riding of Yorkshire' 'South Somerset' 'West Dorset'\n",
      " 'Sevenoaks' 'Medway' 'Nottingham' 'Tamworth' 'Warwick' 'Dartford'\n",
      " 'Surrey Heath' 'South Norfolk' 'Oldham' 'West Lindsey' 'Lambeth'\n",
      " 'North Norfolk' 'Breckland' 'Broxtowe' 'Staffordshire Moorlands'\n",
      " 'Worthing' \"King's Lynn and West Norfolk\" 'Kirklees' 'Calderdale'\n",
      " 'Great Yarmouth' 'Crawley' 'East Devon' 'Mid Devon' 'St Edmundsbury'\n",
      " 'Mid Suffolk' 'East Cambridgeshire' 'Forest Heath' 'North Devon'\n",
      " 'Fenland' 'North Dorset' 'Bracknell Forest' 'Haringey' 'Coventry'\n",
      " 'Hounslow' 'Wakefield' 'Eastbourne' 'Selby' 'Wealden' 'West Somerset'\n",
      " 'Exeter' 'Kingston upon Hull, City of' 'Broadland' 'Norwich' 'Eden'\n",
      " 'Rugby' 'Barrow-in-Furness' 'Cannock Chase' 'South Lakeland' 'Carlisle'\n",
      " 'Isle of Anglesey' 'West Berkshire' 'Allerdale' 'Derby'\n",
      " 'South Derbyshire' 'Leicester' 'Hinckley and Bosworth' 'Gwynedd'\n",
      " 'County Durham' 'Bexley' 'West Devon' 'Torridge' 'Winchester'\n",
      " 'South Oxfordshire' 'Blaby' 'North Somerset' 'Bristol, City of' 'Wigan'\n",
      " 'Warrington' 'West Lancashire' 'Fylde' 'Manchester' 'North Tyneside'\n",
      " 'Newcastle upon Tyne' 'Rochdale' 'Barnsley' 'Gateshead' 'Sunderland'\n",
      " 'Redcar and Cleveland' 'Hartlepool' 'Bury' 'Ryedale' 'Harborough'\n",
      " 'Rutland' 'Scarborough' 'Harrogate' 'Melton' 'Hambleton' 'Richmondshire'\n",
      " 'South Tyneside' 'Pendle' 'Bolton' 'Bradford' 'Chorley' 'York' 'Leeds'\n",
      " 'New Forest' 'Preston' 'Powys' 'South Ribble' 'Wyre' 'Rossendale'\n",
      " 'Darlington' 'Stockton-on-Tees' 'Burnley' 'Craven' 'Christchurch'\n",
      " 'East Dorset' 'Weymouth and Portland' 'Middlesbrough' 'Conwy'\n",
      " 'Southampton' 'Blackpool' 'Fareham' 'Eastleigh' 'Lancaster' 'Purbeck'\n",
      " 'Gosport' 'Poole' 'Bournemouth' 'Wrexham' 'Pembrokeshire' 'Sedgemoor'\n",
      " 'Cornwall' 'Taunton Deane' 'Halton' 'Mansfield' 'Wirral'\n",
      " 'Carmarthenshire' 'Blackburn with Darwen' 'East Staffordshire'\n",
      " 'Ceredigion' 'Richmond upon Thames' 'Isles of Scilly' 'Derbyshire Dales'\n",
      " 'Adur' 'Rhondda Cynon Taf' 'Caerphilly' 'Ribble Valley'\n",
      " 'The Vale of Glamorgan' 'Bridgend' 'Neath Port Talbot' 'Merthyr Tydfil'\n",
      " 'Swansea' 'Cardiff' 'Blaenau Gwent' 'Newport' 'Hyndburn' 'Torfaen'\n",
      " 'East Hertfordshire' 'Stevenage' 'Uttlesford' 'St Albans' 'East Lindsey'\n",
      " 'Colchester' 'East Northamptonshire' 'Central Bedfordshire' 'Babergh'\n",
      " 'Braintree' 'Huntingdonshire' 'Suffolk Coastal' 'Ipswich' 'Peterborough'\n",
      " 'South Holland' 'Welwyn Hatfield' 'Boston' 'Watford' 'Maldon'\n",
      " 'South Cambridgeshire' 'Hertsmere' 'Three Rivers' 'Bedford' 'Brentwood'\n",
      " 'North Hertfordshire' 'Cambridge' 'Basildon' 'Harlow' 'Chelmsford'\n",
      " 'Tendring' 'Dacorum' 'Luton' 'Harrow' 'Havering' 'Islington' 'Brent'\n",
      " 'Greenwich' 'Castle Point' 'Aylesbury Vale' 'Milton Keynes' 'Kettering'\n",
      " 'Thurrock' 'Westminster' 'Camden' 'Hammersmith and Fulham'\n",
      " 'Kensington and Chelsea' 'Teignbridge' 'Southend-on-Sea' 'Hart'\n",
      " 'East Hampshire' 'Lewisham' 'Rochford' 'Wandsworth'\n",
      " 'North East Lincolnshire' 'Wokingham' 'Barking and Dagenham' 'Newham'\n",
      " 'Portsmouth' 'Tower Hamlets' 'Daventry' 'Corby' 'Rushmoor'\n",
      " 'South Northamptonshire' 'Wellingborough' 'Hackney' 'Torbay'\n",
      " 'Northampton' 'Havant' 'Reading' 'Swale' 'Shepway' 'Hastings' 'Bromley'\n",
      " 'Tunbridge Wells' 'Maidstone' 'Cherwell' 'Oadby and Wigston' 'Rother'\n",
      " 'Canterbury' 'Ashford' 'Thanet' 'Dover' 'Nuneaton and Bedworth']\n"
     ]
    }
   ],
   "source": [
    "full_dataset_label = 'No Bounds'\n",
    "training_places = ['London']\n",
    "\n",
    "# Fields to ignore\n",
    "meridian_fields = ['meridian_id', 'meridian_gid', 'meridian_code',\n",
    "                   'meridian_osodr', 'meridian_number', 'meridian_road_name',\n",
    "                   'meridian_indicator', 'meridian_class', 'meridian_class_scale']\n",
    "census_geom_fields = ['wz11cd', 'lsoa11nm', 'msoa11nm',\n",
    "                      'oa11cd', 'lsoa11cd', 'msoa11cd'] # Allowed: lad11cd, lad11nm\n",
    "misc_fields = ['id']\n",
    "ignore_fields = meridian_fields + census_geom_fields + misc_fields\n",
    "\n",
    "\n",
    "all_feature_fields = ['metres', 'choice2km', 'nodecount2km', 'integration2km',\n",
    "                      'choice10km', 'nodecount10km','integration10km',\n",
    "                      'choice100km','nodecount100km','integration100km']\n",
    "rank_fields = ['choice2kmrank', 'choice10kmrank','integration10kmrank', 'integration2kmrank']\n",
    "log_fields = ['choice2kmlog','choice10kmlog','choice100kmlog']\n",
    "\n",
    "# dictionary caches - RELOADING THIS CELL DELETES GRAPH CACHES\n",
    "loaded_gdfs = {}\n",
    "loaded_graphs={}\n",
    "\n",
    "full_gdf = gpd.read_file('./OpenMapping-gb-v1_gpkg/gpkg/ssx_openmapping_gb_v1.gpkg',\n",
    "                    ignore_fields=ignore_fields)\n",
    "included_places = full_gdf['lad11nm'].unique()\n",
    "print(included_places)\n",
    "osmnx_buffer = 10000\n",
    "\n",
    "def load_gdf(place=training_places[0], verbose=False): #(W, S, E, N)\n",
    "    \"\"\"Geodataframe (gdf) loader with caching\"\"\"\n",
    "    if place in included_places:\n",
    "        # Retrieve matching rows corresponding to the Local Authority\n",
    "        print(f'Loading {place} from SSx')\n",
    "        gdf = full_gdf.query(f'lad11nm == \"{place}\"').copy()\n",
    "    elif place == full_dataset_label:\n",
    "        # Read full dataset without boundaries\n",
    "        gdf = full_gdf.copy()\n",
    "    else:\n",
    "        print(f'Loading {place} from OSMnx')\n",
    "        # Load gdf from osmnx (for testing only, graph will lack target attr)\n",
    "        # Actually uses the Nominatim API:\n",
    "        # https://nominatim.org/release-docs/latest/api/Overview/\n",
    "        g = ox.graph.graph_from_place(place, buffer_dist=osmnx_buffer)\n",
    "        g = ox.projection.project_graph(g)\n",
    "        gdf = ox.utils_graph.graph_to_gdfs(g, nodes=False)\n",
    "        gdf = gdf.rename(columns={'length': 'metres'})\n",
    "        return gdf\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{gdf.size} geometries retrieved from {place}')\n",
    "\n",
    "    loaded_gdfs[place] = gdf\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc83159-6028-4b6a-b604-544739d8c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph of Birmingham...\n",
      "Loading Birmingham from SSx\n",
      "323840 geometries retrieved from Birmingham\n",
      "Generated graph with 12509 nodes and 16192 edges\n",
      "Node attributes: {'choice2km', 'integration100km', 'nodecount100km', 'choice100km', 'x', 'choice10km', 'metres', 'nodecount2km', 'nodecount10km', 'y', 'integration10km', 'integration2km'}\n",
      "Edge attributes: {'key', 'v', 'u'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 32384], u=[32384, 2], v=[32384, 2], key=[32384], x=[12509, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_graph(g, feature_fields=[]):\n",
    "    \"\"\"\n",
    "    Takes SSx metrics from adjacent edges and averages them to form the node attribute\n",
    "    \"\"\"\n",
    "    for node, d in g.nodes(data=True):\n",
    "        # get attributes from adjacent edges\n",
    "        new_data = {field:[] for field in feature_fields}\n",
    "        for _, _, edge_data in g.edges(node, data=True):\n",
    "            for field in feature_fields:\n",
    "                new_data[field].append(edge_data[field])\n",
    "        \n",
    "        d.clear()\n",
    "        for field in feature_fields:\n",
    "            d[field] = sum(new_data[field]) / len(new_data[field])\n",
    "        \n",
    "        # Encode coordinate as feature\n",
    "        d['x'], d['y'] = node\n",
    "    \n",
    "    for u, v, k, d in g.edges(keys=True, data=True):\n",
    "        d.clear()\n",
    "        d['u'] = u\n",
    "        d['v'] = v\n",
    "        d['key'] = k\n",
    "    return g\n",
    "\n",
    "def load_graph(place, feature_fields=[], reload=True, verbose=False):\n",
    "  if verbose:\n",
    "    print(f'Loading graph of {place}...')\n",
    "  key = (place)\n",
    "  if key in loaded_graphs and reload:\n",
    "    g = loaded_graphs[key]\n",
    "    if verbose:\n",
    "        print('Loaded existing graph.')\n",
    "  else:\n",
    "    gdf = load_gdf(place, verbose=verbose)\n",
    "    G = momepy.gdf_to_nx(gdf, approach='primal')\n",
    "    G = process_graph(G, feature_fields)\n",
    "    \n",
    "    if verbose:\n",
    "      print(f'Generated graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "    node_attrs = set(chain.from_iterable(d.keys() for *_, d in G.nodes(data=True)))\n",
    "    edge_attrs = set(chain.from_iterable(d.keys() for *_, d in G.edges(data=True)))\n",
    "    \n",
    "    if verbose:\n",
    "        # List node attributes\n",
    "        print(f'Node attributes: {node_attrs}')\n",
    "        print(f'Edge attributes: {edge_attrs}')                            \n",
    "    \n",
    "    # If no node attributes, node degree will be added later\n",
    "    # Edge attribute (angle) are not added\n",
    "    if len(node_attrs) > 0:\n",
    "        g = from_networkx(G, group_node_attrs=list(node_attrs))\n",
    "    else:\n",
    "        g = from_networkx(G)\n",
    "    loaded_graphs[key] = g\n",
    "  return g\n",
    "\n",
    "loaded_graphs = {}\n",
    "data = load_graph('Birmingham', all_feature_fields, verbose=True)\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e41c62-1db0-43c6-9d60-f0abbd6383d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "def visualize_preds(place, model):\n",
    "    data = load_graph(place)\n",
    "    gdf = load_gdf(place)\n",
    "    streets = momepy.gdf_to_nx(gdf, approach='primal')\n",
    "\n",
    "    # Randomly sample negative links and run predictions\n",
    "    vis_data, _, _ = RandomLinkSplit(num_val=0, num_test=0, is_undirected=True)(data)\n",
    "    z = model.encode(vis_data.x, vis_data.edge_index)\n",
    "    out = model.decode(z, vis_data.edge_label_index).view(-1).sigmoid()\n",
    "    vis_data.res = (out != vis_data.edge_label)\n",
    "    \n",
    "    streets2 = to_networkx(vis_data, edge_attrs=['res', 'u', 'v', 'key']).to_undirected()\n",
    "    res_dict = {}\n",
    "    for _, _, d in streets2.edges(data=True):\n",
    "        u = tuple(d['u'])\n",
    "        v = tuple(d['v'])\n",
    "        k = d['key']\n",
    "        res_dict[(u, v, k)] = d['res']\n",
    "    nx.set_edge_attributes(streets, res_dict, 'res')\n",
    "    points, lines = momepy.nx_to_gdf(streets)\n",
    "    lines.plot(column='res', figsize=(20,10), cmap='Set1', legend=True)\n",
    "\n",
    "     # plot original and predicted streets\n",
    "    f, ax = plt.subplots(1, 2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "    for i, facet in enumerate(ax):\n",
    "        facet.set_title((\"Original\", \"Predicted\")[i], size=20)\n",
    "        facet.axis(\"off\")\n",
    "    lines.plot(ax=ax[0], column=f'choice{rad}{mod}', cmap='jet',\n",
    "               legend=True, legend_kwds={'shrink': 0.3})\n",
    "    lines.plot(ax=ax[1], column='preds', cmap='jet', legend=True,\n",
    "               legend_kwds={'shrink': 0.3})\n",
    "    plt.suptitle(f'\\\"{place}\\\": choice{rad}{mod}\\n {graph.num_nodes} road nodes. R2: {r2:.3f}, KT: {kt:.3f}',\n",
    "                 fontweight=\"bold\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7b971-8b03-4abb-9a31-e1f977e29b8a",
   "metadata": {},
   "source": [
    "# Standard GAE-GCN Link Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539f4c9-d3e1-4908-8730-cafe28d911e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.05, num_test=0.1,\n",
    "                            is_undirected=True, add_negative_train_samples=False)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(data.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "print_every = 10\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    if epoch % print_every == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "              f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fee448a-c4c3-42ad-80b9-3623610e4a04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39medge_label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.edge_label_index.size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928e738-4c54-44d1-86b8-95ec5066013e",
   "metadata": {},
   "source": [
    "# GVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ac1a5a-a76d-46ae-b8df-29fd9f90a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "\n",
    "class LinearEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv(x, edge_index)\n",
    "\n",
    "\n",
    "class VariationalLinearEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_mu = GCNConv(in_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21458933-2f90-4b33-9e3d-27abf74af483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 277\n",
      "Number of test graphs: 70\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 465518], x=[155354, 17], edge_attr=[465518, 1], y=[32, 3], batch=[155354], ptr=[33])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 580710], x=[189645, 17], edge_attr=[580710, 1], y=[32, 3], batch=[189645], ptr=[33])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 550286], x=[173579, 17], edge_attr=[550286, 1], y=[32, 3], batch=[173579], ptr=[33])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 467834], x=[148436, 17], edge_attr=[467834, 1], y=[32, 3], batch=[148436], ptr=[33])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 497438], x=[163496, 17], edge_attr=[497438, 1], y=[32, 3], batch=[163496], ptr=[33])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 507448], x=[161853, 17], edge_attr=[507448, 1], y=[32, 3], batch=[161853], ptr=[33])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 490344], x=[154133, 17], edge_attr=[490344, 1], y=[32, 3], batch=[154133], ptr=[33])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 603332], x=[187718, 17], edge_attr=[603332, 1], y=[32, 3], batch=[187718], ptr=[33])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 21\n",
      "DataBatch(edge_index=[2, 325522], x=[103877, 17], edge_attr=[325522, 1], y=[21, 3], batch=[103877], ptr=[22])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader    \n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "])\n",
    "\n",
    "def process_dataset(dataset, split=0.8, batch_size=64, verbose=False):\n",
    "    # Train-test split\n",
    "    idx = torch.randperm(len(dataset))\n",
    "    split_idx = math.floor(split * len(dataset))\n",
    "    train_idx = idx[:split_idx]\n",
    "    test_idx = idx[split_idx:]\n",
    "    \n",
    "    train_dataset = [transform(dataset[i]) for i in train_idx]\n",
    "    test_transform = T.Compose([\n",
    "        transform,\n",
    "        RandomLinkSplit(num_val=0, num_test=0, split_labels=True, is_undirected=True)\n",
    "    ])\n",
    "    test_dataset = [test_transform(dataset[i])[0] for i in test_idx]\n",
    "    if verbose:\n",
    "        print(f'Number of training graphs: {len(train_dataset)}')\n",
    "        print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "    # Load graphs into dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    if verbose:\n",
    "        for step, data in enumerate(train_loader):\n",
    "            print(f'Step {step + 1}:')\n",
    "            print('=======')\n",
    "            print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "            print(data)\n",
    "            print()\n",
    "\n",
    "    return train_dataset, test_dataset, train_loader, test_loader\n",
    "\n",
    "\n",
    "dataset = torch.load('datasets/ssx_cities_dataset.pt')\n",
    "train_dataset, test_dataset, train_loader, test_loader = process_dataset(dataset, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "675cf928-5267-473d-8209-d5bfa16603c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.5747, AP: 0.6074\n",
      "Epoch: 002, AUC: 0.5769, AP: 0.6092\n",
      "Epoch: 003, AUC: 0.5802, AP: 0.6114\n",
      "Epoch: 004, AUC: 0.5865, AP: 0.6147\n",
      "Epoch: 005, AUC: 0.5929, AP: 0.6178\n",
      "Epoch: 006, AUC: 0.5994, AP: 0.6210\n",
      "Epoch: 007, AUC: 0.6061, AP: 0.6246\n",
      "Epoch: 008, AUC: 0.6139, AP: 0.6287\n",
      "Epoch: 009, AUC: 0.6218, AP: 0.6324\n",
      "Epoch: 010, AUC: 0.6250, AP: 0.6320\n",
      "Epoch: 011, AUC: 0.6259, AP: 0.6307\n",
      "Epoch: 012, AUC: 0.6248, AP: 0.6289\n",
      "Epoch: 013, AUC: 0.6248, AP: 0.6283\n",
      "Epoch: 014, AUC: 0.6271, AP: 0.6292\n",
      "Epoch: 015, AUC: 0.6305, AP: 0.6306\n",
      "Epoch: 016, AUC: 0.6322, AP: 0.6312\n",
      "Epoch: 017, AUC: 0.6352, AP: 0.6324\n",
      "Epoch: 018, AUC: 0.6359, AP: 0.6326\n",
      "Epoch: 019, AUC: 0.6356, AP: 0.6322\n",
      "Epoch: 020, AUC: 0.6369, AP: 0.6327\n",
      "Epoch: 021, AUC: 0.6413, AP: 0.6346\n",
      "Epoch: 022, AUC: 0.6423, AP: 0.6349\n",
      "Epoch: 023, AUC: 0.6447, AP: 0.6358\n",
      "Epoch: 024, AUC: 0.6467, AP: 0.6366\n",
      "Epoch: 025, AUC: 0.6480, AP: 0.6371\n",
      "Epoch: 026, AUC: 0.6484, AP: 0.6371\n",
      "Epoch: 027, AUC: 0.6490, AP: 0.6372\n",
      "Epoch: 028, AUC: 0.6479, AP: 0.6365\n",
      "Epoch: 029, AUC: 0.6455, AP: 0.6353\n",
      "Epoch: 030, AUC: 0.6474, AP: 0.6360\n",
      "Epoch: 031, AUC: 0.6469, AP: 0.6356\n",
      "Epoch: 032, AUC: 0.6472, AP: 0.6357\n",
      "Epoch: 033, AUC: 0.6517, AP: 0.6377\n",
      "Epoch: 034, AUC: 0.6513, AP: 0.6373\n",
      "Epoch: 035, AUC: 0.6448, AP: 0.6342\n",
      "Epoch: 036, AUC: 0.6422, AP: 0.6328\n",
      "Epoch: 037, AUC: 0.6408, AP: 0.6321\n",
      "Epoch: 038, AUC: 0.6375, AP: 0.6305\n",
      "Epoch: 039, AUC: 0.6406, AP: 0.6318\n",
      "Epoch: 040, AUC: 0.6404, AP: 0.6316\n",
      "Epoch: 041, AUC: 0.6383, AP: 0.6305\n",
      "Epoch: 042, AUC: 0.6373, AP: 0.6300\n",
      "Epoch: 043, AUC: 0.6366, AP: 0.6296\n",
      "Epoch: 044, AUC: 0.6339, AP: 0.6283\n",
      "Epoch: 045, AUC: 0.6286, AP: 0.6259\n",
      "Epoch: 046, AUC: 0.6272, AP: 0.6253\n",
      "Epoch: 047, AUC: 0.6288, AP: 0.6259\n",
      "Epoch: 048, AUC: 0.6260, AP: 0.6246\n",
      "Epoch: 049, AUC: 0.6237, AP: 0.6236\n",
      "Epoch: 050, AUC: 0.6216, AP: 0.6226\n",
      "Epoch: 051, AUC: 0.6210, AP: 0.6223\n",
      "Epoch: 052, AUC: 0.6210, AP: 0.6222\n",
      "Epoch: 053, AUC: 0.6203, AP: 0.6219\n",
      "Epoch: 054, AUC: 0.6210, AP: 0.6221\n",
      "Epoch: 055, AUC: 0.6194, AP: 0.6214\n",
      "Epoch: 056, AUC: 0.6177, AP: 0.6207\n",
      "Epoch: 057, AUC: 0.6170, AP: 0.6203\n",
      "Epoch: 058, AUC: 0.6171, AP: 0.6203\n",
      "Epoch: 059, AUC: 0.6169, AP: 0.6202\n",
      "Epoch: 060, AUC: 0.6154, AP: 0.6195\n",
      "Epoch: 061, AUC: 0.6147, AP: 0.6192\n",
      "Epoch: 062, AUC: 0.6141, AP: 0.6190\n",
      "Epoch: 063, AUC: 0.6142, AP: 0.6190\n",
      "Epoch: 064, AUC: 0.6142, AP: 0.6190\n",
      "Epoch: 065, AUC: 0.6128, AP: 0.6183\n",
      "Epoch: 066, AUC: 0.6127, AP: 0.6183\n",
      "Epoch: 067, AUC: 0.6124, AP: 0.6181\n",
      "Epoch: 068, AUC: 0.6126, AP: 0.6182\n",
      "Epoch: 069, AUC: 0.6126, AP: 0.6182\n",
      "Epoch: 070, AUC: 0.6130, AP: 0.6184\n",
      "Epoch: 071, AUC: 0.6129, AP: 0.6183\n",
      "Epoch: 072, AUC: 0.6125, AP: 0.6182\n",
      "Epoch: 073, AUC: 0.6128, AP: 0.6183\n",
      "Epoch: 074, AUC: 0.6128, AP: 0.6183\n",
      "Epoch: 075, AUC: 0.6123, AP: 0.6181\n",
      "Epoch: 076, AUC: 0.6129, AP: 0.6184\n",
      "Epoch: 077, AUC: 0.6126, AP: 0.6183\n",
      "Epoch: 078, AUC: 0.6134, AP: 0.6186\n",
      "Epoch: 079, AUC: 0.6137, AP: 0.6188\n",
      "Epoch: 080, AUC: 0.6138, AP: 0.6189\n",
      "Epoch: 081, AUC: 0.6143, AP: 0.6192\n",
      "Epoch: 082, AUC: 0.6146, AP: 0.6193\n",
      "Epoch: 083, AUC: 0.6151, AP: 0.6196\n",
      "Epoch: 084, AUC: 0.6160, AP: 0.6200\n",
      "Epoch: 085, AUC: 0.6166, AP: 0.6203\n",
      "Epoch: 086, AUC: 0.6166, AP: 0.6204\n",
      "Epoch: 087, AUC: 0.6177, AP: 0.6209\n",
      "Epoch: 088, AUC: 0.6183, AP: 0.6212\n",
      "Epoch: 089, AUC: 0.6191, AP: 0.6216\n",
      "Epoch: 090, AUC: 0.6199, AP: 0.6221\n",
      "Epoch: 091, AUC: 0.6217, AP: 0.6229\n",
      "Epoch: 092, AUC: 0.6231, AP: 0.6236\n",
      "Epoch: 093, AUC: 0.6238, AP: 0.6240\n",
      "Epoch: 094, AUC: 0.6252, AP: 0.6247\n",
      "Epoch: 095, AUC: 0.6266, AP: 0.6254\n",
      "Epoch: 096, AUC: 0.6283, AP: 0.6262\n",
      "Epoch: 097, AUC: 0.6299, AP: 0.6270\n",
      "Epoch: 098, AUC: 0.6316, AP: 0.6279\n",
      "Epoch: 099, AUC: 0.6337, AP: 0.6290\n",
      "Epoch: 100, AUC: 0.6360, AP: 0.6301\n",
      "Epoch: 101, AUC: 0.6383, AP: 0.6313\n",
      "Epoch: 102, AUC: 0.6413, AP: 0.6328\n",
      "Epoch: 103, AUC: 0.6438, AP: 0.6342\n",
      "Epoch: 104, AUC: 0.6462, AP: 0.6355\n",
      "Epoch: 105, AUC: 0.6496, AP: 0.6373\n",
      "Epoch: 106, AUC: 0.6540, AP: 0.6397\n",
      "Epoch: 107, AUC: 0.6577, AP: 0.6419\n",
      "Epoch: 108, AUC: 0.6606, AP: 0.6437\n",
      "Epoch: 109, AUC: 0.6636, AP: 0.6456\n",
      "Epoch: 110, AUC: 0.6682, AP: 0.6485\n",
      "Epoch: 111, AUC: 0.6716, AP: 0.6506\n",
      "Epoch: 112, AUC: 0.6754, AP: 0.6530\n",
      "Epoch: 113, AUC: 0.6784, AP: 0.6549\n",
      "Epoch: 114, AUC: 0.6801, AP: 0.6560\n",
      "Epoch: 115, AUC: 0.6833, AP: 0.6577\n",
      "Epoch: 116, AUC: 0.6858, AP: 0.6589\n",
      "Epoch: 117, AUC: 0.6880, AP: 0.6599\n",
      "Epoch: 118, AUC: 0.6895, AP: 0.6605\n",
      "Epoch: 119, AUC: 0.6918, AP: 0.6610\n",
      "Epoch: 120, AUC: 0.6928, AP: 0.6614\n",
      "Epoch: 121, AUC: 0.6943, AP: 0.6616\n",
      "Epoch: 122, AUC: 0.6958, AP: 0.6615\n",
      "Epoch: 123, AUC: 0.6968, AP: 0.6612\n",
      "Epoch: 124, AUC: 0.6972, AP: 0.6614\n",
      "Epoch: 125, AUC: 0.6976, AP: 0.6614\n",
      "Epoch: 126, AUC: 0.6980, AP: 0.6613\n",
      "Epoch: 127, AUC: 0.6983, AP: 0.6612\n",
      "Epoch: 128, AUC: 0.6985, AP: 0.6610\n",
      "Epoch: 129, AUC: 0.6987, AP: 0.6608\n",
      "Epoch: 130, AUC: 0.6989, AP: 0.6605\n",
      "Epoch: 131, AUC: 0.6990, AP: 0.6603\n",
      "Epoch: 132, AUC: 0.6991, AP: 0.6600\n",
      "Epoch: 133, AUC: 0.6991, AP: 0.6599\n",
      "Epoch: 134, AUC: 0.6991, AP: 0.6601\n",
      "Epoch: 135, AUC: 0.6991, AP: 0.6597\n",
      "Epoch: 136, AUC: 0.6990, AP: 0.6590\n",
      "Epoch: 137, AUC: 0.6991, AP: 0.6595\n",
      "Epoch: 138, AUC: 0.6990, AP: 0.6594\n",
      "Epoch: 139, AUC: 0.6990, AP: 0.6591\n",
      "Epoch: 140, AUC: 0.6990, AP: 0.6592\n",
      "Epoch: 141, AUC: 0.6989, AP: 0.6588\n",
      "Epoch: 142, AUC: 0.6989, AP: 0.6590\n",
      "Epoch: 143, AUC: 0.6988, AP: 0.6585\n",
      "Epoch: 144, AUC: 0.6989, AP: 0.6590\n",
      "Epoch: 145, AUC: 0.6988, AP: 0.6586\n",
      "Epoch: 146, AUC: 0.6987, AP: 0.6581\n",
      "Epoch: 147, AUC: 0.6989, AP: 0.6591\n",
      "Epoch: 148, AUC: 0.6988, AP: 0.6588\n",
      "Epoch: 149, AUC: 0.6987, AP: 0.6585\n",
      "Epoch: 150, AUC: 0.6987, AP: 0.6584\n",
      "Epoch: 151, AUC: 0.6988, AP: 0.6590\n",
      "Epoch: 152, AUC: 0.6988, AP: 0.6593\n",
      "Epoch: 153, AUC: 0.6987, AP: 0.6586\n",
      "Epoch: 154, AUC: 0.6986, AP: 0.6583\n",
      "Epoch: 155, AUC: 0.6985, AP: 0.6580\n",
      "Epoch: 156, AUC: 0.6985, AP: 0.6580\n",
      "Epoch: 157, AUC: 0.6987, AP: 0.6586\n",
      "Epoch: 158, AUC: 0.6986, AP: 0.6583\n",
      "Epoch: 159, AUC: 0.6986, AP: 0.6586\n",
      "Epoch: 160, AUC: 0.6985, AP: 0.6580\n",
      "Epoch: 161, AUC: 0.6987, AP: 0.6588\n",
      "Epoch: 162, AUC: 0.6987, AP: 0.6591\n",
      "Epoch: 163, AUC: 0.6985, AP: 0.6580\n",
      "Epoch: 164, AUC: 0.6984, AP: 0.6577\n",
      "Epoch: 165, AUC: 0.6985, AP: 0.6584\n",
      "Epoch: 166, AUC: 0.6986, AP: 0.6585\n",
      "Epoch: 167, AUC: 0.6985, AP: 0.6583\n",
      "Epoch: 168, AUC: 0.6986, AP: 0.6586\n",
      "Epoch: 169, AUC: 0.6985, AP: 0.6581\n",
      "Epoch: 170, AUC: 0.6986, AP: 0.6587\n",
      "Epoch: 171, AUC: 0.6985, AP: 0.6584\n",
      "Epoch: 172, AUC: 0.6986, AP: 0.6585\n",
      "Epoch: 173, AUC: 0.6985, AP: 0.6582\n",
      "Epoch: 174, AUC: 0.6983, AP: 0.6575\n",
      "Epoch: 175, AUC: 0.6987, AP: 0.6587\n",
      "Epoch: 176, AUC: 0.6987, AP: 0.6589\n",
      "Epoch: 177, AUC: 0.6986, AP: 0.6586\n",
      "Epoch: 178, AUC: 0.6986, AP: 0.6582\n",
      "Epoch: 179, AUC: 0.6986, AP: 0.6582\n",
      "Epoch: 180, AUC: 0.6986, AP: 0.6584\n",
      "Epoch: 181, AUC: 0.6988, AP: 0.6589\n",
      "Epoch: 182, AUC: 0.6985, AP: 0.6579\n",
      "Epoch: 183, AUC: 0.6983, AP: 0.6573\n",
      "Epoch: 184, AUC: 0.6988, AP: 0.6588\n",
      "Epoch: 185, AUC: 0.6988, AP: 0.6588\n",
      "Epoch: 186, AUC: 0.6986, AP: 0.6582\n",
      "Epoch: 187, AUC: 0.6986, AP: 0.6579\n",
      "Epoch: 188, AUC: 0.6987, AP: 0.6584\n",
      "Epoch: 189, AUC: 0.6989, AP: 0.6589\n",
      "Epoch: 190, AUC: 0.6988, AP: 0.6584\n",
      "Epoch: 191, AUC: 0.6985, AP: 0.6575\n",
      "Epoch: 192, AUC: 0.6988, AP: 0.6585\n",
      "Epoch: 193, AUC: 0.6989, AP: 0.6589\n",
      "Epoch: 194, AUC: 0.6988, AP: 0.6582\n",
      "Epoch: 195, AUC: 0.6987, AP: 0.6579\n",
      "Epoch: 196, AUC: 0.6988, AP: 0.6580\n",
      "Epoch: 197, AUC: 0.6990, AP: 0.6588\n",
      "Epoch: 198, AUC: 0.6989, AP: 0.6583\n",
      "Epoch: 199, AUC: 0.6988, AP: 0.6579\n",
      "Epoch: 200, AUC: 0.6990, AP: 0.6588\n",
      "Epoch: 201, AUC: 0.6990, AP: 0.6585\n",
      "Epoch: 202, AUC: 0.6991, AP: 0.6587\n",
      "Epoch: 203, AUC: 0.6990, AP: 0.6584\n",
      "Epoch: 204, AUC: 0.6989, AP: 0.6578\n",
      "Epoch: 205, AUC: 0.6994, AP: 0.6594\n",
      "Epoch: 206, AUC: 0.6990, AP: 0.6581\n",
      "Epoch: 207, AUC: 0.6990, AP: 0.6581\n",
      "Epoch: 208, AUC: 0.6992, AP: 0.6584\n",
      "Epoch: 209, AUC: 0.6990, AP: 0.6579\n",
      "Epoch: 210, AUC: 0.6993, AP: 0.6586\n",
      "Epoch: 211, AUC: 0.6993, AP: 0.6586\n",
      "Epoch: 212, AUC: 0.6993, AP: 0.6585\n",
      "Epoch: 213, AUC: 0.6992, AP: 0.6583\n",
      "Epoch: 214, AUC: 0.6994, AP: 0.6588\n",
      "Epoch: 215, AUC: 0.6993, AP: 0.6586\n",
      "Epoch: 216, AUC: 0.6989, AP: 0.6574\n",
      "Epoch: 217, AUC: 0.6994, AP: 0.6588\n",
      "Epoch: 218, AUC: 0.6997, AP: 0.6599\n",
      "Epoch: 219, AUC: 0.6993, AP: 0.6582\n",
      "Epoch: 220, AUC: 0.6992, AP: 0.6580\n",
      "Epoch: 221, AUC: 0.6996, AP: 0.6593\n",
      "Epoch: 222, AUC: 0.6995, AP: 0.6588\n",
      "Epoch: 223, AUC: 0.6994, AP: 0.6585\n",
      "Epoch: 224, AUC: 0.6996, AP: 0.6593\n",
      "Epoch: 225, AUC: 0.6993, AP: 0.6584\n",
      "Epoch: 226, AUC: 0.6995, AP: 0.6589\n",
      "Epoch: 227, AUC: 0.6996, AP: 0.6592\n",
      "Epoch: 228, AUC: 0.6994, AP: 0.6585\n",
      "Epoch: 229, AUC: 0.6995, AP: 0.6587\n",
      "Epoch: 230, AUC: 0.6996, AP: 0.6591\n",
      "Epoch: 231, AUC: 0.6996, AP: 0.6591\n",
      "Epoch: 232, AUC: 0.6995, AP: 0.6589\n",
      "Epoch: 233, AUC: 0.6995, AP: 0.6587\n",
      "Epoch: 234, AUC: 0.6995, AP: 0.6588\n",
      "Epoch: 235, AUC: 0.6998, AP: 0.6597\n",
      "Epoch: 236, AUC: 0.6998, AP: 0.6597\n",
      "Epoch: 237, AUC: 0.6994, AP: 0.6585\n",
      "Epoch: 238, AUC: 0.6994, AP: 0.6585\n",
      "Epoch: 239, AUC: 0.6995, AP: 0.6589\n",
      "Epoch: 240, AUC: 0.6996, AP: 0.6592\n",
      "Epoch: 241, AUC: 0.6996, AP: 0.6593\n",
      "Epoch: 242, AUC: 0.6998, AP: 0.6597\n",
      "Epoch: 243, AUC: 0.6995, AP: 0.6590\n",
      "Epoch: 244, AUC: 0.6995, AP: 0.6589\n",
      "Epoch: 245, AUC: 0.6998, AP: 0.6599\n",
      "Epoch: 246, AUC: 0.6997, AP: 0.6597\n",
      "Epoch: 247, AUC: 0.6995, AP: 0.6591\n",
      "Epoch: 248, AUC: 0.6996, AP: 0.6595\n",
      "Epoch: 249, AUC: 0.6997, AP: 0.6598\n",
      "Epoch: 250, AUC: 0.6997, AP: 0.6598\n",
      "Epoch: 251, AUC: 0.6995, AP: 0.6592\n",
      "Epoch: 252, AUC: 0.6997, AP: 0.6597\n",
      "Epoch: 253, AUC: 0.6997, AP: 0.6598\n",
      "Epoch: 254, AUC: 0.6995, AP: 0.6592\n",
      "Epoch: 255, AUC: 0.6996, AP: 0.6598\n",
      "Epoch: 256, AUC: 0.6995, AP: 0.6594\n",
      "Epoch: 257, AUC: 0.6997, AP: 0.6600\n",
      "Epoch: 258, AUC: 0.6995, AP: 0.6595\n",
      "Epoch: 259, AUC: 0.6999, AP: 0.6608\n",
      "Epoch: 260, AUC: 0.6996, AP: 0.6599\n",
      "Epoch: 261, AUC: 0.6996, AP: 0.6598\n",
      "Epoch: 262, AUC: 0.7000, AP: 0.6612\n",
      "Epoch: 263, AUC: 0.6993, AP: 0.6592\n",
      "Epoch: 264, AUC: 0.6995, AP: 0.6598\n",
      "Epoch: 265, AUC: 0.7001, AP: 0.6614\n",
      "Epoch: 266, AUC: 0.6998, AP: 0.6607\n",
      "Epoch: 267, AUC: 0.6993, AP: 0.6594\n",
      "Epoch: 268, AUC: 0.6996, AP: 0.6600\n",
      "Epoch: 269, AUC: 0.6998, AP: 0.6608\n",
      "Epoch: 270, AUC: 0.6999, AP: 0.6612\n",
      "Epoch: 271, AUC: 0.7001, AP: 0.6615\n",
      "Epoch: 272, AUC: 0.6996, AP: 0.6602\n",
      "Epoch: 273, AUC: 0.6996, AP: 0.6604\n",
      "Epoch: 274, AUC: 0.6999, AP: 0.6612\n",
      "Epoch: 275, AUC: 0.6993, AP: 0.6595\n",
      "Epoch: 276, AUC: 0.6995, AP: 0.6601\n",
      "Epoch: 277, AUC: 0.6999, AP: 0.6613\n",
      "Epoch: 278, AUC: 0.6998, AP: 0.6612\n",
      "Epoch: 279, AUC: 0.6998, AP: 0.6611\n",
      "Epoch: 280, AUC: 0.7000, AP: 0.6616\n",
      "Epoch: 281, AUC: 0.6996, AP: 0.6606\n",
      "Epoch: 282, AUC: 0.6997, AP: 0.6609\n",
      "Epoch: 283, AUC: 0.7000, AP: 0.6620\n",
      "Epoch: 284, AUC: 0.6998, AP: 0.6614\n",
      "Epoch: 285, AUC: 0.6995, AP: 0.6607\n",
      "Epoch: 286, AUC: 0.7000, AP: 0.6620\n",
      "Epoch: 287, AUC: 0.6995, AP: 0.6608\n",
      "Epoch: 288, AUC: 0.6995, AP: 0.6608\n",
      "Epoch: 289, AUC: 0.6999, AP: 0.6619\n",
      "Epoch: 290, AUC: 0.6996, AP: 0.6613\n",
      "Epoch: 291, AUC: 0.6995, AP: 0.6610\n",
      "Epoch: 292, AUC: 0.6997, AP: 0.6616\n",
      "Epoch: 293, AUC: 0.7000, AP: 0.6625\n",
      "Epoch: 294, AUC: 0.6994, AP: 0.6609\n",
      "Epoch: 295, AUC: 0.6998, AP: 0.6619\n",
      "Epoch: 296, AUC: 0.6997, AP: 0.6619\n",
      "Epoch: 297, AUC: 0.6994, AP: 0.6612\n",
      "Epoch: 298, AUC: 0.6997, AP: 0.6619\n",
      "Epoch: 299, AUC: 0.6999, AP: 0.6625\n",
      "Epoch: 300, AUC: 0.6994, AP: 0.6612\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GAE, VGAE\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/GVAE1_experiment_'+'2d_300_epochs')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "out_channels = 2\n",
    "in_channels = dataset[0].num_node_features\n",
    "epochs = 300\n",
    "variational = True\n",
    "linear = False\n",
    "\n",
    "if not variational and not linear:\n",
    "    model = GAE(GCNEncoder(in_channels, out_channels))\n",
    "elif not variational and linear:\n",
    "    model = GAE(LinearEncoder(in_channels, out_channels))\n",
    "elif variational and not linear:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
    "elif variational and linear:\n",
    "    model = VGAE(VariationalLinearEncoder(in_channels, out_channels))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    loss_tot = 0\n",
    "    loss_recon = 0\n",
    "    loss_kl = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        \n",
    "        loss = model.recon_loss(z, data.edge_index)\n",
    "        loss_recon += loss\n",
    "        \n",
    "        kl_loss = (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss_kl += kl_loss\n",
    "        \n",
    "        loss += kl_loss\n",
    "        loss_tot += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_tot += loss\n",
    "    loss_tot /= len(loader.dataset)\n",
    "    loss_recon /= len(loader.dataset)\n",
    "    loss_kl /= len(loader.dataset)\n",
    "    return loss_tot, loss_recon, loss_kl\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    auc_tot = 0\n",
    "    ap_tot = 0\n",
    "    for data in loader:\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        auc, ap = model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "        auc_tot += auc\n",
    "        ap_tot += ap\n",
    "    return auc_tot / len(loader), ap_tot / len(loader)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss, recon_loss, kl_loss = train(train_loader)\n",
    "    auc, ap = test(test_dataset)\n",
    "    writer.add_scalar('auc train',auc,epoch)\n",
    "    writer.add_scalar('ap train',ap,epoch)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a564f66f-e1c7-45cf-8280-dd67644de83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fdb10d0fa5cfda79\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fdb10d0fa5cfda79\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0724a0c-5d20-4d71-a926-9199c341e067",
   "metadata": {},
   "source": [
    "# SEAL + DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55dc073f-306e-41b9-9043-d2464f8c21f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/tmp/ipykernel_2883187/1265208625.py:94: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class SEALDataset(InMemoryDataset):\n",
    "    def __init__(self, dataset, num_hops, split='train'):\n",
    "        self.data = dataset[0]\n",
    "        self.num_hops = num_hops\n",
    "        super().__init__(dataset_root)\n",
    "        index = ['train', 'val', 'test'].index(split)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[index])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SEAL_train_data.pt', 'SEAL_val_data.pt', 'SEAL_test_data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        transform = RandomLinkSplit(num_val=0.05, num_test=0.1,\n",
    "                                    is_undirected=True, split_labels=True)\n",
    "        train_data, val_data, test_data = transform(self.data)\n",
    "\n",
    "        self._max_z = 0\n",
    "\n",
    "        # Collect a list of subgraphs for training, validation and testing:\n",
    "        train_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            train_data.edge_index, train_data.pos_edge_label_index, 1)\n",
    "        train_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            train_data.edge_index, train_data.neg_edge_label_index, 0)\n",
    "\n",
    "        val_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            val_data.edge_index, val_data.pos_edge_label_index, 1)\n",
    "        val_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            val_data.edge_index, val_data.neg_edge_label_index, 0)\n",
    "\n",
    "        test_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            test_data.edge_index, test_data.pos_edge_label_index, 1)\n",
    "        test_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            test_data.edge_index, test_data.neg_edge_label_index, 0)\n",
    "\n",
    "        # Convert node labeling to one-hot features.\n",
    "        for data in chain(train_pos_data_list, train_neg_data_list,\n",
    "                          val_pos_data_list, val_neg_data_list,\n",
    "                          test_pos_data_list, test_neg_data_list):\n",
    "            # We solely learn links from structure, dropping any node features:\n",
    "            data.x = F.one_hot(data.z, self._max_z + 1).to(torch.float)\n",
    "\n",
    "        torch.save(self.collate(train_pos_data_list + train_neg_data_list),\n",
    "                   self.processed_paths[0])\n",
    "        torch.save(self.collate(val_pos_data_list + val_neg_data_list),\n",
    "                   self.processed_paths[1])\n",
    "        torch.save(self.collate(test_pos_data_list + test_neg_data_list),\n",
    "                   self.processed_paths[2])\n",
    "\n",
    "    def extract_enclosing_subgraphs(self, edge_index, edge_label_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in edge_label_index.t().tolist():\n",
    "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "                [src, dst], self.num_hops, edge_index, relabel_nodes=True)\n",
    "            src, dst = mapping.tolist()\n",
    "\n",
    "            # Remove target link from the subgraph.\n",
    "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "            # Calculate node labeling.\n",
    "            z = self.drnl_node_labeling(sub_edge_index, src, dst,\n",
    "                                        num_nodes=sub_nodes.size(0))\n",
    "\n",
    "            data = Data(x=self.data.x[sub_nodes], z=z,\n",
    "                        edge_index=sub_edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self._max_z = max(int(z.max()), self._max_z)\n",
    "\n",
    "        return z.to(torch.long)\n",
    "\n",
    "dataset = [data]\n",
    "\n",
    "train_dataset = SEALDataset(dataset, num_hops=2, split='train')\n",
    "val_dataset = SEALDataset(dataset, num_hops=2, split='val')\n",
    "test_dataset = SEALDataset(dataset, num_hops=2, split='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0fd75c-e1fd-47e8-b365-53dca96c4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers, GNN=GCNConv, k=0.6):\n",
    "        super().__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = max(10, k)\n",
    "        self.k = int(k)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(train_dataset.num_features, hidden_channels))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GNN(hidden_channels, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_channels * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((self.k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.mlp = MLP([dense_dim, 128, 1], dropout=0.5, batch_norm=False)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [conv(xs[-1], edge_index).tanh()]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "        x = global_sort_pool(x, batch, self.k)\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = self.conv1(x).relu()\n",
    "        x = self.maxpool1d(x)\n",
    "        x = self.conv2(x).relu()\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4a11510-b059-4162-abb8-67555b70b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.5439, Val: 0.8484, Test: 0.8939\n",
      "Epoch: 02, Loss: 0.4729, Val: 0.8508, Test: 0.8964\n",
      "Epoch: 03, Loss: 0.4682, Val: 0.8532, Test: 0.8993\n",
      "Epoch: 04, Loss: 0.4654, Val: 0.8562, Test: 0.9029\n",
      "Epoch: 05, Loss: 0.4600, Val: 0.8595, Test: 0.9057\n",
      "Epoch: 06, Loss: 0.4584, Val: 0.8601, Test: 0.9067\n",
      "Epoch: 07, Loss: 0.4546, Val: 0.8630, Test: 0.9085\n",
      "Epoch: 08, Loss: 0.4515, Val: 0.8620, Test: 0.9085\n",
      "Epoch: 09, Loss: 0.4477, Val: 0.8633, Test: 0.9105\n",
      "Epoch: 10, Loss: 0.4458, Val: 0.8654, Test: 0.9116\n",
      "Epoch: 11, Loss: 0.4447, Val: 0.8671, Test: 0.9119\n",
      "Epoch: 12, Loss: 0.4444, Val: 0.8678, Test: 0.9132\n",
      "Epoch: 13, Loss: 0.4419, Val: 0.8682, Test: 0.9140\n",
      "Epoch: 14, Loss: 0.4423, Val: 0.8671, Test: 0.9140\n",
      "Epoch: 15, Loss: 0.4401, Val: 0.8672, Test: 0.9140\n",
      "Epoch: 16, Loss: 0.4406, Val: 0.8668, Test: 0.9140\n",
      "Epoch: 17, Loss: 0.4395, Val: 0.8675, Test: 0.9140\n",
      "Epoch: 18, Loss: 0.4396, Val: 0.8679, Test: 0.9140\n",
      "Epoch: 19, Loss: 0.4388, Val: 0.8673, Test: 0.9140\n",
      "Epoch: 20, Loss: 0.4380, Val: 0.8674, Test: 0.9140\n",
      "Epoch: 21, Loss: 0.4374, Val: 0.8681, Test: 0.9140\n",
      "Epoch: 22, Loss: 0.4374, Val: 0.8683, Test: 0.9148\n",
      "Epoch: 23, Loss: 0.4375, Val: 0.8684, Test: 0.9150\n",
      "Epoch: 24, Loss: 0.4355, Val: 0.8683, Test: 0.9150\n",
      "Epoch: 25, Loss: 0.4357, Val: 0.8681, Test: 0.9150\n",
      "Epoch: 26, Loss: 0.4346, Val: 0.8678, Test: 0.9150\n",
      "Epoch: 27, Loss: 0.4354, Val: 0.8683, Test: 0.9150\n",
      "Epoch: 28, Loss: 0.4351, Val: 0.8681, Test: 0.9150\n",
      "Epoch: 29, Loss: 0.4349, Val: 0.8682, Test: 0.9150\n",
      "Epoch: 30, Loss: 0.4337, Val: 0.8692, Test: 0.9157\n",
      "Epoch: 31, Loss: 0.4330, Val: 0.8683, Test: 0.9157\n",
      "Epoch: 32, Loss: 0.4333, Val: 0.8680, Test: 0.9157\n",
      "Epoch: 33, Loss: 0.4328, Val: 0.8684, Test: 0.9157\n",
      "Epoch: 34, Loss: 0.4325, Val: 0.8694, Test: 0.9157\n",
      "Epoch: 35, Loss: 0.4314, Val: 0.8690, Test: 0.9157\n",
      "Epoch: 36, Loss: 0.4312, Val: 0.8691, Test: 0.9157\n",
      "Epoch: 37, Loss: 0.4307, Val: 0.8691, Test: 0.9157\n",
      "Epoch: 38, Loss: 0.4310, Val: 0.8684, Test: 0.9157\n",
      "Epoch: 39, Loss: 0.4310, Val: 0.8692, Test: 0.9157\n",
      "Epoch: 40, Loss: 0.4309, Val: 0.8688, Test: 0.9157\n",
      "Epoch: 41, Loss: 0.4301, Val: 0.8694, Test: 0.9157\n",
      "Epoch: 42, Loss: 0.4307, Val: 0.8687, Test: 0.9157\n",
      "Epoch: 43, Loss: 0.4302, Val: 0.8694, Test: 0.9157\n",
      "Epoch: 44, Loss: 0.4294, Val: 0.8697, Test: 0.9166\n",
      "Epoch: 45, Loss: 0.4297, Val: 0.8697, Test: 0.9166\n",
      "Epoch: 46, Loss: 0.4297, Val: 0.8697, Test: 0.9166\n",
      "Epoch: 47, Loss: 0.4290, Val: 0.8687, Test: 0.9166\n",
      "Epoch: 48, Loss: 0.4291, Val: 0.8698, Test: 0.9167\n",
      "Epoch: 49, Loss: 0.4287, Val: 0.8686, Test: 0.9167\n",
      "Epoch: 50, Loss: 0.4290, Val: 0.8690, Test: 0.9167\n"
     ]
    }
   ],
   "source": [
    "model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(logits.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
    "\n",
    "\n",
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    val_auc = test(val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        test_auc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1f920-d8e1-4ed1-a69c-c52b53bc3db5",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272c22d-90f6-43af-a4bd-9d5ccdacdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import GAE, RGCNConv\n",
    "\n",
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        self.node_emb = Parameter(torch.Tensor(num_nodes, hidden_channels))\n",
    "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_emb)\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.node_emb\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.rel_emb = Parameter(torch.Tensor(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)\n",
    "\n",
    "\n",
    "model = GAE(\n",
    "    RGCNEncoder(data.num_nodes, hidden_channels=500,\n",
    "                num_relations=dataset.num_relations),\n",
    "    DistMultDecoder(dataset.num_relations // 2, hidden_channels=500),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def negative_sampling(edge_index, num_nodes):\n",
    "    # Sample edges by corrupting either the subject or the object of each edge.\n",
    "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
    "    mask_2 = ~mask_1\n",
    "\n",
    "    neg_edge_index = edge_index.clone()\n",
    "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(), ))\n",
    "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(), ))\n",
    "    return neg_edge_index\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.train_edge_index, data.train_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "    cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "    reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
    "    loss = cross_entropy_loss + 1e-2 * reg_loss\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    valid_mrr = compute_mrr(z, data.valid_edge_index, data.valid_edge_type)\n",
    "    test_mrr = compute_mrr(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    return valid_mrr, test_mrr\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mrr(z, edge_index, edge_type):\n",
    "    ranks = []\n",
    "    for i in tqdm(range(edge_type.numel())):\n",
    "        (src, dst), rel = edge_index[:, i], edge_type[i]\n",
    "\n",
    "        # Try all nodes as tails, but delete true triplets:\n",
    "        tail_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            tail_mask[tails[(heads == src) & (types == rel)]] = False\n",
    "\n",
    "        tail = torch.arange(data.num_nodes)[tail_mask]\n",
    "        tail = torch.cat([torch.tensor([dst]), tail])\n",
    "        head = torch.full_like(tail, fill_value=src)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(tail, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        perm = out.argsort(descending=True)\n",
    "        rank = int((perm == 0).nonzero(as_tuple=False).view(-1)[0])\n",
    "        ranks.append(rank + 1)\n",
    "\n",
    "        # Try all nodes as heads, but delete true triplets:\n",
    "        head_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            head_mask[heads[(tails == dst) & (types == rel)]] = False\n",
    "\n",
    "        head = torch.arange(data.num_nodes)[head_mask]\n",
    "        head = torch.cat([torch.tensor([src]), head])\n",
    "        tail = torch.full_like(head, fill_value=dst)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(head, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        perm = out.argsort(descending=True)\n",
    "        rank = int((perm == 0).nonzero(as_tuple=False).view(-1)[0])\n",
    "        ranks.append(rank + 1)\n",
    "\n",
    "    return (1. / torch.tensor(ranks, dtype=torch.float)).mean()\n",
    "\n",
    "\n",
    "for epoch in range(1, 10001):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:05d}, Loss: {loss:.4f}')\n",
    "    if (epoch % 500) == 0:\n",
    "        valid_mrr, test_mrr = test()\n",
    "        print(f'Val MRR: {valid_mrr:.4f}, Test MRR: {test_mrr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
