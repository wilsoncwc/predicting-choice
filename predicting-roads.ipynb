{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7958681-6281-4f3f-92b8-ee6f2a1c8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/wwc4618/venv/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSx metrics of 346 local authorities retrieved\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from itertools import chain\n",
    "\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import BCEWithLogitsLoss, Conv1d, MaxPool1d, ModuleList\n",
    "\n",
    "from torch_geometric.data import Data, Batch, InMemoryDataset, download_url, extract_zip\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import RandomLinkSplit, OneHotDegree\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from train import run, run_single\n",
    "from utils.load_geodata import load_gdf, load_graph, process_graph\n",
    "from utils.constants import project_root, dataset_root\n",
    "from utils.constants import rank_fields, log_fields, all_feature_fields, feats, included_places\n",
    "from utils.valid_edge import is_valid\n",
    "\n",
    "print(f'SSx metrics of {len(included_places)} local authorities retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600dd4a1-4dde-4c33-bee7-f307078c4d99",
   "metadata": {},
   "source": [
    "## Train on multiple LAs and test on a hold-out set of LAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0339c468-2708-446c-ba8f-0a9e7116a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1 of expt GAE_20d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (1.74s/epoch): Train AUC: 0.7862, Train AP: 0.3897,Test AUC: 0.7832, Test AP: 0.3874\n",
      "Epoch 020 (1.74s/epoch): Train AUC: 0.8087, Train AP: 0.4102,Test AUC: 0.8050, Test AP: 0.4048\n",
      "Epoch 030 (1.74s/epoch): Train AUC: 0.8231, Train AP: 0.4397,Test AUC: 0.8195, Test AP: 0.4338\n",
      "Epoch 040 (1.74s/epoch): Train AUC: 0.8322, Train AP: 0.4595,Test AUC: 0.8285, Test AP: 0.4533\n",
      "Epoch 050 (1.74s/epoch): Train AUC: 0.8499, Train AP: 0.5007,Test AUC: 0.8469, Test AP: 0.4955\n",
      "Epoch 060 (1.74s/epoch): Train AUC: 0.8438, Train AP: 0.4762,Test AUC: 0.8404, Test AP: 0.4707\n",
      "Epoch 070 (1.74s/epoch): Train AUC: 0.8342, Train AP: 0.4497,Test AUC: 0.8308, Test AP: 0.4452\n",
      "Epoch 080 (1.75s/epoch): Train AUC: 0.8436, Train AP: 0.4727,Test AUC: 0.8403, Test AP: 0.4677\n",
      "Epoch 090 (1.76s/epoch): Train AUC: 0.8435, Train AP: 0.4686,Test AUC: 0.8401, Test AP: 0.4635\n",
      "Epoch 100 (1.74s/epoch): Train AUC: 0.8494, Train AP: 0.4835,Test AUC: 0.8464, Test AP: 0.4793\n",
      "Epoch 110 (1.74s/epoch): Train AUC: 0.8435, Train AP: 0.4654,Test AUC: 0.8400, Test AP: 0.4591\n",
      "Epoch 120 (1.74s/epoch): Train AUC: 0.8511, Train AP: 0.4877,Test AUC: 0.8480, Test AP: 0.4835\n",
      "Epoch 130 (1.74s/epoch): Train AUC: 0.8537, Train AP: 0.4944,Test AUC: 0.8508, Test AP: 0.4908\n",
      "Epoch 140 (1.74s/epoch): Train AUC: 0.8510, Train AP: 0.4857,Test AUC: 0.8481, Test AP: 0.4826\n",
      "Epoch 150 (1.74s/epoch): Train AUC: 0.8524, Train AP: 0.4889,Test AUC: 0.8495, Test AP: 0.4854\n",
      "Epoch 160 (1.74s/epoch): Train AUC: 0.8516, Train AP: 0.4853,Test AUC: 0.8486, Test AP: 0.4811\n",
      "Epoch 170 (1.74s/epoch): Train AUC: 0.8531, Train AP: 0.4888,Test AUC: 0.8502, Test AP: 0.4850\n",
      "Epoch 180 (1.74s/epoch): Train AUC: 0.8544, Train AP: 0.4908,Test AUC: 0.8513, Test AP: 0.4858\n",
      "Epoch 190 (1.74s/epoch): Train AUC: 0.8587, Train AP: 0.5040,Test AUC: 0.8558, Test AP: 0.5000\n",
      "Epoch 200 (1.74s/epoch): Train AUC: 0.8625, Train AP: 0.5146,Test AUC: 0.8600, Test AP: 0.5122\n",
      "Epoch 210 (1.74s/epoch): Train AUC: 0.8547, Train AP: 0.4871,Test AUC: 0.8517, Test AP: 0.4827\n",
      "Epoch 220 (1.74s/epoch): Train AUC: 0.8573, Train AP: 0.4949,Test AUC: 0.8543, Test AP: 0.4899\n",
      "Epoch 230 (1.74s/epoch): Train AUC: 0.8609, Train AP: 0.5077,Test AUC: 0.8580, Test AP: 0.5027\n",
      "Epoch 240 (1.74s/epoch): Train AUC: 0.8560, Train AP: 0.4862,Test AUC: 0.8529, Test AP: 0.4805\n",
      "Epoch 250 (1.74s/epoch): Train AUC: 0.8606, Train AP: 0.5034,Test AUC: 0.8577, Test AP: 0.4985\n",
      "Epoch 260 (1.74s/epoch): Train AUC: 0.8593, Train AP: 0.4983,Test AUC: 0.8562, Test AP: 0.4930\n",
      "Epoch 270 (1.74s/epoch): Train AUC: 0.8580, Train AP: 0.4929,Test AUC: 0.8548, Test AP: 0.4874\n",
      "Epoch 280 (1.74s/epoch): Train AUC: 0.8555, Train AP: 0.4845,Test AUC: 0.8520, Test AP: 0.4771\n",
      "Epoch 290 (1.74s/epoch): Train AUC: 0.8612, Train AP: 0.5041,Test AUC: 0.8582, Test AP: 0.4989\n",
      "Epoch 300 (1.75s/epoch): Train AUC: 0.8581, Train AP: 0.4914,Test AUC: 0.8551, Test AP: 0.4870\n",
      "Epoch 310 (1.74s/epoch): Train AUC: 0.8628, Train AP: 0.5048,Test AUC: 0.8598, Test AP: 0.4993\n",
      "Epoch 320 (1.74s/epoch): Train AUC: 0.8627, Train AP: 0.5039,Test AUC: 0.8597, Test AP: 0.4983\n",
      "Epoch 330 (1.74s/epoch): Train AUC: 0.8625, Train AP: 0.5006,Test AUC: 0.8595, Test AP: 0.4951\n",
      "Epoch 340 (1.74s/epoch): Train AUC: 0.8637, Train AP: 0.5034,Test AUC: 0.8607, Test AP: 0.4980\n",
      "Epoch 350 (1.74s/epoch): Train AUC: 0.8669, Train AP: 0.5135,Test AUC: 0.8640, Test AP: 0.5080\n",
      "Epoch 360 (1.73s/epoch): Train AUC: 0.8652, Train AP: 0.5087,Test AUC: 0.8622, Test AP: 0.5032\n",
      "Epoch 370 (1.74s/epoch): Train AUC: 0.8625, Train AP: 0.4997,Test AUC: 0.8593, Test AP: 0.4934\n",
      "Epoch 380 (1.74s/epoch): Train AUC: 0.8668, Train AP: 0.5132,Test AUC: 0.8637, Test AP: 0.5071\n",
      "Epoch 390 (1.73s/epoch): Train AUC: 0.8624, Train AP: 0.4959,Test AUC: 0.8593, Test AP: 0.4902\n",
      "Epoch 400 (1.74s/epoch): Train AUC: 0.8649, Train AP: 0.5043,Test AUC: 0.8616, Test AP: 0.4973\n",
      "Epoch 410 (1.74s/epoch): Train AUC: 0.8624, Train AP: 0.4972,Test AUC: 0.8593, Test AP: 0.4911\n",
      "Epoch 420 (1.74s/epoch): Train AUC: 0.8650, Train AP: 0.5049,Test AUC: 0.8619, Test AP: 0.4989\n",
      "Epoch 430 (1.73s/epoch): Train AUC: 0.8634, Train AP: 0.4972,Test AUC: 0.8604, Test AP: 0.4911\n",
      "Epoch 440 (1.73s/epoch): Train AUC: 0.8673, Train AP: 0.5120,Test AUC: 0.8641, Test AP: 0.5050\n",
      "Epoch 450 (1.74s/epoch): Train AUC: 0.8644, Train AP: 0.4999,Test AUC: 0.8612, Test AP: 0.4929\n",
      "Epoch 460 (1.74s/epoch): Train AUC: 0.8628, Train AP: 0.4954,Test AUC: 0.8596, Test AP: 0.4889\n",
      "Epoch 470 (1.74s/epoch): Train AUC: 0.8672, Train AP: 0.5094,Test AUC: 0.8642, Test AP: 0.5037\n",
      "Epoch 480 (1.74s/epoch): Train AUC: 0.8658, Train AP: 0.5029,Test AUC: 0.8628, Test AP: 0.4968\n",
      "Epoch 490 (1.74s/epoch): Train AUC: 0.8662, Train AP: 0.5049,Test AUC: 0.8632, Test AP: 0.4992\n",
      "Epoch 500 (1.73s/epoch): Train AUC: 0.8669, Train AP: 0.5037,Test AUC: 0.8641, Test AP: 0.4984\n",
      "Running iteration 2 of expt GAE_20d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (1.74s/epoch): Train AUC: 0.7885, Train AP: 0.3807,Test AUC: 0.7852, Test AP: 0.3794\n",
      "Epoch 020 (1.75s/epoch): Train AUC: 0.8053, Train AP: 0.3906,Test AUC: 0.8023, Test AP: 0.3891\n",
      "Epoch 030 (1.74s/epoch): Train AUC: 0.8213, Train AP: 0.4251,Test AUC: 0.8184, Test AP: 0.4229\n",
      "Epoch 040 (1.74s/epoch): Train AUC: 0.8252, Train AP: 0.4291,Test AUC: 0.8225, Test AP: 0.4281\n",
      "Epoch 050 (1.74s/epoch): Train AUC: 0.8242, Train AP: 0.4249,Test AUC: 0.8213, Test AP: 0.4231\n",
      "Epoch 060 (1.75s/epoch): Train AUC: 0.8286, Train AP: 0.4335,Test AUC: 0.8260, Test AP: 0.4323\n",
      "Epoch 070 (1.74s/epoch): Train AUC: 0.8264, Train AP: 0.4237,Test AUC: 0.8238, Test AP: 0.4235\n",
      "Epoch 080 (1.74s/epoch): Train AUC: 0.8250, Train AP: 0.4200,Test AUC: 0.8220, Test AP: 0.4178\n",
      "Epoch 090 (1.74s/epoch): Train AUC: 0.8302, Train AP: 0.4325,Test AUC: 0.8273, Test AP: 0.4310\n",
      "Epoch 100 (1.74s/epoch): Train AUC: 0.8323, Train AP: 0.4380,Test AUC: 0.8293, Test AP: 0.4352\n",
      "Epoch 110 (1.74s/epoch): Train AUC: 0.8320, Train AP: 0.4327,Test AUC: 0.8293, Test AP: 0.4312\n",
      "Epoch 120 (1.74s/epoch): Train AUC: 0.8344, Train AP: 0.4396,Test AUC: 0.8313, Test AP: 0.4361\n",
      "Epoch 130 (1.74s/epoch): Train AUC: 0.8363, Train AP: 0.4399,Test AUC: 0.8337, Test AP: 0.4382\n",
      "Epoch 140 (1.74s/epoch): Train AUC: 0.8410, Train AP: 0.4537,Test AUC: 0.8384, Test AP: 0.4520\n",
      "Epoch 150 (1.74s/epoch): Train AUC: 0.8398, Train AP: 0.4477,Test AUC: 0.8371, Test AP: 0.4457\n",
      "Epoch 160 (1.74s/epoch): Train AUC: 0.8503, Train AP: 0.4831,Test AUC: 0.8476, Test AP: 0.4807\n",
      "Epoch 170 (1.74s/epoch): Train AUC: 0.8449, Train AP: 0.4621,Test AUC: 0.8422, Test AP: 0.4598\n",
      "Epoch 180 (1.74s/epoch): Train AUC: 0.8498, Train AP: 0.4772,Test AUC: 0.8471, Test AP: 0.4746\n",
      "Epoch 190 (1.74s/epoch): Train AUC: 0.8517, Train AP: 0.4810,Test AUC: 0.8490, Test AP: 0.4787\n",
      "Epoch 200 (1.73s/epoch): Train AUC: 0.8475, Train AP: 0.4674,Test AUC: 0.8446, Test AP: 0.4640\n",
      "Epoch 210 (1.73s/epoch): Train AUC: 0.8472, Train AP: 0.4653,Test AUC: 0.8446, Test AP: 0.4635\n",
      "Epoch 220 (1.73s/epoch): Train AUC: 0.8508, Train AP: 0.4772,Test AUC: 0.8480, Test AP: 0.4743\n",
      "Epoch 230 (1.74s/epoch): Train AUC: 0.8516, Train AP: 0.4782,Test AUC: 0.8489, Test AP: 0.4756\n",
      "Epoch 240 (1.73s/epoch): Train AUC: 0.8505, Train AP: 0.4775,Test AUC: 0.8474, Test AP: 0.4739\n",
      "Epoch 250 (1.73s/epoch): Train AUC: 0.8481, Train AP: 0.4672,Test AUC: 0.8451, Test AP: 0.4634\n",
      "Epoch 260 (1.73s/epoch): Train AUC: 0.8499, Train AP: 0.4722,Test AUC: 0.8471, Test AP: 0.4693\n",
      "Epoch 270 (1.73s/epoch): Train AUC: 0.8536, Train AP: 0.4822,Test AUC: 0.8508, Test AP: 0.4785\n",
      "Epoch 280 (1.73s/epoch): Train AUC: 0.8521, Train AP: 0.4767,Test AUC: 0.8492, Test AP: 0.4727\n",
      "Epoch 290 (1.73s/epoch): Train AUC: 0.8530, Train AP: 0.4809,Test AUC: 0.8499, Test AP: 0.4762\n",
      "Epoch 300 (1.73s/epoch): Train AUC: 0.8522, Train AP: 0.4761,Test AUC: 0.8492, Test AP: 0.4721\n",
      "Epoch 310 (1.73s/epoch): Train AUC: 0.8488, Train AP: 0.4663,Test AUC: 0.8456, Test AP: 0.4617\n",
      "Epoch 320 (1.73s/epoch): Train AUC: 0.8558, Train AP: 0.4894,Test AUC: 0.8528, Test AP: 0.4852\n",
      "Epoch 330 (1.73s/epoch): Train AUC: 0.8561, Train AP: 0.4928,Test AUC: 0.8529, Test AP: 0.4886\n",
      "Epoch 340 (1.73s/epoch): Train AUC: 0.8540, Train AP: 0.4817,Test AUC: 0.8509, Test AP: 0.4776\n",
      "Epoch 350 (1.73s/epoch): Train AUC: 0.8513, Train AP: 0.4706,Test AUC: 0.8482, Test AP: 0.4666\n",
      "Epoch 360 (1.74s/epoch): Train AUC: 0.8554, Train AP: 0.4850,Test AUC: 0.8524, Test AP: 0.4813\n",
      "Epoch 370 (1.74s/epoch): Train AUC: 0.8553, Train AP: 0.4849,Test AUC: 0.8523, Test AP: 0.4808\n",
      "Epoch 380 (1.74s/epoch): Train AUC: 0.8558, Train AP: 0.4856,Test AUC: 0.8528, Test AP: 0.4814\n",
      "Epoch 390 (1.73s/epoch): Train AUC: 0.8530, Train AP: 0.4783,Test AUC: 0.8498, Test AP: 0.4740\n",
      "Epoch 400 (1.73s/epoch): Train AUC: 0.8554, Train AP: 0.4847,Test AUC: 0.8525, Test AP: 0.4819\n",
      "Epoch 410 (1.74s/epoch): Train AUC: 0.8577, Train AP: 0.4907,Test AUC: 0.8548, Test AP: 0.4872\n",
      "Epoch 420 (1.73s/epoch): Train AUC: 0.8566, Train AP: 0.4879,Test AUC: 0.8541, Test AP: 0.4863\n",
      "Epoch 430 (1.74s/epoch): Train AUC: 0.8559, Train AP: 0.4848,Test AUC: 0.8531, Test AP: 0.4817\n",
      "Epoch 440 (1.73s/epoch): Train AUC: 0.8581, Train AP: 0.4896,Test AUC: 0.8550, Test AP: 0.4850\n",
      "Epoch 450 (1.74s/epoch): Train AUC: 0.8534, Train AP: 0.4767,Test AUC: 0.8501, Test AP: 0.4725\n",
      "Epoch 460 (1.74s/epoch): Train AUC: 0.8544, Train AP: 0.4778,Test AUC: 0.8511, Test AP: 0.4732\n",
      "Epoch 470 (1.74s/epoch): Train AUC: 0.8559, Train AP: 0.4847,Test AUC: 0.8531, Test AP: 0.4818\n",
      "Epoch 480 (1.74s/epoch): Train AUC: 0.8589, Train AP: 0.4937,Test AUC: 0.8559, Test AP: 0.4895\n",
      "Epoch 490 (1.74s/epoch): Train AUC: 0.8569, Train AP: 0.4865,Test AUC: 0.8537, Test AP: 0.4824\n",
      "Epoch 500 (1.74s/epoch): Train AUC: 0.8529, Train AP: 0.4765,Test AUC: 0.8496, Test AP: 0.4725\n",
      "Running iteration 3 of expt GAE_20d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (1.75s/epoch): Train AUC: 0.7995, Train AP: 0.4014,Test AUC: 0.7965, Test AP: 0.3984\n",
      "Epoch 020 (1.75s/epoch): Train AUC: 0.8132, Train AP: 0.4156,Test AUC: 0.8095, Test AP: 0.4103\n",
      "Epoch 030 (1.74s/epoch): Train AUC: 0.8171, Train AP: 0.4149,Test AUC: 0.8140, Test AP: 0.4115\n",
      "Epoch 040 (1.74s/epoch): Train AUC: 0.8179, Train AP: 0.4113,Test AUC: 0.8148, Test AP: 0.4082\n",
      "Epoch 050 (1.74s/epoch): Train AUC: 0.8161, Train AP: 0.4057,Test AUC: 0.8132, Test AP: 0.4032\n",
      "Epoch 060 (1.74s/epoch): Train AUC: 0.8143, Train AP: 0.3993,Test AUC: 0.8109, Test AP: 0.3955\n",
      "Epoch 070 (1.74s/epoch): Train AUC: 0.8137, Train AP: 0.3967,Test AUC: 0.8102, Test AP: 0.3925\n",
      "Epoch 080 (1.74s/epoch): Train AUC: 0.8142, Train AP: 0.3986,Test AUC: 0.8105, Test AP: 0.3937\n",
      "Epoch 090 (1.77s/epoch): Train AUC: 0.8170, Train AP: 0.3999,Test AUC: 0.8134, Test AP: 0.3957\n",
      "Epoch 100 (1.74s/epoch): Train AUC: 0.8190, Train AP: 0.4023,Test AUC: 0.8159, Test AP: 0.4000\n",
      "Epoch 110 (1.74s/epoch): Train AUC: 0.8214, Train AP: 0.4070,Test AUC: 0.8177, Test AP: 0.4032\n",
      "Epoch 120 (1.74s/epoch): Train AUC: 0.8257, Train AP: 0.4161,Test AUC: 0.8219, Test AP: 0.4109\n",
      "Epoch 130 (1.74s/epoch): Train AUC: 0.8227, Train AP: 0.4079,Test AUC: 0.8188, Test AP: 0.4029\n",
      "Epoch 140 (1.74s/epoch): Train AUC: 0.8270, Train AP: 0.4173,Test AUC: 0.8232, Test AP: 0.4123\n",
      "Epoch 150 (1.74s/epoch): Train AUC: 0.8268, Train AP: 0.4145,Test AUC: 0.8230, Test AP: 0.4104\n",
      "Epoch 160 (1.74s/epoch): Train AUC: 0.8287, Train AP: 0.4164,Test AUC: 0.8249, Test AP: 0.4118\n",
      "Epoch 170 (1.74s/epoch): Train AUC: 0.8303, Train AP: 0.4221,Test AUC: 0.8264, Test AP: 0.4166\n",
      "Epoch 180 (1.74s/epoch): Train AUC: 0.8335, Train AP: 0.4300,Test AUC: 0.8294, Test AP: 0.4235\n",
      "Epoch 190 (1.73s/epoch): Train AUC: 0.8404, Train AP: 0.4478,Test AUC: 0.8367, Test AP: 0.4430\n",
      "Epoch 200 (1.74s/epoch): Train AUC: 0.8413, Train AP: 0.4472,Test AUC: 0.8377, Test AP: 0.4429\n",
      "Epoch 210 (1.74s/epoch): Train AUC: 0.8452, Train AP: 0.4599,Test AUC: 0.8416, Test AP: 0.4555\n",
      "Epoch 220 (1.73s/epoch): Train AUC: 0.8452, Train AP: 0.4572,Test AUC: 0.8417, Test AP: 0.4532\n",
      "Epoch 230 (1.74s/epoch): Train AUC: 0.8524, Train AP: 0.4779,Test AUC: 0.8489, Test AP: 0.4735\n",
      "Epoch 240 (1.74s/epoch): Train AUC: 0.8515, Train AP: 0.4784,Test AUC: 0.8482, Test AP: 0.4749\n",
      "Epoch 250 (1.73s/epoch): Train AUC: 0.8509, Train AP: 0.4746,Test AUC: 0.8470, Test AP: 0.4681\n",
      "Epoch 260 (1.73s/epoch): Train AUC: 0.8533, Train AP: 0.4764,Test AUC: 0.8497, Test AP: 0.4714\n",
      "Epoch 270 (1.73s/epoch): Train AUC: 0.8560, Train AP: 0.4847,Test AUC: 0.8526, Test AP: 0.4801\n",
      "Epoch 280 (1.74s/epoch): Train AUC: 0.8570, Train AP: 0.4929,Test AUC: 0.8532, Test AP: 0.4878\n",
      "Epoch 290 (1.73s/epoch): Train AUC: 0.8599, Train AP: 0.4953,Test AUC: 0.8568, Test AP: 0.4920\n",
      "Epoch 300 (1.74s/epoch): Train AUC: 0.8585, Train AP: 0.4906,Test AUC: 0.8556, Test AP: 0.4880\n",
      "Epoch 310 (1.73s/epoch): Train AUC: 0.8579, Train AP: 0.4881,Test AUC: 0.8542, Test AP: 0.4820\n",
      "Epoch 320 (1.74s/epoch): Train AUC: 0.8564, Train AP: 0.4841,Test AUC: 0.8527, Test AP: 0.4780\n",
      "Epoch 330 (1.73s/epoch): Train AUC: 0.8570, Train AP: 0.4823,Test AUC: 0.8533, Test AP: 0.4761\n",
      "Epoch 340 (1.74s/epoch): Train AUC: 0.8598, Train AP: 0.4930,Test AUC: 0.8565, Test AP: 0.4883\n",
      "Epoch 350 (1.73s/epoch): Train AUC: 0.8600, Train AP: 0.4935,Test AUC: 0.8565, Test AP: 0.4878\n",
      "Epoch 360 (1.74s/epoch): Train AUC: 0.8591, Train AP: 0.4895,Test AUC: 0.8556, Test AP: 0.4840\n",
      "Epoch 370 (1.74s/epoch): Train AUC: 0.8595, Train AP: 0.4882,Test AUC: 0.8565, Test AP: 0.4849\n",
      "Epoch 380 (1.73s/epoch): Train AUC: 0.8630, Train AP: 0.5020,Test AUC: 0.8597, Test AP: 0.4970\n",
      "Epoch 390 (1.73s/epoch): Train AUC: 0.8587, Train AP: 0.4847,Test AUC: 0.8553, Test AP: 0.4797\n",
      "Epoch 400 (1.74s/epoch): Train AUC: 0.8593, Train AP: 0.4885,Test AUC: 0.8555, Test AP: 0.4818\n",
      "Epoch 410 (1.74s/epoch): Train AUC: 0.8621, Train AP: 0.4991,Test AUC: 0.8591, Test AP: 0.4953\n",
      "Epoch 420 (1.73s/epoch): Train AUC: 0.8605, Train AP: 0.4938,Test AUC: 0.8571, Test AP: 0.4888\n",
      "Epoch 430 (1.73s/epoch): Train AUC: 0.8616, Train AP: 0.4982,Test AUC: 0.8583, Test AP: 0.4936\n",
      "Epoch 440 (1.73s/epoch): Train AUC: 0.8641, Train AP: 0.5039,Test AUC: 0.8609, Test AP: 0.4993\n",
      "Epoch 450 (1.73s/epoch): Train AUC: 0.8657, Train AP: 0.5066,Test AUC: 0.8624, Test AP: 0.5013\n",
      "Epoch 460 (1.73s/epoch): Train AUC: 0.8622, Train AP: 0.4988,Test AUC: 0.8593, Test AP: 0.4952\n",
      "Epoch 470 (1.73s/epoch): Train AUC: 0.8613, Train AP: 0.4931,Test AUC: 0.8583, Test AP: 0.4893\n",
      "Epoch 480 (1.73s/epoch): Train AUC: 0.8624, Train AP: 0.4938,Test AUC: 0.8592, Test AP: 0.4888\n",
      "Epoch 490 (1.73s/epoch): Train AUC: 0.8634, Train AP: 0.5009,Test AUC: 0.8598, Test AP: 0.4943\n",
      "Epoch 500 (1.73s/epoch): Train AUC: 0.8677, Train AP: 0.5104,Test AUC: 0.8649, Test AP: 0.5071\n",
      "Running iteration 1 of expt GAE_10d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.76s/epoch): Train AUC: 0.7659, Train AP: 0.3373,Test AUC: 0.7644, Test AP: 0.3361\n",
      "Epoch 020 (1.76s/epoch): Train AUC: 0.7959, Train AP: 0.3710,Test AUC: 0.7925, Test AP: 0.3678\n",
      "Epoch 030 (1.76s/epoch): Train AUC: 0.8043, Train AP: 0.3825,Test AUC: 0.8009, Test AP: 0.3796\n",
      "Epoch 040 (1.76s/epoch): Train AUC: 0.8090, Train AP: 0.3896,Test AUC: 0.8052, Test AP: 0.3859\n",
      "Epoch 050 (1.76s/epoch): Train AUC: 0.8116, Train AP: 0.3894,Test AUC: 0.8078, Test AP: 0.3847\n",
      "Epoch 060 (1.76s/epoch): Train AUC: 0.8144, Train AP: 0.3959,Test AUC: 0.8105, Test AP: 0.3912\n",
      "Epoch 070 (1.76s/epoch): Train AUC: 0.8179, Train AP: 0.4005,Test AUC: 0.8139, Test AP: 0.3955\n",
      "Epoch 080 (1.75s/epoch): Train AUC: 0.8207, Train AP: 0.4057,Test AUC: 0.8165, Test AP: 0.4000\n",
      "Epoch 090 (1.76s/epoch): Train AUC: 0.8240, Train AP: 0.4141,Test AUC: 0.8195, Test AP: 0.4073\n",
      "Epoch 100 (1.76s/epoch): Train AUC: 0.8253, Train AP: 0.4103,Test AUC: 0.8212, Test AP: 0.4055\n",
      "Epoch 110 (1.76s/epoch): Train AUC: 0.8274, Train AP: 0.4169,Test AUC: 0.8230, Test AP: 0.4112\n",
      "Epoch 120 (1.76s/epoch): Train AUC: 0.8285, Train AP: 0.4162,Test AUC: 0.8240, Test AP: 0.4106\n",
      "Epoch 130 (1.80s/epoch): Train AUC: 0.8315, Train AP: 0.4235,Test AUC: 0.8271, Test AP: 0.4181\n",
      "Epoch 140 (1.83s/epoch): Train AUC: 0.8328, Train AP: 0.4221,Test AUC: 0.8284, Test AP: 0.4168\n",
      "Epoch 150 (1.81s/epoch): Train AUC: 0.8341, Train AP: 0.4227,Test AUC: 0.8297, Test AP: 0.4172\n",
      "Epoch 160 (1.82s/epoch): Train AUC: 0.8369, Train AP: 0.4308,Test AUC: 0.8325, Test AP: 0.4252\n",
      "Epoch 170 (1.76s/epoch): Train AUC: 0.8377, Train AP: 0.4312,Test AUC: 0.8334, Test AP: 0.4261\n",
      "Epoch 180 (1.76s/epoch): Train AUC: 0.8375, Train AP: 0.4270,Test AUC: 0.8330, Test AP: 0.4211\n",
      "Epoch 190 (1.76s/epoch): Train AUC: 0.8393, Train AP: 0.4324,Test AUC: 0.8346, Test AP: 0.4259\n",
      "Epoch 200 (1.76s/epoch): Train AUC: 0.8389, Train AP: 0.4321,Test AUC: 0.8349, Test AP: 0.4291\n",
      "Epoch 210 (1.76s/epoch): Train AUC: 0.8381, Train AP: 0.4255,Test AUC: 0.8337, Test AP: 0.4209\n",
      "Epoch 220 (1.75s/epoch): Train AUC: 0.8407, Train AP: 0.4332,Test AUC: 0.8361, Test AP: 0.4279\n",
      "Epoch 230 (1.76s/epoch): Train AUC: 0.8410, Train AP: 0.4337,Test AUC: 0.8365, Test AP: 0.4285\n",
      "Epoch 240 (1.76s/epoch): Train AUC: 0.8420, Train AP: 0.4330,Test AUC: 0.8375, Test AP: 0.4276\n",
      "Epoch 250 (1.75s/epoch): Train AUC: 0.8419, Train AP: 0.4317,Test AUC: 0.8376, Test AP: 0.4273\n",
      "Epoch 260 (1.76s/epoch): Train AUC: 0.8428, Train AP: 0.4337,Test AUC: 0.8385, Test AP: 0.4290\n",
      "Epoch 270 (1.75s/epoch): Train AUC: 0.8455, Train AP: 0.4425,Test AUC: 0.8410, Test AP: 0.4368\n",
      "Epoch 280 (1.76s/epoch): Train AUC: 0.8447, Train AP: 0.4372,Test AUC: 0.8403, Test AP: 0.4322\n",
      "Epoch 290 (1.76s/epoch): Train AUC: 0.8434, Train AP: 0.4314,Test AUC: 0.8390, Test AP: 0.4264\n",
      "Epoch 300 (1.75s/epoch): Train AUC: 0.8464, Train AP: 0.4413,Test AUC: 0.8422, Test AP: 0.4368\n",
      "Epoch 310 (1.76s/epoch): Train AUC: 0.8445, Train AP: 0.4326,Test AUC: 0.8403, Test AP: 0.4277\n",
      "Epoch 320 (1.75s/epoch): Train AUC: 0.8480, Train AP: 0.4474,Test AUC: 0.8435, Test AP: 0.4414\n",
      "Epoch 330 (1.76s/epoch): Train AUC: 0.8451, Train AP: 0.4352,Test AUC: 0.8410, Test AP: 0.4310\n",
      "Epoch 340 (1.75s/epoch): Train AUC: 0.8468, Train AP: 0.4400,Test AUC: 0.8426, Test AP: 0.4352\n",
      "Epoch 350 (1.75s/epoch): Train AUC: 0.8478, Train AP: 0.4419,Test AUC: 0.8436, Test AP: 0.4372\n",
      "Epoch 360 (1.75s/epoch): Train AUC: 0.8464, Train AP: 0.4373,Test AUC: 0.8421, Test AP: 0.4323\n",
      "Epoch 370 (1.75s/epoch): Train AUC: 0.8469, Train AP: 0.4392,Test AUC: 0.8425, Test AP: 0.4333\n",
      "Epoch 380 (1.75s/epoch): Train AUC: 0.8478, Train AP: 0.4406,Test AUC: 0.8436, Test AP: 0.4356\n",
      "Epoch 390 (1.76s/epoch): Train AUC: 0.8477, Train AP: 0.4402,Test AUC: 0.8435, Test AP: 0.4349\n",
      "Epoch 400 (1.76s/epoch): Train AUC: 0.8489, Train AP: 0.4447,Test AUC: 0.8445, Test AP: 0.4392\n",
      "Epoch 410 (1.75s/epoch): Train AUC: 0.8466, Train AP: 0.4348,Test AUC: 0.8423, Test AP: 0.4295\n",
      "Epoch 420 (1.75s/epoch): Train AUC: 0.8484, Train AP: 0.4433,Test AUC: 0.8442, Test AP: 0.4389\n",
      "Epoch 430 (1.75s/epoch): Train AUC: 0.8499, Train AP: 0.4490,Test AUC: 0.8457, Test AP: 0.4431\n",
      "Epoch 440 (1.76s/epoch): Train AUC: 0.8480, Train AP: 0.4419,Test AUC: 0.8440, Test AP: 0.4375\n",
      "Epoch 450 (1.75s/epoch): Train AUC: 0.8494, Train AP: 0.4477,Test AUC: 0.8452, Test AP: 0.4423\n",
      "Epoch 460 (1.75s/epoch): Train AUC: 0.8484, Train AP: 0.4412,Test AUC: 0.8443, Test AP: 0.4368\n",
      "Epoch 470 (1.75s/epoch): Train AUC: 0.8495, Train AP: 0.4450,Test AUC: 0.8454, Test AP: 0.4398\n",
      "Epoch 480 (1.75s/epoch): Train AUC: 0.8506, Train AP: 0.4519,Test AUC: 0.8464, Test AP: 0.4460\n",
      "Epoch 490 (1.75s/epoch): Train AUC: 0.8512, Train AP: 0.4529,Test AUC: 0.8470, Test AP: 0.4465\n",
      "Epoch 500 (1.75s/epoch): Train AUC: 0.8506, Train AP: 0.4484,Test AUC: 0.8468, Test AP: 0.4442\n",
      "Running iteration 2 of expt GAE_10d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.76s/epoch): Train AUC: 0.7304, Train AP: 0.3047,Test AUC: 0.7280, Test AP: 0.3028\n",
      "Epoch 020 (1.76s/epoch): Train AUC: 0.7902, Train AP: 0.3665,Test AUC: 0.7860, Test AP: 0.3604\n",
      "Epoch 030 (1.75s/epoch): Train AUC: 0.8178, Train AP: 0.3980,Test AUC: 0.8139, Test AP: 0.3926\n",
      "Epoch 040 (1.76s/epoch): Train AUC: 0.8320, Train AP: 0.4346,Test AUC: 0.8283, Test AP: 0.4300\n",
      "Epoch 050 (1.76s/epoch): Train AUC: 0.8391, Train AP: 0.4515,Test AUC: 0.8357, Test AP: 0.4471\n",
      "Epoch 060 (1.75s/epoch): Train AUC: 0.8436, Train AP: 0.4518,Test AUC: 0.8400, Test AP: 0.4455\n",
      "Epoch 070 (1.75s/epoch): Train AUC: 0.8465, Train AP: 0.4592,Test AUC: 0.8428, Test AP: 0.4524\n",
      "Epoch 080 (1.76s/epoch): Train AUC: 0.8502, Train AP: 0.4658,Test AUC: 0.8466, Test AP: 0.4589\n",
      "Epoch 090 (1.76s/epoch): Train AUC: 0.8498, Train AP: 0.4613,Test AUC: 0.8465, Test AP: 0.4558\n",
      "Epoch 100 (1.76s/epoch): Train AUC: 0.8508, Train AP: 0.4603,Test AUC: 0.8473, Test AP: 0.4536\n",
      "Epoch 110 (1.76s/epoch): Train AUC: 0.8524, Train AP: 0.4673,Test AUC: 0.8490, Test AP: 0.4611\n",
      "Epoch 120 (1.76s/epoch): Train AUC: 0.8508, Train AP: 0.4598,Test AUC: 0.8475, Test AP: 0.4548\n",
      "Epoch 130 (1.76s/epoch): Train AUC: 0.8518, Train AP: 0.4591,Test AUC: 0.8484, Test AP: 0.4539\n",
      "Epoch 140 (1.76s/epoch): Train AUC: 0.8515, Train AP: 0.4627,Test AUC: 0.8484, Test AP: 0.4599\n",
      "Epoch 150 (1.76s/epoch): Train AUC: 0.8536, Train AP: 0.4616,Test AUC: 0.8501, Test AP: 0.4557\n",
      "Epoch 160 (1.77s/epoch): Train AUC: 0.8530, Train AP: 0.4611,Test AUC: 0.8497, Test AP: 0.4578\n",
      "Epoch 170 (1.76s/epoch): Train AUC: 0.8540, Train AP: 0.4572,Test AUC: 0.8504, Test AP: 0.4517\n",
      "Epoch 180 (1.75s/epoch): Train AUC: 0.8538, Train AP: 0.4566,Test AUC: 0.8501, Test AP: 0.4506\n",
      "Epoch 190 (1.76s/epoch): Train AUC: 0.8557, Train AP: 0.4617,Test AUC: 0.8522, Test AP: 0.4559\n",
      "Epoch 200 (1.76s/epoch): Train AUC: 0.8538, Train AP: 0.4552,Test AUC: 0.8502, Test AP: 0.4497\n",
      "Epoch 210 (1.76s/epoch): Train AUC: 0.8550, Train AP: 0.4560,Test AUC: 0.8515, Test AP: 0.4510\n",
      "Epoch 220 (1.76s/epoch): Train AUC: 0.8554, Train AP: 0.4566,Test AUC: 0.8518, Test AP: 0.4506\n",
      "Epoch 230 (1.75s/epoch): Train AUC: 0.8552, Train AP: 0.4582,Test AUC: 0.8516, Test AP: 0.4533\n",
      "Epoch 240 (1.75s/epoch): Train AUC: 0.8546, Train AP: 0.4543,Test AUC: 0.8511, Test AP: 0.4496\n",
      "Epoch 250 (1.74s/epoch): Train AUC: 0.8559, Train AP: 0.4624,Test AUC: 0.8526, Test AP: 0.4593\n",
      "Epoch 260 (1.74s/epoch): Train AUC: 0.8560, Train AP: 0.4565,Test AUC: 0.8525, Test AP: 0.4513\n",
      "Epoch 270 (1.75s/epoch): Train AUC: 0.8571, Train AP: 0.4608,Test AUC: 0.8535, Test AP: 0.4546\n",
      "Epoch 280 (1.76s/epoch): Train AUC: 0.8559, Train AP: 0.4587,Test AUC: 0.8523, Test AP: 0.4541\n",
      "Epoch 290 (1.75s/epoch): Train AUC: 0.8567, Train AP: 0.4578,Test AUC: 0.8532, Test AP: 0.4526\n",
      "Epoch 300 (1.76s/epoch): Train AUC: 0.8553, Train AP: 0.4537,Test AUC: 0.8519, Test AP: 0.4496\n",
      "Epoch 310 (1.76s/epoch): Train AUC: 0.8570, Train AP: 0.4569,Test AUC: 0.8537, Test AP: 0.4522\n",
      "Epoch 320 (1.75s/epoch): Train AUC: 0.8564, Train AP: 0.4564,Test AUC: 0.8531, Test AP: 0.4523\n",
      "Epoch 330 (1.75s/epoch): Train AUC: 0.8580, Train AP: 0.4593,Test AUC: 0.8546, Test AP: 0.4538\n",
      "Epoch 340 (1.75s/epoch): Train AUC: 0.8589, Train AP: 0.4682,Test AUC: 0.8554, Test AP: 0.4618\n",
      "Epoch 350 (1.76s/epoch): Train AUC: 0.8568, Train AP: 0.4584,Test AUC: 0.8534, Test AP: 0.4540\n",
      "Epoch 360 (1.75s/epoch): Train AUC: 0.8552, Train AP: 0.4463,Test AUC: 0.8515, Test AP: 0.4406\n",
      "Epoch 370 (1.75s/epoch): Train AUC: 0.8575, Train AP: 0.4579,Test AUC: 0.8541, Test AP: 0.4529\n",
      "Epoch 380 (1.75s/epoch): Train AUC: 0.8579, Train AP: 0.4597,Test AUC: 0.8544, Test AP: 0.4538\n",
      "Epoch 390 (1.75s/epoch): Train AUC: 0.8576, Train AP: 0.4562,Test AUC: 0.8543, Test AP: 0.4513\n",
      "Epoch 400 (1.75s/epoch): Train AUC: 0.8573, Train AP: 0.4553,Test AUC: 0.8539, Test AP: 0.4504\n",
      "Epoch 410 (1.75s/epoch): Train AUC: 0.8575, Train AP: 0.4583,Test AUC: 0.8542, Test AP: 0.4535\n",
      "Epoch 420 (1.76s/epoch): Train AUC: 0.8589, Train AP: 0.4614,Test AUC: 0.8559, Test AP: 0.4569\n",
      "Epoch 430 (1.83s/epoch): Train AUC: 0.8590, Train AP: 0.4626,Test AUC: 0.8557, Test AP: 0.4571\n",
      "Epoch 440 (1.81s/epoch): Train AUC: 0.8581, Train AP: 0.4568,Test AUC: 0.8548, Test AP: 0.4519\n",
      "Epoch 450 (1.75s/epoch): Train AUC: 0.8578, Train AP: 0.4544,Test AUC: 0.8545, Test AP: 0.4494\n",
      "Epoch 460 (1.75s/epoch): Train AUC: 0.8588, Train AP: 0.4594,Test AUC: 0.8556, Test AP: 0.4546\n",
      "Epoch 470 (1.76s/epoch): Train AUC: 0.8573, Train AP: 0.4533,Test AUC: 0.8541, Test AP: 0.4491\n",
      "Epoch 480 (1.75s/epoch): Train AUC: 0.8575, Train AP: 0.4525,Test AUC: 0.8542, Test AP: 0.4478\n",
      "Epoch 490 (1.75s/epoch): Train AUC: 0.8548, Train AP: 0.4608,Test AUC: 0.8514, Test AP: 0.4570\n",
      "Epoch 500 (1.75s/epoch): Train AUC: 0.8567, Train AP: 0.4526,Test AUC: 0.8535, Test AP: 0.4484\n",
      "Running iteration 3 of expt GAE_10d_gcn_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.76s/epoch): Train AUC: 0.7434, Train AP: 0.3134,Test AUC: 0.7413, Test AP: 0.3103\n",
      "Epoch 020 (1.76s/epoch): Train AUC: 0.8001, Train AP: 0.3750,Test AUC: 0.7989, Test AP: 0.3709\n",
      "Epoch 030 (1.74s/epoch): Train AUC: 0.8265, Train AP: 0.4195,Test AUC: 0.8246, Test AP: 0.4160\n",
      "Epoch 040 (1.74s/epoch): Train AUC: 0.8339, Train AP: 0.4303,Test AUC: 0.8317, Test AP: 0.4267\n",
      "Epoch 050 (1.75s/epoch): Train AUC: 0.8410, Train AP: 0.4460,Test AUC: 0.8390, Test AP: 0.4437\n",
      "Epoch 060 (1.75s/epoch): Train AUC: 0.8436, Train AP: 0.4553,Test AUC: 0.8416, Test AP: 0.4522\n",
      "Epoch 070 (1.75s/epoch): Train AUC: 0.8451, Train AP: 0.4542,Test AUC: 0.8429, Test AP: 0.4505\n",
      "Epoch 080 (1.75s/epoch): Train AUC: 0.8447, Train AP: 0.4521,Test AUC: 0.8424, Test AP: 0.4472\n",
      "Epoch 090 (1.75s/epoch): Train AUC: 0.8452, Train AP: 0.4473,Test AUC: 0.8429, Test AP: 0.4430\n",
      "Epoch 100 (1.75s/epoch): Train AUC: 0.8486, Train AP: 0.4609,Test AUC: 0.8460, Test AP: 0.4550\n",
      "Epoch 110 (1.75s/epoch): Train AUC: 0.8493, Train AP: 0.4577,Test AUC: 0.8468, Test AP: 0.4523\n",
      "Epoch 120 (1.75s/epoch): Train AUC: 0.8501, Train AP: 0.4605,Test AUC: 0.8474, Test AP: 0.4542\n",
      "Epoch 130 (1.75s/epoch): Train AUC: 0.8516, Train AP: 0.4653,Test AUC: 0.8488, Test AP: 0.4590\n",
      "Epoch 140 (1.76s/epoch): Train AUC: 0.8500, Train AP: 0.4541,Test AUC: 0.8470, Test AP: 0.4475\n",
      "Epoch 150 (1.75s/epoch): Train AUC: 0.8501, Train AP: 0.4544,Test AUC: 0.8469, Test AP: 0.4473\n",
      "Epoch 160 (1.75s/epoch): Train AUC: 0.8533, Train AP: 0.4673,Test AUC: 0.8501, Test AP: 0.4594\n",
      "Epoch 170 (1.75s/epoch): Train AUC: 0.8534, Train AP: 0.4670,Test AUC: 0.8499, Test AP: 0.4585\n",
      "Epoch 180 (1.76s/epoch): Train AUC: 0.8533, Train AP: 0.4641,Test AUC: 0.8499, Test AP: 0.4555\n",
      "Epoch 190 (1.78s/epoch): Train AUC: 0.8518, Train AP: 0.4563,Test AUC: 0.8484, Test AP: 0.4483\n",
      "Epoch 200 (1.75s/epoch): Train AUC: 0.8535, Train AP: 0.4597,Test AUC: 0.8501, Test AP: 0.4520\n",
      "Epoch 210 (1.75s/epoch): Train AUC: 0.8545, Train AP: 0.4659,Test AUC: 0.8510, Test AP: 0.4573\n",
      "Epoch 220 (1.74s/epoch): Train AUC: 0.8549, Train AP: 0.4652,Test AUC: 0.8514, Test AP: 0.4567\n",
      "Epoch 230 (1.75s/epoch): Train AUC: 0.8546, Train AP: 0.4626,Test AUC: 0.8511, Test AP: 0.4542\n",
      "Epoch 240 (1.75s/epoch): Train AUC: 0.8532, Train AP: 0.4567,Test AUC: 0.8498, Test AP: 0.4500\n",
      "Epoch 250 (1.75s/epoch): Train AUC: 0.8562, Train AP: 0.4673,Test AUC: 0.8525, Test AP: 0.4579\n",
      "Epoch 260 (1.75s/epoch): Train AUC: 0.8543, Train AP: 0.4584,Test AUC: 0.8509, Test AP: 0.4512\n",
      "Epoch 270 (1.75s/epoch): Train AUC: 0.8530, Train AP: 0.4503,Test AUC: 0.8494, Test AP: 0.4430\n",
      "Epoch 280 (1.75s/epoch): Train AUC: 0.8574, Train AP: 0.4723,Test AUC: 0.8536, Test AP: 0.4622\n",
      "Epoch 290 (1.76s/epoch): Train AUC: 0.8548, Train AP: 0.4561,Test AUC: 0.8512, Test AP: 0.4475\n",
      "Epoch 300 (1.75s/epoch): Train AUC: 0.8543, Train AP: 0.4529,Test AUC: 0.8506, Test AP: 0.4446\n",
      "Epoch 310 (1.75s/epoch): Train AUC: 0.8569, Train AP: 0.4661,Test AUC: 0.8532, Test AP: 0.4568\n",
      "Epoch 320 (1.75s/epoch): Train AUC: 0.8572, Train AP: 0.4664,Test AUC: 0.8537, Test AP: 0.4572\n",
      "Epoch 330 (1.75s/epoch): Train AUC: 0.8565, Train AP: 0.4615,Test AUC: 0.8531, Test AP: 0.4531\n",
      "Epoch 340 (1.76s/epoch): Train AUC: 0.8572, Train AP: 0.4711,Test AUC: 0.8537, Test AP: 0.4618\n",
      "Epoch 350 (1.75s/epoch): Train AUC: 0.8564, Train AP: 0.4589,Test AUC: 0.8530, Test AP: 0.4506\n",
      "Epoch 360 (1.76s/epoch): Train AUC: 0.8561, Train AP: 0.4583,Test AUC: 0.8526, Test AP: 0.4499\n",
      "Epoch 370 (1.76s/epoch): Train AUC: 0.8567, Train AP: 0.4591,Test AUC: 0.8533, Test AP: 0.4506\n",
      "Epoch 380 (1.75s/epoch): Train AUC: 0.8580, Train AP: 0.4638,Test AUC: 0.8547, Test AP: 0.4553\n",
      "Epoch 390 (1.75s/epoch): Train AUC: 0.8552, Train AP: 0.4505,Test AUC: 0.8518, Test AP: 0.4429\n",
      "Epoch 400 (1.76s/epoch): Train AUC: 0.8595, Train AP: 0.4706,Test AUC: 0.8562, Test AP: 0.4615\n",
      "Epoch 410 (1.75s/epoch): Train AUC: 0.8582, Train AP: 0.4634,Test AUC: 0.8548, Test AP: 0.4547\n",
      "Epoch 420 (1.76s/epoch): Train AUC: 0.8567, Train AP: 0.4566,Test AUC: 0.8535, Test AP: 0.4493\n",
      "Epoch 430 (1.75s/epoch): Train AUC: 0.8583, Train AP: 0.4622,Test AUC: 0.8549, Test AP: 0.4535\n",
      "Epoch 440 (1.75s/epoch): Train AUC: 0.8591, Train AP: 0.4664,Test AUC: 0.8559, Test AP: 0.4574\n",
      "Epoch 450 (1.75s/epoch): Train AUC: 0.8593, Train AP: 0.4628,Test AUC: 0.8559, Test AP: 0.4541\n",
      "Epoch 460 (1.75s/epoch): Train AUC: 0.8591, Train AP: 0.4618,Test AUC: 0.8560, Test AP: 0.4543\n",
      "Epoch 470 (1.75s/epoch): Train AUC: 0.8588, Train AP: 0.4611,Test AUC: 0.8555, Test AP: 0.4524\n",
      "Epoch 480 (1.75s/epoch): Train AUC: 0.8571, Train AP: 0.4497,Test AUC: 0.8538, Test AP: 0.4427\n",
      "Epoch 490 (1.75s/epoch): Train AUC: 0.8555, Train AP: 0.4490,Test AUC: 0.8527, Test AP: 0.4449\n",
      "Epoch 500 (1.75s/epoch): Train AUC: 0.8591, Train AP: 0.4642,Test AUC: 0.8559, Test AP: 0.4562\n",
      "Running iteration 1 of expt GAE_20d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (4.02s/epoch): Train AUC: 0.8070, Train AP: 0.4519,Test AUC: 0.8020, Test AP: 0.4484\n",
      "Epoch 020 (1.85s/epoch): Train AUC: 0.8314, Train AP: 0.5037,Test AUC: 0.8271, Test AP: 0.5026\n",
      "Epoch 030 (1.83s/epoch): Train AUC: 0.8294, Train AP: 0.5178,Test AUC: 0.8240, Test AP: 0.5124\n",
      "Epoch 040 (1.85s/epoch): Train AUC: 0.8266, Train AP: 0.5201,Test AUC: 0.8212, Test AP: 0.5150\n",
      "Epoch 050 (1.85s/epoch): Train AUC: 0.8251, Train AP: 0.5171,Test AUC: 0.8197, Test AP: 0.5119\n",
      "Epoch 060 (1.85s/epoch): Train AUC: 0.8310, Train AP: 0.5250,Test AUC: 0.8263, Test AP: 0.5208\n",
      "Epoch 070 (1.85s/epoch): Train AUC: 0.8312, Train AP: 0.5283,Test AUC: 0.8262, Test AP: 0.5231\n",
      "Epoch 080 (1.85s/epoch): Train AUC: 0.8339, Train AP: 0.5319,Test AUC: 0.8292, Test AP: 0.5265\n",
      "Epoch 090 (1.85s/epoch): Train AUC: 0.8356, Train AP: 0.5295,Test AUC: 0.8311, Test AP: 0.5263\n",
      "Epoch 100 (1.85s/epoch): Train AUC: 0.8371, Train AP: 0.5364,Test AUC: 0.8323, Test AP: 0.5306\n",
      "Epoch 110 (1.85s/epoch): Train AUC: 0.8395, Train AP: 0.5275,Test AUC: 0.8353, Test AP: 0.5244\n",
      "Epoch 120 (1.85s/epoch): Train AUC: 0.8415, Train AP: 0.5409,Test AUC: 0.8371, Test AP: 0.5381\n",
      "Epoch 130 (1.83s/epoch): Train AUC: 0.8422, Train AP: 0.5399,Test AUC: 0.8378, Test AP: 0.5372\n",
      "Epoch 140 (1.85s/epoch): Train AUC: 0.8428, Train AP: 0.5436,Test AUC: 0.8383, Test AP: 0.5402\n",
      "Epoch 150 (1.85s/epoch): Train AUC: 0.8459, Train AP: 0.5486,Test AUC: 0.8414, Test AP: 0.5447\n",
      "Epoch 160 (1.85s/epoch): Train AUC: 0.8474, Train AP: 0.5586,Test AUC: 0.8428, Test AP: 0.5540\n",
      "Epoch 170 (1.85s/epoch): Train AUC: 0.8495, Train AP: 0.5553,Test AUC: 0.8451, Test AP: 0.5519\n",
      "Epoch 180 (1.83s/epoch): Train AUC: 0.8506, Train AP: 0.5648,Test AUC: 0.8462, Test AP: 0.5609\n",
      "Epoch 190 (1.85s/epoch): Train AUC: 0.8518, Train AP: 0.5649,Test AUC: 0.8475, Test AP: 0.5609\n",
      "Epoch 200 (1.85s/epoch): Train AUC: 0.8555, Train AP: 0.5746,Test AUC: 0.8511, Test AP: 0.5704\n",
      "Epoch 210 (1.85s/epoch): Train AUC: 0.8569, Train AP: 0.5779,Test AUC: 0.8526, Test AP: 0.5738\n",
      "Epoch 220 (1.85s/epoch): Train AUC: 0.8582, Train AP: 0.5807,Test AUC: 0.8539, Test AP: 0.5767\n",
      "Epoch 230 (1.85s/epoch): Train AUC: 0.8607, Train AP: 0.5823,Test AUC: 0.8565, Test AP: 0.5784\n",
      "Epoch 240 (1.85s/epoch): Train AUC: 0.8615, Train AP: 0.5877,Test AUC: 0.8571, Test AP: 0.5833\n",
      "Epoch 250 (1.85s/epoch): Train AUC: 0.8639, Train AP: 0.5913,Test AUC: 0.8597, Test AP: 0.5863\n",
      "Epoch 260 (1.85s/epoch): Train AUC: 0.8639, Train AP: 0.5939,Test AUC: 0.8596, Test AP: 0.5884\n",
      "Epoch 270 (1.84s/epoch): Train AUC: 0.8642, Train AP: 0.5894,Test AUC: 0.8601, Test AP: 0.5844\n",
      "Epoch 280 (1.85s/epoch): Train AUC: 0.8671, Train AP: 0.5963,Test AUC: 0.8630, Test AP: 0.5912\n",
      "Epoch 290 (1.84s/epoch): Train AUC: 0.8663, Train AP: 0.5984,Test AUC: 0.8621, Test AP: 0.5930\n",
      "Epoch 300 (1.85s/epoch): Train AUC: 0.8669, Train AP: 0.5986,Test AUC: 0.8628, Test AP: 0.5932\n",
      "Epoch 310 (1.85s/epoch): Train AUC: 0.8685, Train AP: 0.5923,Test AUC: 0.8647, Test AP: 0.5880\n",
      "Epoch 320 (1.85s/epoch): Train AUC: 0.8692, Train AP: 0.6010,Test AUC: 0.8653, Test AP: 0.5960\n",
      "Epoch 330 (1.85s/epoch): Train AUC: 0.8696, Train AP: 0.6070,Test AUC: 0.8654, Test AP: 0.6004\n",
      "Epoch 340 (1.86s/epoch): Train AUC: 0.8704, Train AP: 0.6072,Test AUC: 0.8662, Test AP: 0.6007\n",
      "Epoch 350 (1.85s/epoch): Train AUC: 0.8711, Train AP: 0.6097,Test AUC: 0.8670, Test AP: 0.6035\n",
      "Epoch 360 (1.85s/epoch): Train AUC: 0.8702, Train AP: 0.6082,Test AUC: 0.8659, Test AP: 0.6011\n",
      "Epoch 370 (1.85s/epoch): Train AUC: 0.8713, Train AP: 0.6099,Test AUC: 0.8671, Test AP: 0.6028\n",
      "Epoch 380 (1.85s/epoch): Train AUC: 0.8695, Train AP: 0.6079,Test AUC: 0.8651, Test AP: 0.5996\n",
      "Epoch 390 (1.85s/epoch): Train AUC: 0.8716, Train AP: 0.6099,Test AUC: 0.8674, Test AP: 0.6027\n",
      "Epoch 400 (1.85s/epoch): Train AUC: 0.8732, Train AP: 0.6122,Test AUC: 0.8692, Test AP: 0.6055\n",
      "Epoch 410 (1.84s/epoch): Train AUC: 0.8729, Train AP: 0.6076,Test AUC: 0.8690, Test AP: 0.6013\n",
      "Epoch 420 (1.85s/epoch): Train AUC: 0.8724, Train AP: 0.6129,Test AUC: 0.8683, Test AP: 0.6055\n",
      "Epoch 430 (1.85s/epoch): Train AUC: 0.8717, Train AP: 0.6018,Test AUC: 0.8681, Test AP: 0.5974\n",
      "Epoch 440 (1.81s/epoch): Train AUC: 0.8733, Train AP: 0.6135,Test AUC: 0.8692, Test AP: 0.6066\n",
      "Epoch 450 (1.80s/epoch): Train AUC: 0.8738, Train AP: 0.6151,Test AUC: 0.8694, Test AP: 0.6066\n",
      "Epoch 460 (1.85s/epoch): Train AUC: 0.8738, Train AP: 0.6150,Test AUC: 0.8694, Test AP: 0.6067\n",
      "Epoch 470 (1.85s/epoch): Train AUC: 0.8765, Train AP: 0.6170,Test AUC: 0.8725, Test AP: 0.6112\n",
      "Epoch 480 (1.85s/epoch): Train AUC: 0.8748, Train AP: 0.6116,Test AUC: 0.8708, Test AP: 0.6059\n",
      "Epoch 490 (1.85s/epoch): Train AUC: 0.8747, Train AP: 0.6171,Test AUC: 0.8706, Test AP: 0.6105\n",
      "Epoch 500 (1.85s/epoch): Train AUC: 0.8761, Train AP: 0.6161,Test AUC: 0.8719, Test AP: 0.6090\n",
      "Running iteration 2 of expt GAE_20d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (1.85s/epoch): Train AUC: 0.8036, Train AP: 0.4597,Test AUC: 0.7994, Test AP: 0.4542\n",
      "Epoch 020 (1.85s/epoch): Train AUC: 0.8383, Train AP: 0.5068,Test AUC: 0.8338, Test AP: 0.4988\n",
      "Epoch 030 (1.85s/epoch): Train AUC: 0.8331, Train AP: 0.5231,Test AUC: 0.8278, Test AP: 0.5158\n",
      "Epoch 040 (1.85s/epoch): Train AUC: 0.8383, Train AP: 0.5343,Test AUC: 0.8333, Test AP: 0.5274\n",
      "Epoch 050 (1.85s/epoch): Train AUC: 0.8410, Train AP: 0.5376,Test AUC: 0.8364, Test AP: 0.5305\n",
      "Epoch 060 (1.85s/epoch): Train AUC: 0.8409, Train AP: 0.5392,Test AUC: 0.8363, Test AP: 0.5322\n",
      "Epoch 070 (1.85s/epoch): Train AUC: 0.8414, Train AP: 0.5403,Test AUC: 0.8368, Test AP: 0.5333\n",
      "Epoch 080 (1.85s/epoch): Train AUC: 0.8434, Train AP: 0.5367,Test AUC: 0.8393, Test AP: 0.5307\n",
      "Epoch 090 (1.85s/epoch): Train AUC: 0.8462, Train AP: 0.5435,Test AUC: 0.8421, Test AP: 0.5371\n",
      "Epoch 100 (1.85s/epoch): Train AUC: 0.8463, Train AP: 0.5465,Test AUC: 0.8419, Test AP: 0.5391\n",
      "Epoch 110 (1.84s/epoch): Train AUC: 0.8477, Train AP: 0.5497,Test AUC: 0.8433, Test AP: 0.5418\n",
      "Epoch 120 (1.86s/epoch): Train AUC: 0.8481, Train AP: 0.5371,Test AUC: 0.8444, Test AP: 0.5317\n",
      "Epoch 130 (1.84s/epoch): Train AUC: 0.8487, Train AP: 0.5380,Test AUC: 0.8449, Test AP: 0.5326\n",
      "Epoch 140 (1.84s/epoch): Train AUC: 0.8504, Train AP: 0.5508,Test AUC: 0.8462, Test AP: 0.5439\n",
      "Epoch 150 (1.85s/epoch): Train AUC: 0.8515, Train AP: 0.5523,Test AUC: 0.8473, Test AP: 0.5451\n",
      "Epoch 160 (1.85s/epoch): Train AUC: 0.8510, Train AP: 0.5508,Test AUC: 0.8467, Test AP: 0.5435\n",
      "Epoch 170 (1.85s/epoch): Train AUC: 0.8520, Train AP: 0.5555,Test AUC: 0.8478, Test AP: 0.5483\n",
      "Epoch 180 (1.84s/epoch): Train AUC: 0.8531, Train AP: 0.5541,Test AUC: 0.8489, Test AP: 0.5471\n",
      "Epoch 190 (1.85s/epoch): Train AUC: 0.8545, Train AP: 0.5524,Test AUC: 0.8508, Test AP: 0.5466\n",
      "Epoch 200 (1.85s/epoch): Train AUC: 0.8533, Train AP: 0.5573,Test AUC: 0.8490, Test AP: 0.5496\n",
      "Epoch 210 (1.85s/epoch): Train AUC: 0.8549, Train AP: 0.5547,Test AUC: 0.8508, Test AP: 0.5479\n",
      "Epoch 220 (1.85s/epoch): Train AUC: 0.8555, Train AP: 0.5540,Test AUC: 0.8515, Test AP: 0.5481\n",
      "Epoch 230 (1.85s/epoch): Train AUC: 0.8540, Train AP: 0.5528,Test AUC: 0.8495, Test AP: 0.5449\n",
      "Epoch 240 (1.85s/epoch): Train AUC: 0.8528, Train AP: 0.5528,Test AUC: 0.8481, Test AP: 0.5444\n",
      "Epoch 250 (1.85s/epoch): Train AUC: 0.8571, Train AP: 0.5555,Test AUC: 0.8531, Test AP: 0.5493\n",
      "Epoch 260 (1.84s/epoch): Train AUC: 0.8569, Train AP: 0.5592,Test AUC: 0.8527, Test AP: 0.5516\n",
      "Epoch 270 (1.84s/epoch): Train AUC: 0.8577, Train AP: 0.5555,Test AUC: 0.8538, Test AP: 0.5495\n",
      "Epoch 280 (1.85s/epoch): Train AUC: 0.8581, Train AP: 0.5647,Test AUC: 0.8538, Test AP: 0.5572\n",
      "Epoch 290 (1.85s/epoch): Train AUC: 0.8579, Train AP: 0.5616,Test AUC: 0.8537, Test AP: 0.5546\n",
      "Epoch 300 (1.85s/epoch): Train AUC: 0.8582, Train AP: 0.5614,Test AUC: 0.8541, Test AP: 0.5545\n",
      "Epoch 310 (1.85s/epoch): Train AUC: 0.8588, Train AP: 0.5630,Test AUC: 0.8546, Test AP: 0.5559\n",
      "Epoch 320 (1.84s/epoch): Train AUC: 0.8594, Train AP: 0.5618,Test AUC: 0.8553, Test AP: 0.5551\n",
      "Epoch 330 (1.84s/epoch): Train AUC: 0.8596, Train AP: 0.5643,Test AUC: 0.8555, Test AP: 0.5575\n",
      "Epoch 340 (1.84s/epoch): Train AUC: 0.8597, Train AP: 0.5645,Test AUC: 0.8556, Test AP: 0.5578\n",
      "Epoch 350 (1.85s/epoch): Train AUC: 0.8596, Train AP: 0.5641,Test AUC: 0.8555, Test AP: 0.5571\n",
      "Epoch 360 (1.85s/epoch): Train AUC: 0.8589, Train AP: 0.5442,Test AUC: 0.8555, Test AP: 0.5411\n",
      "Epoch 370 (1.85s/epoch): Train AUC: 0.8578, Train AP: 0.5496,Test AUC: 0.8539, Test AP: 0.5439\n",
      "Epoch 380 (1.85s/epoch): Train AUC: 0.8605, Train AP: 0.5634,Test AUC: 0.8566, Test AP: 0.5568\n",
      "Epoch 390 (1.84s/epoch): Train AUC: 0.8581, Train AP: 0.5428,Test AUC: 0.8546, Test AP: 0.5393\n",
      "Epoch 400 (1.84s/epoch): Train AUC: 0.8610, Train AP: 0.5584,Test AUC: 0.8574, Test AP: 0.5534\n",
      "Epoch 410 (1.84s/epoch): Train AUC: 0.8610, Train AP: 0.5683,Test AUC: 0.8570, Test AP: 0.5612\n",
      "Epoch 420 (1.85s/epoch): Train AUC: 0.8586, Train AP: 0.5491,Test AUC: 0.8547, Test AP: 0.5436\n",
      "Epoch 430 (1.85s/epoch): Train AUC: 0.8614, Train AP: 0.5585,Test AUC: 0.8577, Test AP: 0.5534\n",
      "Epoch 440 (1.84s/epoch): Train AUC: 0.8589, Train AP: 0.5489,Test AUC: 0.8551, Test AP: 0.5441\n",
      "Epoch 450 (1.85s/epoch): Train AUC: 0.8596, Train AP: 0.5632,Test AUC: 0.8553, Test AP: 0.5552\n",
      "Epoch 460 (1.85s/epoch): Train AUC: 0.8616, Train AP: 0.5678,Test AUC: 0.8577, Test AP: 0.5609\n",
      "Epoch 470 (1.84s/epoch): Train AUC: 0.8614, Train AP: 0.5689,Test AUC: 0.8573, Test AP: 0.5618\n",
      "Epoch 480 (1.85s/epoch): Train AUC: 0.8618, Train AP: 0.5584,Test AUC: 0.8582, Test AP: 0.5537\n",
      "Epoch 490 (1.85s/epoch): Train AUC: 0.8600, Train AP: 0.5540,Test AUC: 0.8562, Test AP: 0.5491\n",
      "Epoch 500 (1.85s/epoch): Train AUC: 0.8620, Train AP: 0.5697,Test AUC: 0.8580, Test AP: 0.5630\n",
      "Running iteration 3 of expt GAE_20d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 20, 'hidden_channels': 20, 'num_layers': 2}\n",
      "Epoch 010 (1.86s/epoch): Train AUC: 0.8280, Train AP: 0.5057,Test AUC: 0.8240, Test AP: 0.5028\n",
      "Epoch 020 (1.88s/epoch): Train AUC: 0.8445, Train AP: 0.5322,Test AUC: 0.8404, Test AP: 0.5274\n",
      "Epoch 030 (1.83s/epoch): Train AUC: 0.8451, Train AP: 0.5300,Test AUC: 0.8412, Test AP: 0.5261\n",
      "Epoch 040 (1.85s/epoch): Train AUC: 0.8443, Train AP: 0.5425,Test AUC: 0.8399, Test AP: 0.5381\n",
      "Epoch 050 (1.84s/epoch): Train AUC: 0.8453, Train AP: 0.5460,Test AUC: 0.8410, Test AP: 0.5419\n",
      "Epoch 060 (1.85s/epoch): Train AUC: 0.8441, Train AP: 0.5451,Test AUC: 0.8397, Test AP: 0.5405\n",
      "Epoch 070 (1.85s/epoch): Train AUC: 0.8469, Train AP: 0.5426,Test AUC: 0.8430, Test AP: 0.5392\n",
      "Epoch 080 (1.85s/epoch): Train AUC: 0.8477, Train AP: 0.5508,Test AUC: 0.8436, Test AP: 0.5467\n",
      "Epoch 090 (1.85s/epoch): Train AUC: 0.8494, Train AP: 0.5424,Test AUC: 0.8458, Test AP: 0.5401\n",
      "Epoch 100 (1.94s/epoch): Train AUC: 0.8488, Train AP: 0.5538,Test AUC: 0.8445, Test AP: 0.5495\n",
      "Epoch 110 (1.89s/epoch): Train AUC: 0.8490, Train AP: 0.5499,Test AUC: 0.8448, Test AP: 0.5446\n",
      "Epoch 120 (1.91s/epoch): Train AUC: 0.8414, Train AP: 0.5337,Test AUC: 0.8366, Test AP: 0.5273\n",
      "Epoch 130 (1.84s/epoch): Train AUC: 0.8509, Train AP: 0.5462,Test AUC: 0.8469, Test AP: 0.5416\n",
      "Epoch 140 (1.85s/epoch): Train AUC: 0.8508, Train AP: 0.5530,Test AUC: 0.8465, Test AP: 0.5473\n",
      "Epoch 150 (1.85s/epoch): Train AUC: 0.8532, Train AP: 0.5535,Test AUC: 0.8494, Test AP: 0.5496\n",
      "Epoch 160 (1.85s/epoch): Train AUC: 0.8537, Train AP: 0.5534,Test AUC: 0.8498, Test AP: 0.5487\n",
      "Epoch 170 (1.85s/epoch): Train AUC: 0.8521, Train AP: 0.5565,Test AUC: 0.8477, Test AP: 0.5502\n",
      "Epoch 180 (1.84s/epoch): Train AUC: 0.8526, Train AP: 0.5568,Test AUC: 0.8483, Test AP: 0.5502\n",
      "Epoch 190 (1.85s/epoch): Train AUC: 0.8542, Train AP: 0.5572,Test AUC: 0.8500, Test AP: 0.5514\n",
      "Epoch 200 (1.85s/epoch): Train AUC: 0.8538, Train AP: 0.5598,Test AUC: 0.8494, Test AP: 0.5537\n",
      "Epoch 210 (1.85s/epoch): Train AUC: 0.8522, Train AP: 0.5561,Test AUC: 0.8477, Test AP: 0.5487\n",
      "Epoch 220 (1.85s/epoch): Train AUC: 0.8501, Train AP: 0.5391,Test AUC: 0.8456, Test AP: 0.5316\n",
      "Epoch 230 (1.85s/epoch): Train AUC: 0.8559, Train AP: 0.5594,Test AUC: 0.8518, Test AP: 0.5533\n",
      "Epoch 240 (1.85s/epoch): Train AUC: 0.8545, Train AP: 0.5363,Test AUC: 0.8512, Test AP: 0.5333\n",
      "Epoch 250 (1.85s/epoch): Train AUC: 0.8569, Train AP: 0.5593,Test AUC: 0.8528, Test AP: 0.5533\n",
      "Epoch 260 (1.85s/epoch): Train AUC: 0.8553, Train AP: 0.5619,Test AUC: 0.8509, Test AP: 0.5561\n",
      "Epoch 270 (1.85s/epoch): Train AUC: 0.8572, Train AP: 0.5636,Test AUC: 0.8529, Test AP: 0.5574\n",
      "Epoch 280 (1.85s/epoch): Train AUC: 0.8575, Train AP: 0.5655,Test AUC: 0.8532, Test AP: 0.5590\n",
      "Epoch 290 (1.84s/epoch): Train AUC: 0.8564, Train AP: 0.5639,Test AUC: 0.8519, Test AP: 0.5566\n",
      "Epoch 300 (1.85s/epoch): Train AUC: 0.8583, Train AP: 0.5643,Test AUC: 0.8540, Test AP: 0.5572\n",
      "Epoch 310 (1.84s/epoch): Train AUC: 0.8582, Train AP: 0.5513,Test AUC: 0.8545, Test AP: 0.5467\n",
      "Epoch 320 (1.85s/epoch): Train AUC: 0.8581, Train AP: 0.5654,Test AUC: 0.8537, Test AP: 0.5583\n",
      "Epoch 330 (1.84s/epoch): Train AUC: 0.8585, Train AP: 0.5538,Test AUC: 0.8547, Test AP: 0.5484\n",
      "Epoch 340 (1.85s/epoch): Train AUC: 0.8598, Train AP: 0.5499,Test AUC: 0.8562, Test AP: 0.5454\n",
      "Epoch 350 (1.83s/epoch): Train AUC: 0.8572, Train AP: 0.5593,Test AUC: 0.8526, Test AP: 0.5513\n",
      "Epoch 360 (1.84s/epoch): Train AUC: 0.8592, Train AP: 0.5527,Test AUC: 0.8552, Test AP: 0.5470\n",
      "Epoch 370 (1.85s/epoch): Train AUC: 0.8577, Train AP: 0.5636,Test AUC: 0.8530, Test AP: 0.5555\n",
      "Epoch 380 (1.84s/epoch): Train AUC: 0.8596, Train AP: 0.5657,Test AUC: 0.8551, Test AP: 0.5580\n",
      "Epoch 390 (1.81s/epoch): Train AUC: 0.8610, Train AP: 0.5692,Test AUC: 0.8567, Test AP: 0.5619\n",
      "Epoch 400 (1.84s/epoch): Train AUC: 0.8603, Train AP: 0.5693,Test AUC: 0.8559, Test AP: 0.5623\n",
      "Epoch 410 (1.84s/epoch): Train AUC: 0.8539, Train AP: 0.5518,Test AUC: 0.8494, Test AP: 0.5454\n",
      "Epoch 420 (1.85s/epoch): Train AUC: 0.8606, Train AP: 0.5716,Test AUC: 0.8561, Test AP: 0.5634\n",
      "Epoch 430 (1.84s/epoch): Train AUC: 0.8621, Train AP: 0.5698,Test AUC: 0.8579, Test AP: 0.5628\n",
      "Epoch 440 (1.84s/epoch): Train AUC: 0.8529, Train AP: 0.5459,Test AUC: 0.8484, Test AP: 0.5396\n",
      "Epoch 450 (1.85s/epoch): Train AUC: 0.8621, Train AP: 0.5645,Test AUC: 0.8580, Test AP: 0.5579\n",
      "Epoch 460 (1.85s/epoch): Train AUC: 0.8640, Train AP: 0.5716,Test AUC: 0.8600, Test AP: 0.5657\n",
      "Epoch 470 (1.85s/epoch): Train AUC: 0.8630, Train AP: 0.5690,Test AUC: 0.8589, Test AP: 0.5620\n",
      "Epoch 480 (1.85s/epoch): Train AUC: 0.8633, Train AP: 0.5683,Test AUC: 0.8593, Test AP: 0.5618\n",
      "Epoch 490 (1.85s/epoch): Train AUC: 0.8607, Train AP: 0.5716,Test AUC: 0.8562, Test AP: 0.5644\n",
      "Epoch 500 (1.85s/epoch): Train AUC: 0.8620, Train AP: 0.5707,Test AUC: 0.8577, Test AP: 0.5631\n",
      "Running iteration 1 of expt GAE_10d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.90s/epoch): Train AUC: 0.7456, Train AP: 0.3518,Test AUC: 0.7453, Test AP: 0.3521\n",
      "Epoch 020 (1.90s/epoch): Train AUC: 0.7822, Train AP: 0.3918,Test AUC: 0.7811, Test AP: 0.3900\n",
      "Epoch 030 (1.90s/epoch): Train AUC: 0.8066, Train AP: 0.4320,Test AUC: 0.8048, Test AP: 0.4276\n",
      "Epoch 040 (1.90s/epoch): Train AUC: 0.8184, Train AP: 0.4526,Test AUC: 0.8165, Test AP: 0.4468\n",
      "Epoch 050 (1.90s/epoch): Train AUC: 0.8244, Train AP: 0.4583,Test AUC: 0.8223, Test AP: 0.4517\n",
      "Epoch 060 (1.90s/epoch): Train AUC: 0.8286, Train AP: 0.4674,Test AUC: 0.8265, Test AP: 0.4612\n",
      "Epoch 070 (1.90s/epoch): Train AUC: 0.8309, Train AP: 0.4666,Test AUC: 0.8287, Test AP: 0.4603\n",
      "Epoch 080 (1.90s/epoch): Train AUC: 0.8366, Train AP: 0.4791,Test AUC: 0.8349, Test AP: 0.4758\n",
      "Epoch 090 (1.90s/epoch): Train AUC: 0.8357, Train AP: 0.4764,Test AUC: 0.8335, Test AP: 0.4702\n",
      "Epoch 100 (1.88s/epoch): Train AUC: 0.8388, Train AP: 0.4817,Test AUC: 0.8365, Test AP: 0.4759\n",
      "Epoch 110 (1.91s/epoch): Train AUC: 0.8387, Train AP: 0.4753,Test AUC: 0.8362, Test AP: 0.4692\n",
      "Epoch 120 (1.90s/epoch): Train AUC: 0.8426, Train AP: 0.4865,Test AUC: 0.8401, Test AP: 0.4814\n",
      "Epoch 130 (1.89s/epoch): Train AUC: 0.8442, Train AP: 0.4891,Test AUC: 0.8417, Test AP: 0.4832\n",
      "Epoch 140 (1.89s/epoch): Train AUC: 0.8440, Train AP: 0.4934,Test AUC: 0.8416, Test AP: 0.4889\n",
      "Epoch 150 (1.89s/epoch): Train AUC: 0.8453, Train AP: 0.4925,Test AUC: 0.8428, Test AP: 0.4859\n",
      "Epoch 160 (1.89s/epoch): Train AUC: 0.8489, Train AP: 0.4986,Test AUC: 0.8465, Test AP: 0.4939\n",
      "Epoch 170 (1.89s/epoch): Train AUC: 0.8495, Train AP: 0.5036,Test AUC: 0.8469, Test AP: 0.4979\n",
      "Epoch 180 (1.89s/epoch): Train AUC: 0.8516, Train AP: 0.5067,Test AUC: 0.8491, Test AP: 0.5007\n",
      "Epoch 190 (1.89s/epoch): Train AUC: 0.8506, Train AP: 0.5030,Test AUC: 0.8478, Test AP: 0.4958\n",
      "Epoch 200 (1.89s/epoch): Train AUC: 0.8539, Train AP: 0.5067,Test AUC: 0.8514, Test AP: 0.5028\n",
      "Epoch 210 (1.89s/epoch): Train AUC: 0.8539, Train AP: 0.5120,Test AUC: 0.8513, Test AP: 0.5070\n",
      "Epoch 220 (1.88s/epoch): Train AUC: 0.8548, Train AP: 0.5115,Test AUC: 0.8521, Test AP: 0.5058\n",
      "Epoch 230 (1.88s/epoch): Train AUC: 0.8560, Train AP: 0.5120,Test AUC: 0.8534, Test AP: 0.5068\n",
      "Epoch 240 (1.89s/epoch): Train AUC: 0.8565, Train AP: 0.5185,Test AUC: 0.8537, Test AP: 0.5128\n",
      "Epoch 250 (1.89s/epoch): Train AUC: 0.8575, Train AP: 0.5173,Test AUC: 0.8547, Test AP: 0.5121\n",
      "Epoch 260 (1.84s/epoch): Train AUC: 0.8572, Train AP: 0.5153,Test AUC: 0.8542, Test AP: 0.5091\n",
      "Epoch 270 (1.83s/epoch): Train AUC: 0.8593, Train AP: 0.5201,Test AUC: 0.8565, Test AP: 0.5163\n",
      "Epoch 280 (1.90s/epoch): Train AUC: 0.8585, Train AP: 0.5240,Test AUC: 0.8555, Test AP: 0.5180\n",
      "Epoch 290 (1.89s/epoch): Train AUC: 0.8599, Train AP: 0.5242,Test AUC: 0.8569, Test AP: 0.5187\n",
      "Epoch 300 (1.89s/epoch): Train AUC: 0.8599, Train AP: 0.5238,Test AUC: 0.8570, Test AP: 0.5184\n",
      "Epoch 310 (1.89s/epoch): Train AUC: 0.8592, Train AP: 0.5166,Test AUC: 0.8561, Test AP: 0.5104\n",
      "Epoch 320 (1.89s/epoch): Train AUC: 0.8603, Train AP: 0.5244,Test AUC: 0.8572, Test AP: 0.5188\n",
      "Epoch 330 (1.89s/epoch): Train AUC: 0.8614, Train AP: 0.5254,Test AUC: 0.8583, Test AP: 0.5203\n",
      "Epoch 340 (1.89s/epoch): Train AUC: 0.8619, Train AP: 0.5262,Test AUC: 0.8589, Test AP: 0.5214\n",
      "Epoch 350 (1.89s/epoch): Train AUC: 0.8623, Train AP: 0.5257,Test AUC: 0.8592, Test AP: 0.5204\n",
      "Epoch 360 (1.89s/epoch): Train AUC: 0.8623, Train AP: 0.5262,Test AUC: 0.8593, Test AP: 0.5209\n",
      "Epoch 370 (1.89s/epoch): Train AUC: 0.8629, Train AP: 0.5254,Test AUC: 0.8598, Test AP: 0.5198\n",
      "Epoch 380 (1.88s/epoch): Train AUC: 0.8625, Train AP: 0.5246,Test AUC: 0.8594, Test AP: 0.5188\n",
      "Epoch 390 (1.89s/epoch): Train AUC: 0.8625, Train AP: 0.5271,Test AUC: 0.8590, Test AP: 0.5193\n",
      "Epoch 400 (1.89s/epoch): Train AUC: 0.8636, Train AP: 0.5292,Test AUC: 0.8603, Test AP: 0.5226\n",
      "Epoch 410 (1.89s/epoch): Train AUC: 0.8648, Train AP: 0.5315,Test AUC: 0.8616, Test AP: 0.5263\n",
      "Epoch 420 (1.89s/epoch): Train AUC: 0.8650, Train AP: 0.5274,Test AUC: 0.8617, Test AP: 0.5215\n",
      "Epoch 430 (1.89s/epoch): Train AUC: 0.8647, Train AP: 0.5270,Test AUC: 0.8614, Test AP: 0.5201\n",
      "Epoch 440 (1.89s/epoch): Train AUC: 0.8654, Train AP: 0.5291,Test AUC: 0.8620, Test AP: 0.5220\n",
      "Epoch 450 (1.89s/epoch): Train AUC: 0.8663, Train AP: 0.5320,Test AUC: 0.8631, Test AP: 0.5262\n",
      "Epoch 460 (1.89s/epoch): Train AUC: 0.8653, Train AP: 0.5301,Test AUC: 0.8618, Test AP: 0.5218\n",
      "Epoch 470 (1.89s/epoch): Train AUC: 0.8662, Train AP: 0.5349,Test AUC: 0.8628, Test AP: 0.5283\n",
      "Epoch 480 (1.89s/epoch): Train AUC: 0.8670, Train AP: 0.5393,Test AUC: 0.8641, Test AP: 0.5356\n",
      "Epoch 490 (1.89s/epoch): Train AUC: 0.8665, Train AP: 0.5329,Test AUC: 0.8632, Test AP: 0.5277\n",
      "Epoch 500 (1.89s/epoch): Train AUC: 0.8666, Train AP: 0.5389,Test AUC: 0.8630, Test AP: 0.5314\n",
      "Running iteration 2 of expt GAE_10d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.90s/epoch): Train AUC: 0.7791, Train AP: 0.3827,Test AUC: 0.7786, Test AP: 0.3834\n",
      "Epoch 020 (1.90s/epoch): Train AUC: 0.7939, Train AP: 0.3978,Test AUC: 0.7909, Test AP: 0.3947\n",
      "Epoch 030 (1.90s/epoch): Train AUC: 0.8271, Train AP: 0.4630,Test AUC: 0.8237, Test AP: 0.4581\n",
      "Epoch 040 (1.90s/epoch): Train AUC: 0.8306, Train AP: 0.4664,Test AUC: 0.8271, Test AP: 0.4607\n",
      "Epoch 050 (1.90s/epoch): Train AUC: 0.8366, Train AP: 0.4839,Test AUC: 0.8332, Test AP: 0.4786\n",
      "Epoch 060 (1.89s/epoch): Train AUC: 0.8398, Train AP: 0.4924,Test AUC: 0.8363, Test AP: 0.4871\n",
      "Epoch 070 (1.89s/epoch): Train AUC: 0.8399, Train AP: 0.4883,Test AUC: 0.8362, Test AP: 0.4823\n",
      "Epoch 080 (1.90s/epoch): Train AUC: 0.8426, Train AP: 0.4960,Test AUC: 0.8385, Test AP: 0.4885\n",
      "Epoch 090 (1.89s/epoch): Train AUC: 0.8418, Train AP: 0.5089,Test AUC: 0.8375, Test AP: 0.5025\n",
      "Epoch 100 (1.90s/epoch): Train AUC: 0.8453, Train AP: 0.5069,Test AUC: 0.8411, Test AP: 0.4995\n",
      "Epoch 110 (1.90s/epoch): Train AUC: 0.8466, Train AP: 0.5039,Test AUC: 0.8428, Test AP: 0.4979\n",
      "Epoch 120 (1.91s/epoch): Train AUC: 0.8482, Train AP: 0.5065,Test AUC: 0.8443, Test AP: 0.4999\n",
      "Epoch 130 (1.89s/epoch): Train AUC: 0.8487, Train AP: 0.5054,Test AUC: 0.8448, Test AP: 0.4984\n",
      "Epoch 140 (1.89s/epoch): Train AUC: 0.8508, Train AP: 0.5091,Test AUC: 0.8471, Test AP: 0.5030\n",
      "Epoch 150 (1.89s/epoch): Train AUC: 0.8482, Train AP: 0.5015,Test AUC: 0.8442, Test AP: 0.4936\n",
      "Epoch 160 (1.89s/epoch): Train AUC: 0.8522, Train AP: 0.5144,Test AUC: 0.8485, Test AP: 0.5080\n",
      "Epoch 170 (1.89s/epoch): Train AUC: 0.8536, Train AP: 0.5139,Test AUC: 0.8499, Test AP: 0.5078\n",
      "Epoch 180 (1.88s/epoch): Train AUC: 0.8535, Train AP: 0.5117,Test AUC: 0.8497, Test AP: 0.5045\n",
      "Epoch 190 (1.89s/epoch): Train AUC: 0.8551, Train AP: 0.5134,Test AUC: 0.8515, Test AP: 0.5070\n",
      "Epoch 200 (1.89s/epoch): Train AUC: 0.8573, Train AP: 0.5214,Test AUC: 0.8538, Test AP: 0.5156\n",
      "Epoch 210 (1.88s/epoch): Train AUC: 0.8576, Train AP: 0.5263,Test AUC: 0.8540, Test AP: 0.5200\n",
      "Epoch 220 (1.88s/epoch): Train AUC: 0.8580, Train AP: 0.5200,Test AUC: 0.8544, Test AP: 0.5137\n",
      "Epoch 230 (1.88s/epoch): Train AUC: 0.8582, Train AP: 0.5146,Test AUC: 0.8550, Test AP: 0.5099\n",
      "Epoch 240 (1.88s/epoch): Train AUC: 0.8589, Train AP: 0.5175,Test AUC: 0.8556, Test AP: 0.5118\n",
      "Epoch 250 (1.88s/epoch): Train AUC: 0.8591, Train AP: 0.5222,Test AUC: 0.8554, Test AP: 0.5145\n",
      "Epoch 260 (1.88s/epoch): Train AUC: 0.8609, Train AP: 0.5230,Test AUC: 0.8576, Test AP: 0.5171\n",
      "Epoch 270 (1.89s/epoch): Train AUC: 0.8610, Train AP: 0.5210,Test AUC: 0.8577, Test AP: 0.5154\n",
      "Epoch 280 (1.89s/epoch): Train AUC: 0.8612, Train AP: 0.5233,Test AUC: 0.8576, Test AP: 0.5156\n",
      "Epoch 290 (1.88s/epoch): Train AUC: 0.8613, Train AP: 0.5238,Test AUC: 0.8577, Test AP: 0.5156\n",
      "Epoch 300 (1.88s/epoch): Train AUC: 0.8615, Train AP: 0.5214,Test AUC: 0.8580, Test AP: 0.5135\n",
      "Epoch 310 (1.88s/epoch): Train AUC: 0.8632, Train AP: 0.5224,Test AUC: 0.8602, Test AP: 0.5164\n",
      "Epoch 320 (1.88s/epoch): Train AUC: 0.8627, Train AP: 0.5197,Test AUC: 0.8594, Test AP: 0.5129\n",
      "Epoch 330 (1.88s/epoch): Train AUC: 0.8623, Train AP: 0.5326,Test AUC: 0.8587, Test AP: 0.5261\n",
      "Epoch 340 (1.88s/epoch): Train AUC: 0.8643, Train AP: 0.5290,Test AUC: 0.8610, Test AP: 0.5221\n",
      "Epoch 350 (1.88s/epoch): Train AUC: 0.8648, Train AP: 0.5295,Test AUC: 0.8618, Test AP: 0.5251\n",
      "Epoch 360 (1.89s/epoch): Train AUC: 0.8648, Train AP: 0.5311,Test AUC: 0.8613, Test AP: 0.5222\n",
      "Epoch 370 (1.88s/epoch): Train AUC: 0.8640, Train AP: 0.5276,Test AUC: 0.8605, Test AP: 0.5193\n",
      "Epoch 380 (1.88s/epoch): Train AUC: 0.8645, Train AP: 0.5252,Test AUC: 0.8609, Test AP: 0.5162\n",
      "Epoch 390 (1.88s/epoch): Train AUC: 0.8655, Train AP: 0.5252,Test AUC: 0.8624, Test AP: 0.5188\n",
      "Epoch 400 (1.88s/epoch): Train AUC: 0.8654, Train AP: 0.5281,Test AUC: 0.8621, Test AP: 0.5208\n",
      "Epoch 410 (1.88s/epoch): Train AUC: 0.8656, Train AP: 0.5293,Test AUC: 0.8622, Test AP: 0.5212\n",
      "Epoch 420 (1.88s/epoch): Train AUC: 0.8660, Train AP: 0.5275,Test AUC: 0.8626, Test AP: 0.5201\n",
      "Epoch 430 (1.87s/epoch): Train AUC: 0.8666, Train AP: 0.5273,Test AUC: 0.8635, Test AP: 0.5208\n",
      "Epoch 440 (1.87s/epoch): Train AUC: 0.8665, Train AP: 0.5266,Test AUC: 0.8634, Test AP: 0.5195\n",
      "Epoch 450 (1.88s/epoch): Train AUC: 0.8669, Train AP: 0.5328,Test AUC: 0.8637, Test AP: 0.5252\n",
      "Epoch 460 (1.88s/epoch): Train AUC: 0.8672, Train AP: 0.5305,Test AUC: 0.8641, Test AP: 0.5242\n",
      "Epoch 470 (1.85s/epoch): Train AUC: 0.8661, Train AP: 0.5205,Test AUC: 0.8630, Test AP: 0.5137\n",
      "Epoch 480 (1.88s/epoch): Train AUC: 0.8669, Train AP: 0.5256,Test AUC: 0.8638, Test AP: 0.5186\n",
      "Epoch 490 (1.88s/epoch): Train AUC: 0.8671, Train AP: 0.5278,Test AUC: 0.8640, Test AP: 0.5216\n",
      "Epoch 500 (1.88s/epoch): Train AUC: 0.8680, Train AP: 0.5349,Test AUC: 0.8649, Test AP: 0.5279\n",
      "Running iteration 3 of expt GAE_10d_gat_500epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (1.90s/epoch): Train AUC: 0.7016, Train AP: 0.3203,Test AUC: 0.6984, Test AP: 0.3179\n",
      "Epoch 020 (1.91s/epoch): Train AUC: 0.7048, Train AP: 0.2888,Test AUC: 0.7017, Test AP: 0.2861\n",
      "Epoch 030 (1.91s/epoch): Train AUC: 0.7093, Train AP: 0.2949,Test AUC: 0.7064, Test AP: 0.2935\n",
      "Epoch 040 (1.90s/epoch): Train AUC: 0.7087, Train AP: 0.3016,Test AUC: 0.7049, Test AP: 0.2988\n",
      "Epoch 050 (1.91s/epoch): Train AUC: 0.7112, Train AP: 0.3027,Test AUC: 0.7070, Test AP: 0.2987\n",
      "Epoch 060 (1.91s/epoch): Train AUC: 0.7086, Train AP: 0.2830,Test AUC: 0.7040, Test AP: 0.2785\n",
      "Epoch 070 (1.90s/epoch): Train AUC: 0.7133, Train AP: 0.2964,Test AUC: 0.7084, Test AP: 0.2914\n",
      "Epoch 080 (1.90s/epoch): Train AUC: 0.7156, Train AP: 0.2943,Test AUC: 0.7098, Test AP: 0.2880\n",
      "Epoch 090 (1.88s/epoch): Train AUC: 0.7181, Train AP: 0.2952,Test AUC: 0.7123, Test AP: 0.2896\n",
      "Epoch 100 (1.90s/epoch): Train AUC: 0.7222, Train AP: 0.3049,Test AUC: 0.7154, Test AP: 0.2989\n",
      "Epoch 110 (1.90s/epoch): Train AUC: 0.7272, Train AP: 0.3138,Test AUC: 0.7197, Test AP: 0.3069\n",
      "Epoch 120 (1.90s/epoch): Train AUC: 0.7296, Train AP: 0.3048,Test AUC: 0.7221, Test AP: 0.2989\n",
      "Epoch 130 (1.91s/epoch): Train AUC: 0.7336, Train AP: 0.3118,Test AUC: 0.7243, Test AP: 0.3020\n",
      "Epoch 140 (1.90s/epoch): Train AUC: 0.7380, Train AP: 0.3225,Test AUC: 0.7287, Test AP: 0.3123\n",
      "Epoch 150 (1.90s/epoch): Train AUC: 0.7414, Train AP: 0.3287,Test AUC: 0.7334, Test AP: 0.3237\n",
      "Epoch 160 (1.90s/epoch): Train AUC: 0.7534, Train AP: 0.3353,Test AUC: 0.7439, Test AP: 0.3250\n",
      "Epoch 170 (1.90s/epoch): Train AUC: 0.7604, Train AP: 0.3425,Test AUC: 0.7507, Test AP: 0.3310\n",
      "Epoch 180 (1.90s/epoch): Train AUC: 0.7648, Train AP: 0.3397,Test AUC: 0.7550, Test AP: 0.3284\n",
      "Epoch 190 (1.95s/epoch): Train AUC: 0.7712, Train AP: 0.3483,Test AUC: 0.7610, Test AP: 0.3349\n",
      "Epoch 200 (1.96s/epoch): Train AUC: 0.7769, Train AP: 0.3647,Test AUC: 0.7672, Test AP: 0.3524\n",
      "Epoch 210 (1.89s/epoch): Train AUC: 0.7844, Train AP: 0.3655,Test AUC: 0.7762, Test AP: 0.3572\n",
      "Epoch 220 (1.90s/epoch): Train AUC: 0.7797, Train AP: 0.3432,Test AUC: 0.7725, Test AP: 0.3378\n",
      "Epoch 230 (1.89s/epoch): Train AUC: 0.7915, Train AP: 0.3603,Test AUC: 0.7834, Test AP: 0.3496\n",
      "Epoch 240 (1.88s/epoch): Train AUC: 0.8031, Train AP: 0.3875,Test AUC: 0.7961, Test AP: 0.3798\n",
      "Epoch 250 (1.89s/epoch): Train AUC: 0.8060, Train AP: 0.3865,Test AUC: 0.7997, Test AP: 0.3802\n",
      "Epoch 260 (1.89s/epoch): Train AUC: 0.8071, Train AP: 0.3807,Test AUC: 0.8005, Test AP: 0.3727\n",
      "Epoch 270 (1.89s/epoch): Train AUC: 0.8076, Train AP: 0.3748,Test AUC: 0.8016, Test AP: 0.3678\n",
      "Epoch 280 (1.89s/epoch): Train AUC: 0.8072, Train AP: 0.3724,Test AUC: 0.8011, Test AP: 0.3645\n",
      "Epoch 290 (1.89s/epoch): Train AUC: 0.8118, Train AP: 0.3894,Test AUC: 0.8055, Test AP: 0.3809\n",
      "Epoch 300 (1.89s/epoch): Train AUC: 0.8144, Train AP: 0.3922,Test AUC: 0.8092, Test AP: 0.3856\n",
      "Epoch 310 (1.90s/epoch): Train AUC: 0.8129, Train AP: 0.3911,Test AUC: 0.8069, Test AP: 0.3801\n",
      "Epoch 320 (1.89s/epoch): Train AUC: 0.8161, Train AP: 0.3937,Test AUC: 0.8109, Test AP: 0.3861\n",
      "Epoch 330 (1.89s/epoch): Train AUC: 0.8164, Train AP: 0.3935,Test AUC: 0.8111, Test AP: 0.3856\n",
      "Epoch 340 (1.89s/epoch): Train AUC: 0.8169, Train AP: 0.4013,Test AUC: 0.8124, Test AP: 0.3967\n",
      "Epoch 350 (1.89s/epoch): Train AUC: 0.8145, Train AP: 0.3882,Test AUC: 0.8098, Test AP: 0.3825\n",
      "Epoch 360 (1.90s/epoch): Train AUC: 0.8148, Train AP: 0.3809,Test AUC: 0.8097, Test AP: 0.3729\n",
      "Epoch 370 (1.88s/epoch): Train AUC: 0.8077, Train AP: 0.3817,Test AUC: 0.8019, Test AP: 0.3707\n",
      "Epoch 380 (1.88s/epoch): Train AUC: 0.8159, Train AP: 0.3865,Test AUC: 0.8109, Test AP: 0.3787\n",
      "Epoch 390 (1.89s/epoch): Train AUC: 0.8160, Train AP: 0.3955,Test AUC: 0.8113, Test AP: 0.3880\n",
      "Epoch 400 (1.89s/epoch): Train AUC: 0.8179, Train AP: 0.4091,Test AUC: 0.8134, Test AP: 0.4024\n",
      "Epoch 410 (1.89s/epoch): Train AUC: 0.8165, Train AP: 0.3968,Test AUC: 0.8118, Test AP: 0.3885\n",
      "Epoch 420 (1.89s/epoch): Train AUC: 0.8182, Train AP: 0.4062,Test AUC: 0.8139, Test AP: 0.3996\n",
      "Epoch 430 (1.89s/epoch): Train AUC: 0.8158, Train AP: 0.3859,Test AUC: 0.8115, Test AP: 0.3804\n",
      "Epoch 440 (1.89s/epoch): Train AUC: 0.8170, Train AP: 0.3935,Test AUC: 0.8124, Test AP: 0.3858\n",
      "Epoch 450 (1.90s/epoch): Train AUC: 0.8161, Train AP: 0.3959,Test AUC: 0.8115, Test AP: 0.3892\n",
      "Epoch 460 (1.89s/epoch): Train AUC: 0.8156, Train AP: 0.3850,Test AUC: 0.8112, Test AP: 0.3788\n",
      "Epoch 470 (1.89s/epoch): Train AUC: 0.8170, Train AP: 0.4003,Test AUC: 0.8124, Test AP: 0.3926\n",
      "Epoch 480 (1.89s/epoch): Train AUC: 0.8149, Train AP: 0.3854,Test AUC: 0.8100, Test AP: 0.3766\n",
      "Epoch 490 (1.89s/epoch): Train AUC: 0.8160, Train AP: 0.4079,Test AUC: 0.8118, Test AP: 0.4016\n",
      "Epoch 500 (1.90s/epoch): Train AUC: 0.8150, Train AP: 0.3811,Test AUC: 0.8104, Test AP: 0.3740\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(f'{dataset_root}/ssx_dataset.pt')\n",
    "\n",
    "proc_args = {\n",
    "    'include_feats': rank_fields,\n",
    "    'add_deg_feats': False\n",
    "}\n",
    "dict_res = {}\n",
    "for model_type in ['gcn', 'gat']:\n",
    "    for model_args in [\n",
    "    {\n",
    "        'out_channels': 20,\n",
    "        'model_type': model_type,\n",
    "        'num_layers': 2,\n",
    "    },\n",
    "    {\n",
    "        'out_channels': 10,\n",
    "        'model_type': model_type,\n",
    "        'jk': 'cat',\n",
    "        'num_layers': 2,\n",
    "    }]:\n",
    "        models, results = run(dataset,\n",
    "                            proc_args,\n",
    "                            model_args,\n",
    "                            num_iter=3,\n",
    "                            lr=0.01,\n",
    "                            epochs=500,\n",
    "                            output_tb=False,\n",
    "                            save_best_model=False)\n",
    "        dict_res[(model_type, model_args['out_channels'])] = models, results\n",
    "# torch.save(dict_res, './run_results_16_04_22.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670af72-d298-44ea-8fa7-ee6ae8fd861e",
   "metadata": {},
   "source": [
    "## Train on a single LA's graph and test against all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7d41b-b060-43bd-8445-e15cddf37977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on SSx data from Poole...\n",
      "Running iteration 1 of expt GAE_10d_gat_1000epochs_0.01lr_4_feats\n",
      "{'in_channels': 4, 'out_channels': 10, 'hidden_channels': 10, 'num_layers': 2, 'jk': 'cat'}\n",
      "Epoch 010 (2.53s/epoch): Train AUC: 0.5702, Train AP: 0.2294,Test AUC: 0.5418, Test AP: 0.2091\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(f'{dataset_root}/ssx_dataset.pt')\n",
    "for model_params in [{\n",
    "        'model_type': 'gat',\n",
    "        'out_channels': 10,\n",
    "        'jk': 'cat'\n",
    "    },{\n",
    "        'model_type': 'gat',\n",
    "        'out_channels': 20,\n",
    "    }]:\n",
    "    run_hyperparams = {\n",
    "        'seed': 42,\n",
    "        'model_args': model_params,\n",
    "        'num_iter': 3,\n",
    "        'lr': 0.01,\n",
    "        'epochs': 1000,\n",
    "        'print_every': 10,\n",
    "        'add_deg_feats': False,\n",
    "        'include_feats': rank_fields,\n",
    "    }\n",
    "    places = ['Poole', 'Southwark']\n",
    "    data = run_single(places, dataset, run_args=run_hyperparams)\n",
    "    res[str(include_feats) + '-no_deg'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e41c62-1db0-43c6-9d60-f0abbd6383d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def predict(model, data, enhanced=True):\n",
    "    pos_preds, pos_logits = model.predict_pos(data)\n",
    "    neg_preds, neg_logits = model.predict_neg(data, enhanced=enhanced)\n",
    "    \n",
    "    # Create negative and positive labels\n",
    "    cat_labels = torch.cat([torch.ones(pos_preds.size(0)), torch.zeros(neg_preds.size(0))])\n",
    "    cat_logits = torch.cat([pos_logits, neg_logits] , dim=-1) # TODO\n",
    "    cat_preds = torch.cat([pos_preds, neg_preds] , dim=-1)\n",
    "    cat_index = torch.cat([data.edge_index, data.pos_edge_label_index, data.neg_edge_label_index], dim=-1)\n",
    "    print('Finished prediction, rebuilding road network')\n",
    "    return cat_preds, cat_labels, cat_index\n",
    "    \n",
    "\n",
    "\n",
    "def visualize_preds(place, model, enhanced_predictions=True, hold_out_test_ratio=0.2, neg_sampling_ratio=-1):\n",
    "    original_data = load_graph(place, all_feature_fields)\n",
    "    \n",
    "    data_process_args = {\n",
    "        'split': 1,\n",
    "        'hold_out_edge_ratio': hold_out_test_ratio,\n",
    "        'neg_sampling_ratio': neg_sampling_ratio\n",
    "    }\n",
    "    viz_data = process_dataset([original_data], verbose=False, \n",
    "                               **data_process_args, **model.data_process_args)[0][0]\n",
    "    held_out_edges = [(u.item(), v.item()) for u, v in zip(viz_data.pos_edge_label_index[0], viz_data.pos_edge_label_index[1])]\n",
    "    preds, edge_label, cat_index = predict(model, viz_data, enhanced_predictions)\n",
    "    data = copy.deepcopy(original_data)\n",
    "    \n",
    "    res_dict = {} # For storing new edge attributes in nx\n",
    "    pred_dict = {} # Map of coords to predicted values\n",
    "    label_dict = {} # Map of coords to labels (sanity check)\n",
    "    sampled_dict = {} # For identifying sampled held out edges in plot\n",
    "    \n",
    "    gdf = load_gdf(place)\n",
    "    streets = momepy.gdf_to_nx(gdf, approach='primal', multigraph=False)\n",
    "    pred_streets = momepy.gdf_to_nx(gdf, approach='primal', multigraph=False)\n",
    "    float32_node_dict = {(torch.tensor(c[0], dtype=torch.float32).item(),\n",
    "                          torch.tensor(c[1], dtype=torch.float32).item()): c for c in streets}\n",
    "    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n",
    "    data = original_data\n",
    "    \n",
    "    # Iterate over predicted edges (which includes real and fake edges)\n",
    "    for i, pred in enumerate(preds):\n",
    "        # Get indices of both the nodes of the edge\n",
    "        u_idx, v_idx = cat_index[:, i]\n",
    "        \n",
    "        # Get their coordinates (the last two node attributes in pretransformed data)\n",
    "        u_float32 = data.x[u_idx, -2].item(), data.x[u_idx, -1].item()\n",
    "        v_float32 = data.x[v_idx, -2].item(), data.x[v_idx, -1].item()\n",
    "        # Convert them into their full precision node coordinates\n",
    "        u, v = float32_node_dict[u_float32], float32_node_dict[v_float32]\n",
    "        key = (u, v)\n",
    "        \n",
    "        \n",
    "        if (u_idx, v_idx) in held_out_edges:\n",
    "            sampled_dict[key] = True\n",
    "        else:\n",
    "            sampled_dict[key] = False\n",
    "        \n",
    "        label = edge_label[i]\n",
    "        if key in pred_dict:\n",
    "            # Should NOT happen\n",
    "            raise NotImplementedError\n",
    "        elif (v, u) in pred_dict:\n",
    "            assert pred_dict[(v, u)] == pred\n",
    "            # Double count for undirected graph, ignore reverse edge\n",
    "            continue\n",
    "        else:\n",
    "            pred_dict[key] = pred\n",
    "        \n",
    "        if not (pred_streets.has_edge(u, v) or pred_streets.has_edge(v, u)):\n",
    "            # Negative sampled edge\n",
    "            assert label == 0\n",
    "            res = 'tn' if pred == label else 'fp'\n",
    "            \n",
    "            # Add the false positive edges for visualization\n",
    "            if res == 'fp':\n",
    "                pred_streets.add_edge(u, v, res=res)\n",
    "        else:\n",
    "            if label != 1:\n",
    "                # Abort mission\n",
    "                raise NotImplementedError(u, v, label)\n",
    "            res = 'tp' if pred == label else 'fn'\n",
    "            res_dict[key] = res\n",
    "\n",
    "        count_dict[res] += 1\n",
    "    print('Results')\n",
    "    print(count_dict)\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    tp = count_dict['tp']\n",
    "    fp = count_dict['fp']\n",
    "    fn = count_dict['fn']\n",
    "    prec = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * prec * recall / (prec + recall)\n",
    "    \n",
    "    # Set attributes on the original and predicted graph\n",
    "    nx.set_edge_attributes(pred_streets, res_dict, 'res')\n",
    "    nx.set_edge_attributes(streets, sampled_dict, 'sampled')\n",
    "    \n",
    "    f, ax = plt.subplots(1, 2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "    for i, facet in enumerate(ax):\n",
    "        facet.set_title((\"Actual\", \"Predicted\")[i], size=20)\n",
    "        facet.axis(\"off\")\n",
    "    # Plot original graph, highlighting the held out edges\n",
    "    colors = ['blue' if edge[2]['sampled'] else 'black' for edge in streets.edges(data=True)]\n",
    "    nx.draw(streets, {n:[n[0], n[1]] for n in list(streets.nodes)}, node_size=0, edge_color=colors, edge_cmap='Set1', ax=ax[0])\n",
    "    \n",
    "    # Plot predicted graph\n",
    "    color_state_map = {'tp': 'green', 'fp': 'blue', 'fn': 'red'}\n",
    "    colors = [color_state_map[edge[2]['res']] for edge in pred_streets.edges(data=True)]\n",
    "    nx.draw(pred_streets, {n:[n[0], n[1]] for n in list(pred_streets.nodes)}, node_size=0, edge_color=colors,\n",
    "            edge_cmap='Set1', ax=ax[1])\n",
    "    plt.suptitle(f'\\\"{place}\\\": {data.num_edges} roads\\n Precision: {prec:.3f}, Recall: {recall:.3f}, F1: {f1: .3f}',\n",
    "                fontweight=\"bold\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "loaded_graphs = {}\n",
    "test_places = ['Poole']\n",
    "model = models[0]\n",
    "torch.save(model.state_dict(), './checkpoint.pt')\n",
    "model = init_model(False, False, 4, 10)\n",
    "model.load_state_dict(torch.load('./checkpoint.pt'))\n",
    "model.data_process_args = {\n",
    "    'add_deg_feats': False,\n",
    "    'include_feats': rank_fields\n",
    "}\n",
    "model = model.eval().to(device)\n",
    "for place in test_places:\n",
    "    visualize_preds(place, model, enhanced_predictions=False, neg_sampling_ratio=0.2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7b971-8b03-4abb-9a31-e1f977e29b8a",
   "metadata": {},
   "source": [
    "# Standard GAE-GCN Link Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539f4c9-d3e1-4908-8730-cafe28d911e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.05, num_test=0.1,\n",
    "                            is_undirected=True, add_negative_train_samples=False)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(data.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "print_every = 10\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    if epoch % print_every == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "              f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696449a8-dc93-4064-8676-8f6f7da4cb4b",
   "metadata": {},
   "source": [
    "# ARGVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8bc11-a86d-4f84-9cb7-58c3a6b35b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Linear, ARGVA, GCNConv\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "        return self.lin3(x)\n",
    "\n",
    "in_channels = dataset[0].num_node_features\n",
    "encoder = Encoder(in_channels, hidden_channels=32, out_channels=32)\n",
    "discriminator = Discriminator(in_channels=32, hidden_channels=64,\n",
    "                              out_channels=32)\n",
    "model = ARGVA(encoder, discriminator).to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(),\n",
    "                                           lr=0.001)\n",
    "\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    loss_tot = 0\n",
    "    for data in loader:\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "        # We optimize the discriminator more frequently than the encoder.\n",
    "        for i in range(5):\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            discriminator_loss = model.discriminator_loss(z)\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "        loss = model.recon_loss(z, data.edge_index)\n",
    "        loss = loss + model.reg_loss(z)\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        loss_tot += loss\n",
    "    loss_tot /= len(loader)\n",
    "    return float(loss_tot)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dataset):\n",
    "    model.eval()\n",
    "    auc_tot = 0\n",
    "    ap_tot = 0\n",
    "    for data in dataset:\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        auc, ap = model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "        auc_tot += auc\n",
    "        ap_tot += ap\n",
    "    return auc_tot / len(dataset), ap_tot / len(dataset)\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss = train(train_loader)\n",
    "    auc, ap = test(test_dataset)\n",
    "    print((f'Epoch: {epoch:03d}, Loss: {loss:.3f}, AUC: {auc:.3f}, '\n",
    "           f'AP: {ap:.3f}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0724a0c-5d20-4d71-a926-9199c341e067",
   "metadata": {},
   "source": [
    "# SEAL + DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc073f-306e-41b9-9043-d2464f8c21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEALDataset(InMemoryDataset):\n",
    "    def __init__(self, dataset, num_hops, split='train'):\n",
    "        self.data = dataset[0]\n",
    "        self.num_hops = num_hops\n",
    "        super().__init__(dataset_root)\n",
    "        index = ['train', 'val', 'test'].index(split)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[index])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SEAL_train_data.pt', 'SEAL_val_data.pt', 'SEAL_test_data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        transform = RandomLinkSplit(num_val=0.05, num_test=0.1,\n",
    "                                    is_undirected=True, split_labels=True)\n",
    "        train_data, val_data, test_data = transform(self.data)\n",
    "\n",
    "        self._max_z = 0\n",
    "\n",
    "        # Collect a list of subgraphs for training, validation and testing:\n",
    "        train_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            train_data.edge_index, train_data.pos_edge_label_index, 1)\n",
    "        train_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            train_data.edge_index, train_data.neg_edge_label_index, 0)\n",
    "\n",
    "        val_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            val_data.edge_index, val_data.pos_edge_label_index, 1)\n",
    "        val_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            val_data.edge_index, val_data.neg_edge_label_index, 0)\n",
    "\n",
    "        test_pos_data_list = self.extract_enclosing_subgraphs(\n",
    "            test_data.edge_index, test_data.pos_edge_label_index, 1)\n",
    "        test_neg_data_list = self.extract_enclosing_subgraphs(\n",
    "            test_data.edge_index, test_data.neg_edge_label_index, 0)\n",
    "\n",
    "        # Convert node labeling to one-hot features.\n",
    "        for data in chain(train_pos_data_list, train_neg_data_list,\n",
    "                          val_pos_data_list, val_neg_data_list,\n",
    "                          test_pos_data_list, test_neg_data_list):\n",
    "            # We solely learn links from structure, dropping any node features:\n",
    "            data.x = F.one_hot(data.z, self._max_z + 1).to(torch.float)\n",
    "\n",
    "        torch.save(self.collate(train_pos_data_list + train_neg_data_list),\n",
    "                   self.processed_paths[0])\n",
    "        torch.save(self.collate(val_pos_data_list + val_neg_data_list),\n",
    "                   self.processed_paths[1])\n",
    "        torch.save(self.collate(test_pos_data_list + test_neg_data_list),\n",
    "                   self.processed_paths[2])\n",
    "\n",
    "    def extract_enclosing_subgraphs(self, edge_index, edge_label_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in edge_label_index.t().tolist():\n",
    "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "                [src, dst], self.num_hops, edge_index, relabel_nodes=True)\n",
    "            src, dst = mapping.tolist()\n",
    "\n",
    "            # Remove target link from the subgraph.\n",
    "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "            # Calculate node labeling.\n",
    "            z = self.drnl_node_labeling(sub_edge_index, src, dst,\n",
    "                                        num_nodes=sub_nodes.size(0))\n",
    "\n",
    "            data = Data(x=self.data.x[sub_nodes], z=z,\n",
    "                        edge_index=sub_edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self._max_z = max(int(z.max()), self._max_z)\n",
    "\n",
    "        return z.to(torch.long)\n",
    "\n",
    "dataset = [data]\n",
    "\n",
    "train_dataset = SEALDataset(dataset, num_hops=2, split='train')\n",
    "val_dataset = SEALDataset(dataset, num_hops=2, split='val')\n",
    "test_dataset = SEALDataset(dataset, num_hops=2, split='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fd75c-e1fd-47e8-b365-53dca96c4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers, GNN=GCNConv, k=0.6):\n",
    "        super().__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = max(10, k)\n",
    "        self.k = int(k)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(train_dataset.num_features, hidden_channels))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GNN(hidden_channels, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_channels * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((self.k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.mlp = MLP([dense_dim, 128, 1], dropout=0.5, batch_norm=False)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [conv(xs[-1], edge_index).tanh()]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "        x = global_sort_pool(x, batch, self.k)\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = self.conv1(x).relu()\n",
    "        x = self.maxpool1d(x)\n",
    "        x = self.conv2(x).relu()\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a11510-b059-4162-abb8-67555b70b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(logits.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
    "\n",
    "\n",
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    val_auc = test(val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        test_auc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1f920-d8e1-4ed1-a69c-c52b53bc3db5",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272c22d-90f6-43af-a4bd-9d5ccdacdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import GAE, RGCNConv\n",
    "\n",
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        self.node_emb = Parameter(torch.Tensor(num_nodes, hidden_channels))\n",
    "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_emb)\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.node_emb\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.rel_emb = Parameter(torch.Tensor(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)\n",
    "\n",
    "\n",
    "model = GAE(\n",
    "    RGCNEncoder(data.num_nodes, hidden_channels=500,\n",
    "                num_relations=dataset.num_relations),\n",
    "    DistMultDecoder(dataset.num_relations // 2, hidden_channels=500),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def negative_sampling(edge_index, num_nodes):\n",
    "    # Sample edges by corrupting either the subject or the object of each edge.\n",
    "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
    "    mask_2 = ~mask_1\n",
    "\n",
    "    neg_edge_index = edge_index.clone()\n",
    "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(), ))\n",
    "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(), ))\n",
    "    return neg_edge_index\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.train_edge_index, data.train_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "    cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "    reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
    "    loss = cross_entropy_loss + 1e-2 * reg_loss\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    valid_mrr = compute_mrr(z, data.valid_edge_index, data.valid_edge_type)\n",
    "    test_mrr = compute_mrr(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    return valid_mrr, test_mrr\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mrr(z, edge_index, edge_type):\n",
    "    ranks = []\n",
    "    for i in tqdm(range(edge_type.numel())):\n",
    "        (src, dst), rel = edge_index[:, i], edge_type[i]\n",
    "\n",
    "        # Try all nodes as tails, but delete true triplets:\n",
    "        tail_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            tail_mask[tails[(heads == src) & (types == rel)]] = False\n",
    "\n",
    "        tail = torch.arange(data.num_nodes)[tail_mask]\n",
    "        tail = torch.cat([torch.tensor([dst]), tail])\n",
    "        head = torch.full_like(tail, fill_value=src)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(tail, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        perm = out.argsort(descending=True)\n",
    "        rank = int((perm == 0).nonzero(as_tuple=False).view(-1)[0])\n",
    "        ranks.append(rank + 1)\n",
    "\n",
    "        # Try all nodes as heads, but delete true triplets:\n",
    "        head_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            head_mask[heads[(tails == dst) & (types == rel)]] = False\n",
    "\n",
    "        head = torch.arange(data.num_nodes)[head_mask]\n",
    "        head = torch.cat([torch.tensor([src]), head])\n",
    "        tail = torch.full_like(head, fill_value=dst)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(head, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        perm = out.argsort(descending=True)\n",
    "        rank = int((perm == 0).nonzero(as_tuple=False).view(-1)[0])\n",
    "        ranks.append(rank + 1)\n",
    "\n",
    "    return (1. / torch.tensor(ranks, dtype=torch.float)).mean()\n",
    "\n",
    "\n",
    "for epoch in range(1, 10001):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:05d}, Loss: {loss:.4f}')\n",
    "    if (epoch % 500) == 0:\n",
    "        valid_mrr, test_mrr = test()\n",
    "        print(f'Val MRR: {valid_mrr:.4f}, Test MRR: {test_mrr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
